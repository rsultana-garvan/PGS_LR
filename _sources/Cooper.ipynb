{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f61cdd",
   "metadata": {},
   "source": [
    "# Cooper 142 SNPs set\n",
    "\n",
    "\n",
    "## Preparation\n",
    "\n",
    "### Import required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c4a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics as st\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3513f4",
   "metadata": {},
   "source": [
    "### Read input matrix with genotypes\n",
    "\n",
    "The matrix contains the genotypes from AMP-PD/MGRB dataset for 140 SNPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14ebe96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>cohort</th>\n",
       "      <th>gender</th>\n",
       "      <th>inv_genotype</th>\n",
       "      <th>rs2275579</th>\n",
       "      <th>rs144115304</th>\n",
       "      <th>rs115581042</th>\n",
       "      <th>rs79531911</th>\n",
       "      <th>rs138844738</th>\n",
       "      <th>...</th>\n",
       "      <th>rs10448130</th>\n",
       "      <th>rs34288580</th>\n",
       "      <th>rs34992950</th>\n",
       "      <th>rs7387252</th>\n",
       "      <th>rs2410595</th>\n",
       "      <th>rs41311559</th>\n",
       "      <th>rs148894916</th>\n",
       "      <th>rs112957100</th>\n",
       "      <th>rs143756122</th>\n",
       "      <th>rs148514732</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SY-NIH_INVAA791MKCET</td>\n",
       "      <td>1</td>\n",
       "      <td>STEADY-PD3</td>\n",
       "      <td>M</td>\n",
       "      <td>NI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SY-NIH_INVEP886EEYYL</td>\n",
       "      <td>1</td>\n",
       "      <td>STEADY-PD3</td>\n",
       "      <td>M</td>\n",
       "      <td>NI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SY-NIH_INVFM717GWDX4</td>\n",
       "      <td>1</td>\n",
       "      <td>STEADY-PD3</td>\n",
       "      <td>F</td>\n",
       "      <td>NI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SY-NIH_INVNN611MKKN9</td>\n",
       "      <td>1</td>\n",
       "      <td>STEADY-PD3</td>\n",
       "      <td>M</td>\n",
       "      <td>NI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SY-NIH_INVRB171EXGUK</td>\n",
       "      <td>1</td>\n",
       "      <td>STEADY-PD3</td>\n",
       "      <td>M</td>\n",
       "      <td>II</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>BABQX</td>\n",
       "      <td>0</td>\n",
       "      <td>MGRB</td>\n",
       "      <td>M</td>\n",
       "      <td>II</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>BABRB</td>\n",
       "      <td>0</td>\n",
       "      <td>MGRB</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>BABRE</td>\n",
       "      <td>0</td>\n",
       "      <td>MGRB</td>\n",
       "      <td>M</td>\n",
       "      <td>NI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>ZAAAB</td>\n",
       "      <td>0</td>\n",
       "      <td>MGRB</td>\n",
       "      <td>M</td>\n",
       "      <td>NI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>AABUO</td>\n",
       "      <td>0</td>\n",
       "      <td>MGRB</td>\n",
       "      <td>F</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3112 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            participant_id  phenotype      cohort gender inv_genotype  \\\n",
       "0     SY-NIH_INVAA791MKCET          1  STEADY-PD3      M           NI   \n",
       "1     SY-NIH_INVEP886EEYYL          1  STEADY-PD3      M           NI   \n",
       "2     SY-NIH_INVFM717GWDX4          1  STEADY-PD3      F           NI   \n",
       "3     SY-NIH_INVNN611MKKN9          1  STEADY-PD3      M           NI   \n",
       "4     SY-NIH_INVRB171EXGUK          1  STEADY-PD3      M           II   \n",
       "...                    ...        ...         ...    ...          ...   \n",
       "3107                 BABQX          0        MGRB      M           II   \n",
       "3108                 BABRB          0        MGRB      F           II   \n",
       "3109                 BABRE          0        MGRB      M           NI   \n",
       "3110                 ZAAAB          0        MGRB      M           NI   \n",
       "3111                 AABUO          0        MGRB      F           NN   \n",
       "\n",
       "      rs2275579  rs144115304  rs115581042  rs79531911  rs138844738  ...  \\\n",
       "0             0            0            0           0            0  ...   \n",
       "1             0            0            0           0            0  ...   \n",
       "2             0            0            0           0            0  ...   \n",
       "3             0            0            0           0            0  ...   \n",
       "4             0            1            1           1            0  ...   \n",
       "...         ...          ...          ...         ...          ...  ...   \n",
       "3107          0            0            0           0            0  ...   \n",
       "3108          0            0            0           0            0  ...   \n",
       "3109          0            0            0           0            0  ...   \n",
       "3110          0            0            0           0            0  ...   \n",
       "3111          0            0            0           0            0  ...   \n",
       "\n",
       "      rs10448130  rs34288580  rs34992950  rs7387252  rs2410595  rs41311559  \\\n",
       "0              2           2           1          2          1           0   \n",
       "1              0           0           0          0          0           0   \n",
       "2              0           0           0          0          0           0   \n",
       "3              1           0           1          1          0           0   \n",
       "4              1           1           0          1          0           0   \n",
       "...          ...         ...         ...        ...        ...         ...   \n",
       "3107           1           0           0          0          0           0   \n",
       "3108           0           0           0          0          0           0   \n",
       "3109           1           0           0          0          0           0   \n",
       "3110           2           1           1          1          0           0   \n",
       "3111           1           0           0          0          0           0   \n",
       "\n",
       "      rs148894916  rs112957100  rs143756122  rs148514732  \n",
       "0               0            0            0            0  \n",
       "1               0            0            0            0  \n",
       "2               0            0            0            0  \n",
       "3               0            0            0            0  \n",
       "4               0            0            0            0  \n",
       "...           ...          ...          ...          ...  \n",
       "3107            0            0            0            0  \n",
       "3108            0            0            0            0  \n",
       "3109            0            0            0            0  \n",
       "3110            0            0            0            0  \n",
       "3111            0            0            0            0  \n",
       "\n",
       "[3112 rows x 145 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.read_csv(\"data/matrix.txt\", sep=\"\\t\")\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8db651",
   "metadata": {},
   "source": [
    "### Distribution of data\n",
    "\n",
    "#### Distribution by phenotype\n",
    "\n",
    "(0=Control, 1=Case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7791939b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phenotype\n",
       "0    1556\n",
       "1    1556\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.groupby('phenotype')['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93110b79",
   "metadata": {},
   "source": [
    "#### Distribution by gender/phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "217d8660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender  phenotype\n",
       "F       0            567\n",
       "        1            567\n",
       "M       0            989\n",
       "        1            989\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.groupby(['gender', 'phenotype'])['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09485cef",
   "metadata": {},
   "source": [
    "#### Distribution by gender/phenotype/inv8_001 genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda60157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender  phenotype  inv_genotype\n",
       "F       0          II              195\n",
       "                   NI              259\n",
       "                   NN              113\n",
       "        1          II              175\n",
       "                   NI              270\n",
       "                   NN              122\n",
       "M       0          II              318\n",
       "                   NI              480\n",
       "                   NN              191\n",
       "        1          II              296\n",
       "                   NI              477\n",
       "                   NN              216\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.groupby(['gender', 'phenotype', 'inv_genotype'])['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8957867b",
   "metadata": {},
   "source": [
    "## All participants\n",
    "\n",
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "724edb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phenotype\n",
       "0    1556\n",
       "1    1556\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 150)\n",
    "X = table[table.columns[5:]]\n",
    "Y = table['phenotype']\n",
    "lr = LogisticRegression(random_state=42, solver='saga', n_jobs=-1, penalty='elasticnet')\n",
    "table.groupby('phenotype')['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e1da99",
   "metadata": {},
   "source": [
    "### Grid search for 3 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0d46a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.02, 0.05], &#x27;l1_ratio&#x27;: [1, 0.9, 0.8],\n",
       "                         &#x27;max_iter&#x27;: [10, 25, 50]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.02, 0.05], &#x27;l1_ratio&#x27;: [1, 0.9, 0.8],\n",
       "                         &#x27;max_iter&#x27;: [10, 25, 50]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                          random_state=42, solver='saga'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.02, 0.05], 'l1_ratio': [1, 0.9, 0.8],\n",
       "                         'max_iter': [10, 25, 50]},\n",
       "             scoring='roc_auc', verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {'C': [0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 1, 10, 20, 30],\n",
    "#              'max_iter': [10, 25, 50, 75, 100, 150, 200, 400, 800, 1600],\n",
    "#              'l1_ratio': [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]}\n",
    "\n",
    "parameters = {'C': [0.01, 0.02, 0.05],\n",
    "              'max_iter': [10, 25, 50],\n",
    "              'l1_ratio': [1, 0.9, 0.8]}\n",
    "\n",
    "grid_lr = GridSearchCV(lr, parameters, verbose=False, scoring='roc_auc', n_jobs=-1, cv=10)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "grid_lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbc3850",
   "metadata": {},
   "source": [
    "### Best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e203f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max AUC score:0.5551641873897212\n",
      "\n",
      "Non-zero coefficients: 2\n",
      "\n",
      "Best estimator: LogisticRegression(C=0.02, l1_ratio=1, max_iter=25, n_jobs=-1,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga')\n",
      "Scorer: make_scorer(roc_auc_score, needs_threshold=True)\n",
      "Best params: {'C': 0.02, 'l1_ratio': 1, 'max_iter': 25}\n",
      "Best score: 0.5492252417764205\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs11248057</td>\n",
       "      <td>0.055163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs3806760</td>\n",
       "      <td>0.098122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SNP Coefficient\n",
       "Index                        \n",
       "1      rs11248057    0.055163\n",
       "2       rs3806760    0.098122"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "max_auc_score = roc_auc_score(Y, best_lr.predict_proba(X)[:, 1])\n",
    "coefs = best_lr.coef_[0, :]\n",
    "num_coef = np.sum(coefs != 0)\n",
    "X_header = np.array(X.columns)\n",
    "\n",
    "data_array = np.vstack((X_header, coefs))\n",
    "model_coefs = pd.DataFrame(data=data_array.T, columns=['SNP', 'Coefficient'])\n",
    "print(f'Max AUC score:{max_auc_score}\\n')\n",
    "print(f'Non-zero coefficients: {num_coef}\\n')\n",
    "print(f'Best estimator: {grid_lr.best_estimator_}')\n",
    "print(f'Scorer: {grid_lr.scorer_}')\n",
    "print(f'Best params: {grid_lr.best_params_}')\n",
    "print(f'Best score: {grid_lr.best_score_}\\n')\n",
    "m = model_coefs[model_coefs['Coefficient'] != 0 ].sort_values(by='Coefficient')\n",
    "m = m.reset_index(drop=True).assign(Index=range(len(m)))\n",
    "m.Index= m.Index + 1\n",
    "m.set_index('Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd2380",
   "metadata": {},
   "source": [
    "### 10-fold cross validation (5-times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad06768d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 TRAIN: [   1    2    3 ... 3108 3109 3110] TEST: [   0   14   17   25   31   32   44   45   51   52   63   67   70   76\n",
      "   88   93  102  120  134  139  144  149  152  170  174  175  178  184\n",
      "  188  192  194  196  203  211  214  218  240  246  251  254  256  257\n",
      "  266  270  289  291  298  299  309  314  321  322  331  332  343  346\n",
      "  354  370  408  410  411  416  423  430  433  438  439  443  450  486\n",
      "  495  506  507  528  535  544  554  555  557  564  565  567  568  572\n",
      "  581  599  602  605  610  611  612  679  680  685  695  700  705  755\n",
      "  759  765  772  789  790  794  798  805  840  857  862  867  887  897\n",
      "  900  903  929  930  932  937  945  949  976  978 1018 1023 1027 1044\n",
      " 1053 1064 1068 1073 1084 1091 1093 1102 1106 1116 1117 1149 1177 1179\n",
      " 1206 1207 1210 1211 1216 1221 1222 1242 1251 1268 1307 1309 1317 1320\n",
      " 1337 1344 1361 1375 1376 1422 1425 1448 1450 1476 1480 1483 1494 1497\n",
      " 1506 1557 1563 1566 1567 1583 1590 1608 1616 1628 1665 1690 1702 1706\n",
      " 1716 1718 1721 1723 1742 1743 1760 1775 1783 1804 1809 1830 1847 1862\n",
      " 1869 1871 1889 1907 1922 1927 1929 1936 1941 1947 1948 1951 1962 1971\n",
      " 1972 1991 1992 2005 2009 2011 2040 2043 2066 2087 2108 2115 2124 2130\n",
      " 2134 2144 2166 2171 2178 2195 2209 2216 2219 2222 2232 2236 2248 2250\n",
      " 2269 2276 2321 2344 2374 2376 2396 2401 2408 2409 2421 2422 2439 2457\n",
      " 2462 2467 2472 2499 2508 2510 2516 2530 2547 2552 2561 2563 2566 2577\n",
      " 2586 2614 2635 2647 2648 2669 2692 2716 2719 2746 2748 2765 2775 2812\n",
      " 2818 2831 2834 2837 2841 2847 2849 2851 2862 2881 2884 2898 2912 2921\n",
      " 2928 2930 2937 2940 2943 2946 2950 2967 2968 2979 2986 2987 2997 3002\n",
      " 3026 3097 3102 3111]\n",
      "2 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [  22   29   30   43   48   56   73   80   87  108  111  124  135  141\n",
      "  162  173  176  177  183  221  233  239  272  282  296  313  318  324\n",
      "  325  350  361  366  368  387  393  402  414  420  432  436  449  457\n",
      "  460  463  471  472  478  479  485  501  511  521  522  527  532  533\n",
      "  543  582  594  598  601  621  637  642  651  654  670  676  678  693\n",
      "  718  727  729  744  746  756  764  776  812  819  839  859  864  879\n",
      "  881  889  926  927  940  944  952  962  965 1001 1003 1010 1037 1052\n",
      " 1061 1071 1075 1078 1080 1097 1105 1113 1146 1151 1157 1161 1173 1178\n",
      " 1188 1200 1204 1220 1226 1236 1237 1244 1264 1269 1270 1271 1283 1286\n",
      " 1295 1321 1326 1334 1364 1374 1402 1406 1421 1427 1431 1432 1437 1444\n",
      " 1447 1454 1465 1467 1472 1498 1507 1510 1512 1517 1533 1536 1537 1538\n",
      " 1554 1587 1612 1641 1642 1657 1660 1674 1684 1689 1711 1720 1730 1736\n",
      " 1738 1748 1766 1778 1788 1791 1798 1808 1811 1818 1822 1829 1833 1839\n",
      " 1842 1872 1877 1886 1914 1918 1925 1956 1965 1993 2003 2013 2020 2029\n",
      " 2030 2037 2067 2090 2093 2103 2131 2163 2167 2172 2179 2184 2190 2196\n",
      " 2226 2229 2243 2249 2252 2292 2295 2322 2328 2329 2338 2346 2358 2367\n",
      " 2397 2398 2400 2406 2446 2448 2456 2463 2466 2478 2482 2494 2496 2503\n",
      " 2505 2514 2522 2528 2541 2560 2567 2594 2597 2609 2616 2624 2626 2644\n",
      " 2649 2652 2665 2674 2681 2688 2689 2694 2699 2708 2718 2724 2728 2732\n",
      " 2737 2738 2741 2743 2754 2769 2779 2780 2788 2792 2800 2803 2809 2817\n",
      " 2825 2826 2827 2830 2840 2846 2855 2870 2871 2886 2890 2895 2900 2903\n",
      " 2916 2917 2923 2927 2951 2952 2963 2976 2989 2990 3000 3042 3044 3065\n",
      " 3066 3094 3099 3101]\n",
      "3 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [   7   12   59   96  100  104  109  123  157  163  168  179  195  199\n",
      "  210  212  219  220  226  227  231  237  238  243  247  252  259  261\n",
      "  276  278  283  288  315  340  347  351  358  365  367  381  407  415\n",
      "  422  435  456  461  462  464  480  498  509  518  542  549  573  597\n",
      "  626  644  650  655  662  677  682  691  736  741  742  748  761  767\n",
      "  781  783  785  787  801  803  807  809  810  817  829  831  838  842\n",
      "  845  847  869  871  874  912  942  964  969  979  990  999 1005 1011\n",
      " 1029 1032 1034 1036 1041 1042 1048 1055 1057 1072 1090 1094 1100 1110\n",
      " 1114 1124 1128 1133 1134 1135 1159 1187 1190 1192 1195 1198 1225 1228\n",
      " 1229 1233 1234 1255 1272 1278 1299 1323 1340 1357 1377 1381 1385 1391\n",
      " 1393 1395 1407 1413 1419 1423 1436 1442 1456 1459 1468 1474 1491 1503\n",
      " 1511 1545 1575 1576 1578 1582 1591 1593 1601 1610 1620 1621 1650 1651\n",
      " 1672 1688 1709 1714 1717 1725 1726 1731 1732 1737 1740 1741 1745 1747\n",
      " 1752 1754 1765 1771 1789 1817 1825 1831 1835 1846 1849 1859 1866 1873\n",
      " 1878 1911 1912 1921 1924 1926 1949 1966 1967 1983 1999 2012 2022 2042\n",
      " 2046 2057 2059 2077 2078 2084 2097 2126 2147 2148 2149 2170 2183 2204\n",
      " 2215 2221 2234 2258 2290 2310 2314 2316 2320 2339 2345 2365 2370 2375\n",
      " 2377 2381 2383 2387 2405 2407 2415 2423 2424 2440 2460 2483 2490 2497\n",
      " 2498 2506 2509 2512 2517 2527 2549 2592 2601 2622 2657 2664 2667 2685\n",
      " 2691 2740 2744 2752 2753 2761 2770 2791 2815 2819 2822 2823 2828 2833\n",
      " 2836 2858 2864 2865 2867 2869 2872 2875 2878 2882 2896 2914 2929 2931\n",
      " 2965 2969 2994 3001 3004 3011 3013 3015 3023 3030 3037 3041 3047 3049\n",
      " 3100 3106 3108]\n",
      "4 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [  18   49   57   65   69   84   85  113  118  128  140  155  166  208\n",
      "  229  230  263  269  275  279  281  286  290  297  300  303  304  307\n",
      "  342  344  349  353  360  383  406  424  426  440  445  482  489  494\n",
      "  497  503  508  530  538  547  553  560  561  575  589  596  604  613\n",
      "  617  618  620  629  630  632  643  647  649  657  664  668  669  690\n",
      "  707  714  719  782  786  788  802  811  821  834  841  843  844  856\n",
      "  858  890  891  907  911  916  941  958  961  968  986  998 1000 1009\n",
      " 1014 1017 1024 1025 1033 1047 1058 1088 1089 1099 1103 1123 1125 1127\n",
      " 1174 1196 1208 1213 1231 1235 1239 1241 1253 1261 1263 1288 1289 1292\n",
      " 1298 1302 1313 1316 1322 1330 1336 1345 1350 1352 1356 1359 1360 1366\n",
      " 1370 1373 1378 1392 1398 1411 1412 1426 1429 1446 1451 1455 1477 1509\n",
      " 1518 1552 1553 1558 1562 1565 1580 1584 1586 1588 1600 1602 1606 1609\n",
      " 1611 1618 1623 1637 1640 1667 1670 1671 1677 1697 1712 1713 1729 1739\n",
      " 1763 1770 1776 1779 1786 1793 1795 1797 1803 1812 1837 1840 1850 1861\n",
      " 1867 1874 1896 1898 1913 1938 1953 1957 1960 1963 1964 1973 1979 1980\n",
      " 1995 2019 2023 2025 2044 2051 2063 2083 2096 2098 2106 2111 2112 2117\n",
      " 2120 2127 2161 2168 2176 2211 2230 2241 2242 2268 2272 2279 2283 2291\n",
      " 2293 2297 2299 2306 2313 2319 2323 2332 2335 2347 2356 2357 2372 2379\n",
      " 2380 2418 2425 2426 2443 2465 2468 2473 2484 2501 2536 2540 2548 2562\n",
      " 2570 2576 2580 2582 2583 2584 2605 2621 2632 2650 2655 2658 2661 2662\n",
      " 2670 2679 2686 2700 2712 2723 2725 2730 2766 2774 2783 2808 2845 2848\n",
      " 2850 2899 2901 2920 2936 2938 2954 2955 2958 2960 2993 2996 2998 3007\n",
      " 3008 3051 3096]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 TRAIN: [   0    1    2 ... 3108 3109 3111] TEST: [   8   13   20   23   71   78   83   91   99  105  115  121  132  142\n",
      "  151  156  158  185  191  198  205  207  209  213  222  273  277  287\n",
      "  294  305  306  308  311  316  352  374  377  380  382  386  394  409\n",
      "  421  425  427  429  444  447  458  483  491  500  514  519  526  529\n",
      "  534  548  552  556  570  571  583  585  588  590  591  607  636  672\n",
      "  674  686  694  715  731  733  749  751  754  778  792  800  808  836\n",
      "  855  861  866  873  883  885  886  888  898  902  906  908  910  915\n",
      "  917  923  931  947  970  973  988  993 1004 1007 1050 1054 1056 1083\n",
      " 1087 1096 1098 1185 1186 1189 1230 1245 1247 1259 1260 1265 1273 1281\n",
      " 1293 1328 1338 1343 1349 1351 1362 1368 1397 1399 1405 1410 1417 1435\n",
      " 1453 1457 1461 1462 1475 1487 1488 1502 1505 1525 1532 1543 1547 1551\n",
      " 1556 1559 1569 1613 1614 1624 1626 1644 1655 1656 1659 1662 1675 1694\n",
      " 1703 1710 1727 1735 1744 1764 1767 1769 1800 1805 1807 1832 1844 1868\n",
      " 1882 1883 1885 1891 1897 1910 1933 1937 1950 1952 1961 1977 1988 2004\n",
      " 2008 2010 2034 2050 2054 2073 2079 2089 2095 2102 2113 2118 2119 2123\n",
      " 2153 2154 2157 2186 2194 2208 2227 2228 2245 2259 2262 2266 2271 2273\n",
      " 2274 2287 2307 2309 2312 2318 2325 2330 2334 2342 2348 2349 2360 2362\n",
      " 2366 2373 2382 2384 2410 2428 2437 2459 2461 2470 2475 2480 2526 2531\n",
      " 2533 2534 2551 2573 2575 2588 2589 2593 2600 2620 2631 2663 2676 2677\n",
      " 2696 2697 2698 2702 2703 2711 2727 2750 2759 2760 2764 2771 2781 2784\n",
      " 2789 2795 2798 2806 2820 2832 2843 2856 2877 2891 2892 2894 2902 2971\n",
      " 2973 2981 3019 3021 3024 3034 3045 3048 3057 3067 3070 3076 3081 3086\n",
      " 3090 3104 3110]\n",
      "6 TRAIN: [   0    1    3 ... 3108 3110 3111] TEST: [   2   15   37   39   53   61   72   97  101  107  136  145  148  159\n",
      "  169  171  182  187  215  217  244  250  258  265  271  274  292  295\n",
      "  310  323  328  334  338  339  348  363  371  376  390  398  401  405\n",
      "  413  431  453  465  476  481  505  545  576  579  584  593  614  619\n",
      "  628  634  660  687  696  697  704  710  712  721  726  737  738  743\n",
      "  752  757  771  780  806  816  824  826  849  865  892  893  913  925\n",
      "  934  948  963  974  981  982  983  985  994 1039 1043 1067 1070 1085\n",
      " 1104 1109 1112 1121 1131 1137 1163 1164 1165 1170 1171 1175 1182 1193\n",
      " 1194 1199 1223 1266 1274 1284 1285 1290 1315 1325 1333 1339 1341 1355\n",
      " 1380 1389 1418 1420 1449 1452 1463 1466 1486 1490 1501 1508 1513 1514\n",
      " 1521 1524 1530 1535 1539 1544 1550 1560 1561 1564 1572 1577 1592 1594\n",
      " 1596 1598 1607 1615 1653 1681 1691 1746 1749 1756 1762 1777 1780 1784\n",
      " 1801 1813 1814 1815 1820 1860 1864 1880 1902 1904 1909 1915 1916 1945\n",
      " 1954 1978 1985 1987 2001 2014 2015 2018 2024 2028 2031 2033 2053 2058\n",
      " 2064 2071 2080 2086 2091 2092 2099 2104 2114 2121 2129 2132 2138 2155\n",
      " 2181 2188 2189 2203 2206 2212 2213 2218 2233 2251 2254 2260 2270 2281\n",
      " 2284 2288 2302 2304 2333 2340 2359 2390 2399 2414 2420 2430 2436 2438\n",
      " 2453 2474 2486 2513 2523 2529 2535 2542 2545 2564 2578 2585 2591 2595\n",
      " 2599 2602 2607 2611 2619 2627 2629 2630 2634 2638 2646 2651 2653 2659\n",
      " 2673 2709 2710 2726 2745 2749 2787 2793 2801 2802 2805 2839 2857 2860\n",
      " 2861 2873 2874 2907 2909 2918 2925 2941 2942 2948 2953 2992 2999 3009\n",
      " 3014 3016 3029 3036 3056 3058 3059 3062 3064 3069 3073 3077 3084 3089\n",
      " 3098 3107 3109]\n",
      "7 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [   6   10   24   26   28   33   41   54   58   81   86   94  126  129\n",
      "  147  150  164  167  181  236  285  312  326  327  329  341  345  355\n",
      "  362  385  419  428  441  442  451  454  468  477  490  493  513  516\n",
      "  520  551  566  578  587  592  609  615  631  661  665  692  701  706\n",
      "  711  720  722  730  734  735  745  768  774  777  793  799  813  818\n",
      "  820  822  827  832  848  875  904  905  909  914  921  922  935  936\n",
      "  938  939  943  950  951  966  984  987  989  997 1002 1006 1013 1022\n",
      " 1040 1046 1074 1086 1107 1108 1111 1120 1132 1138 1142 1143 1176 1181\n",
      " 1201 1202 1203 1232 1248 1249 1258 1277 1279 1287 1301 1303 1304 1308\n",
      " 1310 1311 1318 1332 1347 1379 1382 1383 1386 1387 1394 1401 1403 1404\n",
      " 1414 1424 1430 1441 1471 1481 1499 1523 1546 1599 1622 1627 1632 1639\n",
      " 1645 1647 1652 1658 1666 1669 1692 1700 1701 1708 1724 1728 1750 1772\n",
      " 1790 1792 1826 1834 1845 1854 1857 1858 1865 1876 1879 1888 1894 1900\n",
      " 1905 1920 1928 1932 1934 1939 1940 1970 1990 1997 2002 2007 2016 2032\n",
      " 2035 2045 2069 2107 2110 2116 2136 2140 2151 2159 2162 2164 2174 2175\n",
      " 2177 2185 2202 2210 2223 2225 2238 2240 2244 2246 2247 2256 2263 2275\n",
      " 2282 2285 2289 2298 2303 2315 2337 2350 2353 2364 2371 2389 2392 2394\n",
      " 2404 2411 2413 2429 2431 2447 2451 2452 2458 2464 2471 2477 2500 2507\n",
      " 2519 2538 2550 2553 2587 2590 2603 2628 2636 2639 2641 2645 2678 2684\n",
      " 2705 2713 2715 2721 2739 2742 2751 2755 2756 2757 2758 2762 2763 2768\n",
      " 2772 2785 2797 2821 2829 2859 2863 2868 2893 2897 2911 2915 2922 2944\n",
      " 2959 2962 2974 2983 2985 2991 3012 3032 3033 3060 3061 3068 3078 3079\n",
      " 3080 3082 3105]\n",
      "8 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [   3    5    9   27   40   42   47   55   60   62   66   68   74   77\n",
      "   79   82   92  106  110  112  117  125  131  137  138  165  193  204\n",
      "  223  224  228  232  235  242  248  249  255  260  267  280  302  319\n",
      "  320  333  336  357  359  364  372  373  375  384  388  389  404  434\n",
      "  437  446  448  467  470  473  475  484  517  523  525  531  536  539\n",
      "  541  558  577  603  622  624  638  645  653  666  667  671  673  688\n",
      "  689  708  716  723  724  725  739  758  760  762  770  796  814  846\n",
      "  852  868  882  899  901  918  919  924  946  967 1019 1026 1030 1031\n",
      " 1035 1049 1063 1079 1101 1118 1144 1145 1160 1168 1169 1172 1224 1240\n",
      " 1246 1250 1252 1254 1256 1262 1276 1280 1305 1314 1319 1329 1331 1335\n",
      " 1342 1353 1358 1371 1372 1396 1428 1433 1458 1460 1464 1469 1473 1489\n",
      " 1493 1526 1541 1549 1555 1573 1574 1581 1604 1605 1617 1619 1629 1633\n",
      " 1646 1654 1668 1673 1699 1719 1753 1755 1761 1774 1824 1828 1836 1838\n",
      " 1848 1851 1852 1855 1870 1875 1887 1893 1901 1908 1917 1935 1942 1943\n",
      " 1944 1946 1968 1975 1976 1984 1989 1994 2000 2017 2021 2026 2036 2039\n",
      " 2048 2052 2055 2060 2072 2075 2081 2094 2100 2105 2122 2125 2128 2133\n",
      " 2137 2142 2145 2150 2152 2158 2165 2173 2180 2187 2192 2193 2201 2220\n",
      " 2231 2257 2261 2280 2286 2296 2308 2341 2351 2354 2355 2369 2378 2402\n",
      " 2403 2412 2416 2417 2419 2441 2442 2469 2476 2481 2487 2488 2493 2495\n",
      " 2515 2525 2543 2554 2555 2571 2579 2581 2606 2610 2618 2633 2642 2666\n",
      " 2668 2687 2704 2706 2707 2714 2717 2720 2722 2736 2778 2786 2804 2810\n",
      " 2844 2852 2854 2885 2889 2933 2956 2964 2970 2975 2980 3006 3017 3053\n",
      " 3054 3093 3095]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [   4   11   16   19   35   36   38   46   50   75   89   90  114  116\n",
      "  119  127  133  143  153  154  172  180  190  216  225  234  245  264\n",
      "  268  284  301  335  356  369  395  396  399  412  417  469  487  496\n",
      "  499  504  510  512  515  524  537  546  550  559  569  574  580  595\n",
      "  606  616  625  633  635  639  652  656  658  675  681  684  699  703\n",
      "  713  717  728  732  740  750  753  773  784  797  823  825  828  830\n",
      "  833  837  850  851  853  872  876  884  894  895  896  920  928  933\n",
      "  953  954  957  959  971  977  980  991  992  996 1008 1012 1015 1045\n",
      " 1060 1062 1065 1066 1069 1077 1081 1092 1115 1119 1122 1126 1139 1140\n",
      " 1141 1148 1150 1155 1156 1166 1167 1191 1197 1205 1209 1212 1214 1217\n",
      " 1219 1227 1243 1296 1312 1324 1346 1348 1365 1384 1388 1409 1416 1440\n",
      " 1470 1492 1504 1516 1519 1531 1540 1542 1548 1568 1571 1595 1625 1630\n",
      " 1635 1649 1664 1676 1679 1680 1683 1686 1687 1693 1705 1715 1758 1773\n",
      " 1781 1782 1785 1799 1810 1816 1821 1823 1827 1841 1856 1890 1892 1903\n",
      " 1906 1931 1958 1974 1982 1996 2006 2065 2070 2074 2076 2082 2085 2109\n",
      " 2141 2143 2156 2197 2205 2207 2217 2224 2239 2265 2277 2305 2311 2326\n",
      " 2331 2352 2361 2368 2386 2388 2395 2427 2434 2444 2445 2455 2479 2485\n",
      " 2491 2492 2502 2504 2518 2521 2524 2537 2539 2544 2546 2559 2565 2569\n",
      " 2574 2596 2608 2615 2617 2623 2637 2643 2654 2656 2671 2672 2682 2683\n",
      " 2701 2733 2735 2776 2782 2794 2807 2813 2835 2838 2866 2880 2887 2905\n",
      " 2906 2908 2910 2913 2924 2926 2934 2947 2957 2966 2978 2982 2984 3010\n",
      " 3018 3027 3038 3039 3040 3046 3050 3055 3063 3071 3075 3083 3085 3087\n",
      " 3088 3091 3103]\n",
      "10 TRAIN: [   0    2    3 ... 3109 3110 3111] TEST: [   1   21   34   64   95   98  103  122  130  146  160  161  186  189\n",
      "  197  200  201  202  206  241  253  262  293  317  330  337  378  379\n",
      "  391  392  397  400  403  418  452  455  459  466  474  488  492  502\n",
      "  540  562  563  586  600  608  623  627  640  641  646  648  659  663\n",
      "  683  698  702  709  747  763  766  769  775  779  791  795  804  815\n",
      "  835  854  860  863  870  877  878  880  955  956  960  972  975  995\n",
      " 1016 1020 1021 1028 1038 1051 1059 1076 1082 1095 1129 1130 1136 1147\n",
      " 1152 1153 1154 1158 1162 1180 1183 1184 1215 1218 1238 1257 1267 1275\n",
      " 1282 1291 1294 1297 1300 1306 1327 1354 1363 1367 1369 1390 1400 1408\n",
      " 1415 1434 1438 1439 1443 1445 1478 1479 1482 1484 1485 1495 1496 1500\n",
      " 1515 1520 1522 1527 1528 1529 1534 1570 1579 1585 1589 1597 1603 1631\n",
      " 1634 1636 1638 1643 1648 1661 1663 1678 1682 1685 1695 1696 1698 1704\n",
      " 1707 1722 1733 1734 1751 1757 1759 1768 1787 1794 1796 1802 1806 1819\n",
      " 1843 1853 1863 1881 1884 1895 1899 1919 1923 1930 1955 1959 1969 1981\n",
      " 1986 1998 2027 2038 2041 2047 2049 2056 2061 2062 2068 2088 2101 2135\n",
      " 2139 2146 2160 2169 2182 2191 2198 2199 2200 2214 2235 2237 2253 2255\n",
      " 2264 2267 2278 2294 2300 2301 2317 2324 2327 2336 2343 2363 2385 2391\n",
      " 2393 2432 2433 2435 2449 2450 2454 2489 2511 2520 2532 2556 2557 2558\n",
      " 2568 2572 2598 2604 2612 2613 2625 2640 2660 2675 2680 2690 2693 2695\n",
      " 2729 2731 2734 2747 2767 2773 2777 2790 2796 2799 2811 2814 2816 2824\n",
      " 2842 2853 2876 2879 2883 2888 2904 2919 2932 2935 2939 2945 2949 2961\n",
      " 2972 2977 2988 2995 3003 3005 3020 3022 3025 3028 3031 3035 3043 3052\n",
      " 3072 3074 3092]\n",
      "11 TRAIN: [   0    2    3 ... 3109 3110 3111] TEST: [   1   13   23   27   36   37   40   50   79   80   88   91   93  126\n",
      "  132  156  167  190  198  208  230  233  239  263  281  285  296  308\n",
      "  318  324  342  346  351  352  361  388  393  425  432  465  468  472\n",
      "  481  491  496  506  511  512  537  544  545  547  561  591  599  620\n",
      "  625  626  640  651  663  683  696  705  712  723  728  729  743  752\n",
      "  755  756  764  767  771  772  787  813  819  823  852  914  926  933\n",
      "  940  962  982 1009 1018 1021 1022 1039 1042 1047 1058 1073 1075 1077\n",
      " 1078 1090 1092 1108 1110 1129 1131 1154 1156 1163 1165 1166 1182 1186\n",
      " 1190 1193 1195 1197 1217 1221 1226 1235 1244 1269 1273 1277 1280 1282\n",
      " 1314 1315 1320 1322 1339 1344 1357 1370 1371 1383 1393 1428 1445 1447\n",
      " 1486 1495 1499 1515 1536 1542 1553 1561 1566 1568 1580 1586 1604 1620\n",
      " 1623 1630 1640 1641 1662 1663 1679 1686 1704 1713 1721 1725 1729 1748\n",
      " 1753 1762 1778 1782 1785 1795 1802 1804 1814 1846 1851 1854 1864 1874\n",
      " 1881 1886 1892 1904 1910 1938 1939 1945 1955 1967 1975 1984 2007 2013\n",
      " 2023 2027 2031 2051 2071 2073 2087 2114 2115 2117 2138 2143 2148 2154\n",
      " 2159 2164 2175 2177 2180 2182 2195 2234 2244 2247 2251 2254 2259 2269\n",
      " 2278 2283 2287 2292 2296 2304 2306 2312 2315 2322 2348 2350 2353 2354\n",
      " 2377 2396 2402 2403 2415 2418 2423 2433 2434 2441 2465 2486 2504 2505\n",
      " 2511 2514 2528 2533 2536 2542 2547 2549 2554 2557 2562 2589 2609 2613\n",
      " 2616 2617 2621 2623 2627 2629 2644 2664 2683 2692 2696 2722 2740 2758\n",
      " 2785 2791 2792 2801 2811 2819 2824 2832 2839 2850 2858 2865 2871 2873\n",
      " 2904 2914 2929 2955 2996 2998 3016 3020 3031 3043 3053 3056 3057 3058\n",
      " 3070 3089 3097 3104]\n",
      "12 TRAIN: [   0    1    2 ... 3108 3109 3110] TEST: [  14   17   19   28   31   34   41   45   54   65   66   74   78   84\n",
      "   94   97  101  116  130  131  133  157  168  171  177  185  189  199\n",
      "  216  217  221  228  231  242  243  248  254  258  259  264  265  319\n",
      "  323  325  343  345  372  376  377  378  390  401  408  410  417  437\n",
      "  441  466  469  476  486  501  510  534  535  538  550  565  576  604\n",
      "  611  616  622  646  681  686  688  704  706  707  722  730  746  749\n",
      "  763  769  774  800  805  812  814  846  853  864  878  895  907  920\n",
      "  932  936  953  960  964  965 1004 1040 1044 1049 1057 1069 1074 1080\n",
      " 1103 1125 1133 1149 1153 1158 1171 1175 1176 1185 1192 1202 1208 1218\n",
      " 1219 1220 1243 1261 1263 1297 1311 1318 1324 1326 1328 1329 1343 1345\n",
      " 1353 1354 1360 1388 1400 1406 1407 1429 1441 1443 1446 1458 1471 1477\n",
      " 1480 1501 1511 1512 1520 1533 1550 1593 1600 1634 1649 1660 1666 1668\n",
      " 1669 1670 1682 1683 1694 1728 1730 1734 1738 1740 1741 1761 1763 1803\n",
      " 1807 1821 1831 1835 1840 1871 1893 1898 1899 1926 1929 1931 1941 1956\n",
      " 1963 1969 1973 2017 2026 2029 2033 2045 2053 2055 2056 2061 2066 2072\n",
      " 2077 2089 2091 2094 2095 2105 2113 2116 2124 2125 2147 2162 2166 2170\n",
      " 2185 2212 2214 2233 2261 2288 2294 2300 2313 2325 2360 2363 2398 2404\n",
      " 2407 2410 2419 2421 2430 2432 2457 2463 2471 2481 2483 2529 2537 2553\n",
      " 2570 2596 2625 2626 2634 2639 2642 2661 2666 2674 2681 2687 2697 2699\n",
      " 2720 2723 2724 2729 2730 2743 2753 2763 2771 2779 2790 2813 2820 2822\n",
      " 2823 2825 2829 2842 2843 2859 2868 2870 2875 2877 2879 2880 2888 2940\n",
      " 2941 2962 2963 2971 2993 2994 3006 3015 3019 3024 3039 3041 3064 3067\n",
      " 3084 3093 3095 3111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [   8   11   15   20   33   44   46   59   63   98  122  129  141  143\n",
      "  147  163  179  181  213  227  240  245  247  257  262  279  280  284\n",
      "  297  301  302  303  320  321  333  371  373  399  407  409  420  426\n",
      "  435  439  440  447  467  473  477  482  521  523  526  530  549  553\n",
      "  558  577  585  586  587  588  590  612  635  641  655  672  675  676\n",
      "  691  702  710  736  742  747  754  766  781  783  786  794  811  836\n",
      "  845  865  866  893  921  923  934  948  955  966  968  969  970  977\n",
      "  986  988  996 1002 1005 1012 1013 1026 1027 1032 1038 1046 1056 1059\n",
      " 1060 1079 1084 1097 1100 1101 1118 1119 1120 1122 1160 1161 1169 1181\n",
      " 1199 1212 1223 1242 1267 1274 1284 1310 1321 1333 1335 1362 1369 1372\n",
      " 1382 1396 1409 1411 1414 1416 1440 1462 1470 1485 1492 1498 1514 1531\n",
      " 1544 1555 1570 1578 1611 1615 1632 1633 1651 1656 1672 1698 1703 1707\n",
      " 1709 1719 1720 1726 1737 1750 1755 1789 1790 1791 1796 1801 1811 1820\n",
      " 1828 1839 1857 1858 1861 1862 1865 1896 1902 1917 1919 1921 1925 1930\n",
      " 1949 1964 1976 1981 1983 1985 2002 2022 2024 2039 2042 2047 2057 2058\n",
      " 2065 2068 2090 2126 2127 2128 2133 2136 2139 2160 2178 2189 2200 2205\n",
      " 2206 2208 2210 2223 2228 2232 2249 2252 2260 2263 2281 2291 2316 2323\n",
      " 2327 2330 2333 2340 2356 2366 2388 2411 2412 2425 2449 2450 2493 2494\n",
      " 2507 2517 2519 2531 2559 2561 2565 2566 2582 2590 2592 2603 2608 2620\n",
      " 2622 2633 2636 2643 2645 2646 2652 2672 2684 2689 2690 2706 2744 2748\n",
      " 2757 2775 2778 2788 2799 2836 2844 2846 2855 2861 2886 2890 2896 2902\n",
      " 2913 2915 2947 2974 2980 2989 3012 3013 3026 3034 3048 3068 3069 3075\n",
      " 3080 3085 3098]\n",
      "14 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [   3    4   29   57   69   90  102  107  110  121  124  128  135  144\n",
      "  145  148  149  151  172  176  196  202  236  251  268  290  292  293\n",
      "  310  315  349  354  367  375  380  381  384  414  418  422  431  445\n",
      "  453  459  462  471  502  503  509  525  542  548  555  571  584  589\n",
      "  598  608  610  613  623  624  654  662  669  697  701  709  740  748\n",
      "  751  753  773  778  784  788  791  795  797  799  807  808  810  815\n",
      "  825  834  840  851  877  879  881  889  896  899  915  918  947  959\n",
      "  967  981  983  984  994 1008 1015 1028 1033 1048 1086 1128 1138 1139\n",
      " 1142 1144 1170 1172 1174 1183 1188 1206 1209 1215 1225 1232 1247 1248\n",
      " 1250 1253 1254 1256 1265 1266 1268 1272 1276 1285 1286 1290 1298 1300\n",
      " 1317 1323 1374 1375 1376 1384 1397 1404 1408 1418 1419 1421 1425 1430\n",
      " 1453 1454 1483 1484 1487 1496 1500 1507 1547 1557 1562 1565 1575 1579\n",
      " 1585 1601 1606 1608 1612 1617 1618 1631 1646 1654 1667 1674 1677 1678\n",
      " 1685 1695 1706 1715 1718 1747 1764 1773 1780 1798 1848 1852 1853 1860\n",
      " 1869 1885 1888 1894 1905 1922 1933 1940 1953 1958 1977 1979 1992 2020\n",
      " 2025 2030 2063 2075 2103 2109 2112 2137 2141 2142 2144 2153 2171 2183\n",
      " 2184 2190 2197 2202 2215 2227 2229 2237 2255 2258 2267 2268 2271 2286\n",
      " 2290 2297 2303 2310 2317 2318 2332 2374 2391 2424 2440 2472 2474 2479\n",
      " 2484 2491 2502 2515 2520 2521 2534 2543 2560 2568 2571 2574 2578 2579\n",
      " 2599 2600 2605 2638 2663 2676 2677 2711 2713 2717 2718 2728 2741 2745\n",
      " 2746 2764 2781 2782 2786 2798 2807 2815 2854 2856 2893 2900 2926 2937\n",
      " 2948 2956 2961 2978 2987 3008 3010 3017 3021 3025 3030 3071 3072 3078\n",
      " 3088 3094 3106]\n",
      "15 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [   5   10   12   30   35   38   47   71   87   89  100  105  106  109\n",
      "  119  142  154  178  183  223  225  235  237  269  272  275  286  295\n",
      "  307  327  336  344  363  379  405  416  421  423  429  438  443  446\n",
      "  452  478  485  487  497  505  518  529  563  564  569  605  606  627\n",
      "  636  638  642  653  698  711  713  716  721  724  727  732  734  737\n",
      "  738  760  765  776  782  789  804  809  826  829  830  844  848  861\n",
      "  870  875  876  884  903  911  925  927  930  944  952  971  975  978\n",
      "  980  985 1016 1020 1024 1025 1031 1052 1055 1061 1065 1066 1081 1083\n",
      " 1094 1095 1109 1112 1117 1121 1155 1168 1173 1194 1203 1204 1210 1229\n",
      " 1246 1252 1278 1291 1294 1295 1302 1319 1330 1332 1336 1350 1351 1352\n",
      " 1365 1368 1373 1394 1398 1420 1426 1433 1451 1488 1490 1509 1513 1521\n",
      " 1529 1535 1539 1545 1554 1559 1569 1584 1602 1613 1616 1653 1657 1664\n",
      " 1665 1684 1689 1690 1699 1711 1732 1733 1735 1743 1745 1754 1760 1770\n",
      " 1781 1783 1794 1805 1816 1832 1844 1859 1868 1870 1872 1876 1880 1883\n",
      " 1891 1906 1916 1918 1951 1954 1959 1965 1971 1978 1980 1989 1990 2000\n",
      " 2009 2035 2044 2074 2080 2084 2099 2110 2119 2123 2149 2168 2187 2213\n",
      " 2219 2238 2266 2270 2275 2285 2331 2336 2337 2338 2345 2347 2362 2375\n",
      " 2393 2394 2395 2399 2401 2435 2461 2462 2475 2476 2489 2499 2513 2522\n",
      " 2525 2526 2548 2550 2551 2577 2584 2602 2611 2612 2615 2619 2635 2651\n",
      " 2655 2657 2671 2703 2707 2708 2716 2727 2733 2749 2752 2761 2762 2795\n",
      " 2840 2867 2874 2887 2909 2911 2923 2934 2936 2938 2943 2954 2958 2965\n",
      " 2966 2969 2973 2977 2983 2992 3032 3037 3045 3059 3060 3065 3083 3086\n",
      " 3087 3100 3102]\n",
      "16 TRAIN: [   0    1    3 ... 3109 3110 3111] TEST: [   2   26   43   53   55   61   73   95  113  137  155  160  165  169\n",
      "  184  188  193  203  206  210  219  229  249  252  287  291  298  316\n",
      "  322  332  334  335  338  339  347  350  365  370  385  387  391  394\n",
      "  395  400  428  434  454  457  458  479  500  504  507  513  514  527\n",
      "  531  533  536  570  572  574  582  592  597  607  634  649  657  670\n",
      "  677  687  693  715  717  718  731  733  735  750  768  779  780  790\n",
      "  798  803  827  833  837  838  842  854  856  857  867  886  892  897\n",
      "  898  900  904  916  917  919  922  938  950  954  956  961  974  991\n",
      " 1000 1037 1063 1071 1085 1087 1093 1114 1115 1143 1148 1201 1205 1222\n",
      " 1224 1231 1234 1240 1245 1255 1258 1260 1279 1281 1287 1288 1299 1338\n",
      " 1359 1379 1387 1423 1436 1438 1448 1452 1460 1465 1468 1493 1505 1508\n",
      " 1527 1530 1540 1543 1564 1595 1596 1599 1609 1614 1621 1643 1644 1645\n",
      " 1650 1655 1671 1716 1744 1756 1758 1765 1766 1768 1769 1775 1786 1797\n",
      " 1806 1825 1836 1867 1882 1895 1897 1901 1908 1912 1915 1927 1928 1961\n",
      " 1966 1974 2004 2018 2034 2049 2069 2081 2082 2085 2104 2118 2129 2131\n",
      " 2134 2163 2193 2196 2199 2216 2221 2243 2245 2253 2276 2279 2289 2298\n",
      " 2328 2355 2364 2365 2370 2381 2382 2383 2385 2400 2405 2406 2413 2427\n",
      " 2439 2446 2447 2453 2477 2498 2506 2508 2539 2545 2563 2580 2583 2588\n",
      " 2597 2598 2628 2637 2654 2688 2691 2704 2755 2772 2773 2777 2787 2793\n",
      " 2794 2797 2805 2806 2810 2812 2814 2818 2827 2830 2845 2848 2849 2857\n",
      " 2860 2863 2864 2869 2881 2882 2885 2898 2899 2903 2906 2907 2920 2925\n",
      " 2927 2931 2932 2933 2942 2953 2957 2995 2999 3002 3035 3050 3052 3054\n",
      " 3062 3073 3099]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [  16   51   60   62   68   70   72   75   82   86   92   96   99  108\n",
      "  114  120  134  146  150  175  192  195  204  238  241  246  250  255\n",
      "  260  274  282  283  288  294  300  304  311  313  329  337  366  369\n",
      "  402  411  412  415  444  448  464  480  484  489  493  498  528  543\n",
      "  559  566  567  595  596  602  609  617  621  629  633  637  639  644\n",
      "  645  652  661  671  679  689  690  720  741  744  745  757  793  802\n",
      "  806  822  828  831  841  847  859  874  924  931  937  945  949  957\n",
      "  963 1001 1007 1010 1014 1019 1029 1030 1034 1041 1068 1070 1096 1126\n",
      " 1152 1157 1167 1177 1184 1187 1189 1198 1200 1211 1230 1262 1271 1292\n",
      " 1305 1306 1308 1312 1334 1337 1340 1342 1358 1361 1364 1385 1389 1392\n",
      " 1395 1405 1410 1412 1432 1437 1449 1456 1459 1466 1467 1472 1503 1504\n",
      " 1516 1518 1526 1532 1558 1560 1571 1573 1582 1598 1607 1619 1622 1637\n",
      " 1639 1647 1652 1687 1688 1700 1702 1717 1742 1777 1779 1788 1813 1817\n",
      " 1818 1837 1873 1879 1887 1911 1934 1942 1944 1986 1993 2008 2028 2032\n",
      " 2040 2054 2060 2067 2076 2083 2086 2093 2098 2106 2107 2108 2132 2135\n",
      " 2152 2155 2157 2167 2173 2181 2191 2192 2198 2203 2225 2226 2262 2264\n",
      " 2272 2273 2299 2301 2302 2308 2339 2351 2357 2359 2361 2379 2386 2392\n",
      " 2414 2426 2428 2431 2436 2438 2443 2444 2445 2452 2458 2460 2464 2470\n",
      " 2480 2496 2500 2510 2524 2538 2540 2541 2544 2552 2572 2573 2576 2586\n",
      " 2593 2595 2614 2630 2631 2632 2640 2656 2662 2670 2673 2680 2698 2712\n",
      " 2725 2726 2736 2739 2754 2756 2759 2765 2766 2769 2783 2802 2817 2851\n",
      " 2889 2910 2919 2930 2949 2950 2964 2967 2970 2976 2979 2997 3000 3009\n",
      " 3018 3027 3079]\n",
      "18 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [   7    9   39   42   49   64   77   83   85  103  111  127  139  152\n",
      "  153  166  174  180  186  191  205  207  211  212  214  218  220  253\n",
      "  261  270  271  273  278  289  305  309  312  314  326  341  348  356\n",
      "  360  368  383  389  404  406  424  450  451  461  463  474  492  494\n",
      "  495  499  508  516  517  520  524  551  560  568  579  580  594  600\n",
      "  614  618  619  650  658  660  666  668  673  680  684  692  699  708\n",
      "  725  758  759  762  777  824  843  850  860  862  868  869  871  873\n",
      "  885  887  890  894  901  943  992  993  999 1062 1099 1105 1116 1135\n",
      " 1151 1162 1164 1191 1214 1216 1233 1270 1275 1283 1293 1296 1331 1341\n",
      " 1348 1349 1355 1363 1390 1391 1413 1422 1424 1427 1434 1435 1473 1476\n",
      " 1481 1491 1506 1534 1537 1538 1541 1546 1549 1567 1581 1583 1597 1603\n",
      " 1624 1626 1636 1638 1658 1659 1661 1676 1691 1692 1752 1757 1787 1792\n",
      " 1822 1824 1826 1834 1838 1849 1877 1890 1903 1907 1913 1914 1920 1923\n",
      " 1924 1937 1947 1957 1962 1987 1988 1991 2001 2003 2006 2012 2019 2038\n",
      " 2050 2079 2097 2121 2140 2145 2146 2161 2165 2176 2179 2201 2209 2218\n",
      " 2220 2230 2236 2239 2240 2246 2250 2284 2319 2326 2329 2335 2344 2346\n",
      " 2349 2358 2371 2376 2378 2380 2387 2389 2397 2417 2451 2473 2485 2488\n",
      " 2509 2516 2523 2569 2575 2581 2585 2594 2601 2604 2618 2641 2669 2675\n",
      " 2678 2679 2682 2695 2701 2735 2737 2774 2776 2789 2800 2804 2816 2828\n",
      " 2835 2841 2847 2853 2862 2872 2876 2878 2891 2892 2901 2905 2908 2916\n",
      " 2918 2922 2935 2939 2944 2945 2959 2972 2975 2984 2985 2991 3001 3003\n",
      " 3005 3007 3014 3023 3028 3029 3033 3036 3042 3044 3047 3055 3061 3063\n",
      " 3091 3105 3107]\n",
      "19 TRAIN: [   0    1    2 ... 3107 3109 3111] TEST: [  21   22   24   25   32   52   56  112  117  118  136  140  158  159\n",
      "  161  170  187  194  197  200  215  224  226  232  234  256  276  277\n",
      "  306  328  330  353  355  357  392  397  413  427  430  433  436  449\n",
      "  456  460  470  483  488  490  515  522  532  539  540  546  578  615\n",
      "  630  631  632  643  647  648  659  664  667  674  682  685  695  719\n",
      "  739  775  792  801  817  818  821  839  849  872  883  888  905  912\n",
      "  928  939  941  942  951  972  973  979  990 1006 1011 1023 1035 1036\n",
      " 1045 1050 1051 1067 1072 1076 1082 1088 1089 1091 1098 1102 1106 1111\n",
      " 1113 1123 1124 1127 1137 1145 1146 1147 1180 1196 1227 1228 1238 1241\n",
      " 1249 1259 1264 1304 1309 1313 1316 1327 1346 1378 1381 1401 1417 1444\n",
      " 1464 1469 1475 1478 1479 1482 1489 1494 1497 1519 1524 1525 1548 1551\n",
      " 1552 1576 1587 1588 1589 1590 1592 1594 1625 1629 1642 1673 1675 1680\n",
      " 1693 1696 1697 1705 1722 1723 1724 1736 1739 1746 1749 1751 1759 1767\n",
      " 1772 1776 1799 1808 1809 1815 1827 1833 1843 1855 1878 1884 1948 1950\n",
      " 1994 1995 1997 1999 2005 2010 2014 2015 2016 2048 2052 2059 2062 2064\n",
      " 2078 2092 2100 2101 2102 2130 2158 2188 2204 2207 2222 2224 2231 2235\n",
      " 2241 2256 2257 2265 2274 2277 2295 2307 2311 2314 2321 2334 2341 2342\n",
      " 2367 2368 2369 2373 2408 2409 2420 2422 2437 2448 2455 2456 2469 2490\n",
      " 2503 2512 2518 2527 2535 2555 2587 2591 2610 2624 2647 2648 2650 2653\n",
      " 2659 2668 2694 2705 2709 2710 2715 2731 2732 2734 2738 2742 2747 2750\n",
      " 2751 2767 2768 2770 2780 2803 2821 2831 2833 2837 2838 2883 2917 2921\n",
      " 2946 2952 2982 2986 2988 2990 3011 3022 3038 3066 3074 3076 3077 3096\n",
      " 3103 3108 3110]\n",
      "20 TRAIN: [   1    2    3 ... 3108 3110 3111] TEST: [   0    6   18   48   58   67   76   81  104  115  123  125  138  162\n",
      "  164  173  182  201  209  222  244  266  267  299  317  331  340  358\n",
      "  359  362  364  374  382  386  396  398  403  419  442  455  475  519\n",
      "  541  552  554  556  557  562  573  575  581  583  593  601  603  628\n",
      "  656  665  678  694  700  703  714  726  761  770  785  796  816  820\n",
      "  832  835  855  858  863  880  882  891  902  906  908  909  910  913\n",
      "  929  935  946  958  976  987  989  995  997  998 1003 1017 1043 1053\n",
      " 1054 1064 1104 1107 1130 1132 1134 1136 1140 1141 1150 1159 1178 1179\n",
      " 1207 1213 1236 1237 1239 1251 1257 1289 1301 1303 1307 1325 1347 1356\n",
      " 1366 1367 1377 1380 1386 1399 1402 1403 1415 1431 1439 1442 1450 1455\n",
      " 1457 1461 1463 1474 1502 1510 1517 1522 1523 1528 1556 1563 1572 1574\n",
      " 1577 1591 1605 1610 1627 1628 1635 1648 1681 1701 1708 1710 1712 1714\n",
      " 1727 1731 1771 1774 1784 1793 1800 1810 1812 1819 1823 1829 1830 1841\n",
      " 1842 1845 1847 1850 1856 1863 1866 1875 1889 1900 1909 1932 1935 1936\n",
      " 1943 1946 1952 1960 1968 1970 1972 1982 1996 1998 2011 2021 2036 2037\n",
      " 2041 2043 2046 2070 2088 2096 2111 2120 2122 2150 2151 2156 2169 2172\n",
      " 2174 2186 2194 2211 2217 2242 2248 2280 2282 2293 2305 2309 2320 2324\n",
      " 2343 2352 2372 2384 2390 2416 2429 2442 2454 2459 2466 2467 2468 2478\n",
      " 2482 2487 2492 2495 2497 2501 2530 2532 2546 2556 2558 2564 2567 2606\n",
      " 2607 2649 2658 2660 2665 2667 2685 2686 2693 2700 2702 2714 2719 2721\n",
      " 2760 2784 2796 2808 2809 2826 2834 2852 2866 2884 2894 2895 2897 2912\n",
      " 2924 2928 2951 2960 2968 2981 3004 3040 3046 3049 3051 3081 3082 3090\n",
      " 3092 3101 3109]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 TRAIN: [   1    4    5 ... 3109 3110 3111] TEST: [   0    2    3   14   27   29   32   36   39   71   72   80   94   97\n",
      "  106  110  131  141  150  159  173  174  186  244  251  262  278  284\n",
      "  290  293  299  305  311  316  321  346  369  398  399  416  419  424\n",
      "  447  450  464  481  482  483  487  493  543  562  567  570  571  586\n",
      "  590  592  599  606  624  651  668  671  683  685  690  692  695  714\n",
      "  733  735  761  764  788  789  794  796  798  823  836  851  854  863\n",
      "  889  895  902  903  908  929  948  952  960  963  965  975  978 1003\n",
      " 1006 1010 1018 1048 1054 1056 1064 1071 1085 1120 1149 1155 1159 1161\n",
      " 1174 1178 1182 1205 1213 1231 1237 1245 1251 1258 1263 1275 1276 1277\n",
      " 1283 1289 1290 1295 1318 1327 1367 1372 1386 1428 1451 1458 1463 1474\n",
      " 1478 1488 1526 1534 1544 1578 1581 1585 1595 1606 1611 1634 1637 1650\n",
      " 1654 1657 1666 1692 1693 1704 1709 1725 1740 1752 1753 1766 1771 1772\n",
      " 1775 1776 1792 1800 1802 1803 1810 1826 1830 1836 1841 1863 1871 1880\n",
      " 1887 1889 1909 1915 1919 1943 1945 1960 1962 1976 1981 1985 2000 2001\n",
      " 2005 2013 2018 2023 2035 2041 2056 2059 2070 2071 2075 2090 2094 2096\n",
      " 2098 2112 2129 2138 2149 2162 2163 2165 2176 2182 2203 2205 2219 2221\n",
      " 2233 2235 2236 2239 2242 2245 2281 2286 2289 2293 2297 2304 2309 2345\n",
      " 2389 2411 2413 2420 2434 2442 2458 2464 2466 2488 2505 2517 2519 2531\n",
      " 2535 2538 2540 2575 2589 2590 2609 2621 2625 2650 2653 2664 2692 2695\n",
      " 2723 2732 2736 2754 2755 2758 2789 2793 2796 2816 2821 2827 2842 2857\n",
      " 2861 2862 2881 2887 2892 2896 2899 2906 2916 2926 2929 2931 2944 2946\n",
      " 2950 2954 2957 2958 2962 2967 2970 2973 2981 3016 3018 3025 3029 3031\n",
      " 3049 3072 3083 3095]\n",
      "22 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [  23   34   42   43   47   50   76   88   90   93  107  119  123  133\n",
      "  137  152  169  195  200  201  202  245  265  267  271  274  286  295\n",
      "  302  315  318  341  345  352  358  360  367  376  405  410  423  430\n",
      "  451  457  466  480  484  488  504  518  525  526  552  563  577  582\n",
      "  583  621  623  626  635  637  644  658  673  684  698  720  782  783\n",
      "  793  816  829  850  876  884  910  921  936  937  955  956  958  979\n",
      "  980  986 1011 1019 1034 1058 1059 1068 1072 1076 1083 1087 1088 1103\n",
      " 1109 1111 1118 1144 1150 1156 1171 1179 1180 1183 1186 1190 1198 1199\n",
      " 1208 1234 1249 1256 1257 1268 1286 1300 1303 1304 1315 1328 1330 1342\n",
      " 1343 1344 1355 1370 1376 1408 1426 1442 1455 1460 1470 1472 1476 1479\n",
      " 1493 1498 1504 1512 1523 1524 1530 1531 1541 1543 1562 1589 1596 1617\n",
      " 1618 1620 1621 1639 1646 1653 1663 1667 1671 1672 1676 1681 1686 1695\n",
      " 1697 1698 1699 1711 1714 1715 1730 1737 1746 1758 1770 1780 1782 1783\n",
      " 1791 1818 1819 1824 1825 1837 1891 1899 1906 1914 1924 1925 1928 1941\n",
      " 1954 1963 1999 2009 2031 2033 2038 2066 2080 2081 2088 2097 2109 2111\n",
      " 2114 2124 2128 2133 2147 2175 2178 2185 2195 2197 2199 2213 2217 2224\n",
      " 2225 2231 2243 2252 2270 2272 2273 2285 2296 2308 2311 2319 2324 2346\n",
      " 2364 2366 2396 2406 2407 2409 2421 2439 2444 2445 2450 2455 2459 2462\n",
      " 2469 2513 2526 2527 2581 2583 2591 2611 2614 2624 2639 2647 2651 2652\n",
      " 2676 2682 2690 2707 2708 2714 2743 2760 2762 2769 2770 2788 2805 2806\n",
      " 2811 2814 2817 2820 2837 2839 2854 2864 2869 2876 2878 2890 2898 2910\n",
      " 2911 2937 2942 2945 2951 2984 2987 2990 2996 2997 3010 3011 3023 3048\n",
      " 3075 3078 3082 3086]\n",
      "23 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [   7   10   11   19   21   22   33   53   92   95  103  108  112  135\n",
      "  140  144  146  163  182  194  204  212  216  222  234  238  248  256\n",
      "  297  307  323  330  333  335  336  338  344  347  359  362  373  374\n",
      "  375  381  384  388  439  443  456  499  500  509  521  568  581  584\n",
      "  597  603  609  620  622  629  632  634  663  705  708  711  712  713\n",
      "  732  743  747  763  765  770  778  799  806  807  840  846  856  864\n",
      "  869  874  890  900  905  917  932  944  970  971  993 1012 1020 1029\n",
      " 1046 1050 1084 1086 1100 1112 1123 1145 1147 1154 1162 1165 1175 1220\n",
      " 1246 1247 1248 1265 1267 1285 1288 1306 1313 1338 1339 1346 1347 1363\n",
      " 1373 1383 1400 1404 1429 1432 1441 1450 1453 1466 1475 1483 1490 1495\n",
      " 1513 1514 1517 1519 1525 1539 1554 1558 1563 1569 1572 1573 1576 1587\n",
      " 1612 1613 1616 1619 1626 1635 1647 1651 1655 1661 1668 1673 1677 1683\n",
      " 1702 1708 1713 1731 1732 1734 1750 1756 1762 1764 1768 1774 1784 1804\n",
      " 1814 1823 1827 1835 1846 1855 1892 1895 1896 1900 1922 1923 1946 1950\n",
      " 1955 1964 1979 1988 1994 2019 2037 2049 2052 2062 2065 2072 2076 2082\n",
      " 2085 2100 2113 2115 2117 2119 2122 2157 2171 2174 2184 2186 2190 2204\n",
      " 2210 2237 2247 2248 2249 2250 2268 2280 2282 2302 2323 2339 2343 2360\n",
      " 2371 2375 2392 2398 2408 2412 2418 2448 2457 2463 2465 2470 2475 2476\n",
      " 2485 2501 2528 2529 2545 2561 2580 2588 2596 2610 2631 2642 2643 2648\n",
      " 2654 2665 2674 2684 2691 2701 2703 2709 2711 2718 2765 2774 2787 2797\n",
      " 2798 2802 2815 2819 2823 2826 2833 2840 2846 2868 2871 2895 2901 2928\n",
      " 2933 2947 2948 2968 2986 2988 2991 2998 3019 3026 3042 3052 3074 3080\n",
      " 3087 3090 3106]\n",
      "24 TRAIN: [   0    1    2 ... 3108 3110 3111] TEST: [  12   16   52   58   59   62   83  117  136  157  185  189  205  211\n",
      "  221  239  243  249  260  273  279  287  289  292  303  304  320  331\n",
      "  353  379  387  400  406  408  427  436  444  462  465  467  474  475\n",
      "  489  506  507  511  520  554  588  589  591  611  612  617  643  646\n",
      "  647  653  660  676  686  699  700  730  745  766  768  774  781  795\n",
      "  814  817  820  828  830  843  849  858  866  871  875  879  883  906\n",
      "  914  923  925  933  934  939  941  949  951  967  994  999 1002 1009\n",
      " 1021 1028 1038 1060 1078 1090 1110 1124 1136 1142 1160 1188 1200 1217\n",
      " 1224 1225 1228 1241 1250 1261 1270 1291 1297 1309 1326 1361 1366 1368\n",
      " 1378 1389 1393 1402 1422 1423 1424 1436 1440 1446 1457 1477 1482 1486\n",
      " 1494 1496 1497 1499 1508 1536 1538 1550 1555 1608 1623 1630 1638 1642\n",
      " 1645 1664 1665 1685 1688 1690 1696 1726 1794 1801 1806 1807 1809 1816\n",
      " 1838 1840 1851 1854 1856 1866 1881 1883 1901 1902 1904 1920 1930 1931\n",
      " 1934 1940 1948 2002 2010 2011 2015 2029 2030 2032 2045 2054 2074 2078\n",
      " 2091 2093 2105 2108 2123 2130 2132 2141 2143 2180 2214 2215 2227 2229\n",
      " 2241 2251 2279 2299 2322 2326 2328 2350 2352 2358 2361 2363 2373 2391\n",
      " 2401 2419 2422 2425 2426 2428 2429 2430 2431 2432 2435 2436 2438 2453\n",
      " 2454 2461 2471 2479 2492 2498 2514 2525 2530 2552 2558 2560 2563 2564\n",
      " 2566 2567 2569 2578 2594 2617 2619 2632 2633 2649 2669 2670 2671 2673\n",
      " 2685 2702 2724 2727 2737 2748 2753 2759 2764 2766 2778 2779 2784 2795\n",
      " 2803 2818 2841 2865 2886 2889 2897 2903 2915 2918 2934 2935 2963 2964\n",
      " 2965 2979 2985 3003 3017 3024 3028 3035 3036 3039 3046 3055 3076 3084\n",
      " 3097 3102 3109]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [  17   37   49   57   74   75  101  105  111  113  120  130  149  165\n",
      "  166  168  187  197  219  232  233  252  266  268  285  298  301  310\n",
      "  312  319  322  327  340  355  366  380  385  392  412  429  449  453\n",
      "  460  473  490  496  514  519  527  533  538  541  550  557  575  578\n",
      "  600  605  625  645  648  650  652  672  674  679  682  697  715  718\n",
      "  721  724  725  731  736  738  741  758  769  772  780  790  792  802\n",
      "  808  809  810  811  818  827  832  857  860  878  886  891  904  927\n",
      "  930  940  943  945  961  964  974 1014 1022 1023 1043 1055 1057 1095\n",
      " 1106 1121 1127 1138 1153 1167 1181 1195 1196 1209 1218 1254 1287 1293\n",
      " 1298 1305 1310 1316 1336 1352 1353 1377 1382 1387 1392 1406 1409 1413\n",
      " 1415 1416 1418 1431 1447 1452 1464 1468 1473 1485 1516 1527 1529 1547\n",
      " 1560 1568 1571 1575 1591 1592 1593 1597 1627 1662 1669 1675 1678 1682\n",
      " 1684 1694 1712 1739 1741 1747 1748 1760 1761 1773 1785 1790 1805 1817\n",
      " 1831 1843 1845 1877 1879 1886 1890 1912 1933 1949 1953 1965 1970 1973\n",
      " 1987 1991 2012 2017 2057 2077 2116 2150 2170 2183 2192 2201 2228 2230\n",
      " 2265 2277 2288 2290 2291 2306 2316 2320 2325 2341 2342 2344 2359 2362\n",
      " 2367 2369 2382 2384 2393 2394 2400 2414 2416 2423 2424 2440 2447 2456\n",
      " 2473 2483 2496 2503 2504 2515 2516 2522 2534 2537 2546 2554 2573 2598\n",
      " 2602 2603 2604 2612 2613 2615 2628 2660 2663 2667 2683 2698 2700 2712\n",
      " 2715 2729 2734 2735 2744 2750 2752 2767 2783 2786 2790 2794 2808 2824\n",
      " 2830 2835 2847 2852 2853 2856 2873 2885 2888 2904 2920 2938 2959 2974\n",
      " 2989 2993 3004 3008 3009 3012 3014 3020 3032 3033 3060 3063 3070 3071\n",
      " 3081 3103 3107]\n",
      "26 TRAIN: [   0    1    2 ... 3108 3109 3110] TEST: [   5    6    8    9   30   31   35   38   45   46   66   99  114  139\n",
      "  148  158  160  175  199  207  210  217  235  242  247  259  263  269\n",
      "  270  275  291  296  334  357  361  370  383  389  393  396  411  431\n",
      "  438  448  455  461  485  494  501  505  510  532  536  539  540  548\n",
      "  553  576  594  601  604  613  618  627  628  631  655  661  664  675\n",
      "  677  691  696  704  726  746  748  754  760  762  775  784  787  804\n",
      "  812  822  833  837  841  844  852  862  872  885  887  909  911  928\n",
      "  946  947  977 1000 1001 1005 1035 1044 1049 1051 1052 1081 1092 1096\n",
      " 1097 1107 1113 1116 1122 1126 1129 1132 1148 1194 1197 1222 1232 1235\n",
      " 1238 1239 1240 1243 1252 1253 1266 1272 1280 1284 1294 1308 1322 1325\n",
      " 1333 1348 1349 1354 1356 1360 1365 1369 1379 1395 1411 1414 1417 1430\n",
      " 1438 1444 1448 1456 1471 1481 1515 1518 1521 1528 1557 1559 1561 1564\n",
      " 1594 1600 1603 1615 1629 1631 1636 1648 1652 1660 1670 1679 1689 1707\n",
      " 1717 1718 1719 1721 1742 1745 1765 1779 1788 1793 1795 1799 1833 1849\n",
      " 1852 1859 1862 1864 1874 1888 1918 1921 1937 1938 1939 1957 1967 1974\n",
      " 1975 1977 1980 1982 2008 2025 2028 2036 2039 2046 2047 2073 2087 2110\n",
      " 2127 2136 2146 2151 2158 2167 2168 2169 2189 2191 2193 2200 2207 2209\n",
      " 2240 2261 2264 2269 2278 2303 2307 2335 2336 2340 2377 2379 2380 2386\n",
      " 2387 2390 2397 2403 2443 2452 2474 2490 2493 2520 2536 2542 2559 2571\n",
      " 2607 2618 2620 2627 2634 2646 2666 2687 2688 2689 2694 2742 2751 2776\n",
      " 2780 2801 2807 2810 2825 2831 2845 2850 2877 2880 2882 2907 2930 2943\n",
      " 2982 2995 3002 3007 3013 3021 3030 3047 3053 3054 3056 3059 3061 3079\n",
      " 3093 3105 3111]\n",
      "27 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [  15   20   28   63   65   73   81   86   87   96  102  118  125  127\n",
      "  132  161  162  172  177  180  183  208  209  223  224  226  229  258\n",
      "  280  309  313  317  324  325  337  348  349  350  354  368  394  395\n",
      "  403  417  418  440  470  472  478  492  502  508  513  516  522  531\n",
      "  542  559  564  580  593  602  614  639  640  649  656  659  670  678\n",
      "  680  681  709  710  716  742  749  776  785  813  821  831  834  838\n",
      "  845  868  892  893  907  922  931  954  957  969  987  991 1017 1026\n",
      " 1027 1036 1061 1062 1066 1070 1075 1089 1093 1099 1101 1114 1115 1119\n",
      " 1125 1130 1134 1139 1143 1158 1164 1169 1170 1185 1187 1202 1210 1219\n",
      " 1226 1262 1264 1278 1292 1311 1312 1314 1323 1324 1337 1371 1374 1390\n",
      " 1397 1398 1399 1421 1425 1435 1439 1501 1502 1506 1509 1546 1548 1570\n",
      " 1580 1582 1588 1599 1602 1604 1607 1610 1614 1633 1643 1649 1658 1691\n",
      " 1700 1720 1723 1728 1735 1749 1767 1778 1787 1789 1813 1815 1828 1832\n",
      " 1850 1875 1882 1884 1885 1893 1897 1903 1911 1929 1932 1942 1947 1968\n",
      " 1969 1978 1986 1993 2004 2014 2020 2022 2026 2034 2040 2042 2044 2053\n",
      " 2055 2064 2067 2069 2083 2095 2099 2101 2103 2107 2139 2145 2152 2164\n",
      " 2188 2196 2202 2206 2211 2222 2232 2254 2255 2260 2267 2274 2275 2292\n",
      " 2310 2314 2315 2327 2348 2356 2370 2376 2388 2395 2405 2417 2427 2451\n",
      " 2467 2468 2478 2480 2482 2500 2507 2510 2544 2553 2555 2592 2655 2658\n",
      " 2661 2677 2679 2693 2697 2713 2722 2746 2749 2775 2781 2838 2844 2848\n",
      " 2849 2872 2875 2883 2900 2905 2913 2919 2922 2932 2955 2960 2969 2976\n",
      " 2977 2983 3027 3034 3038 3043 3044 3051 3062 3064 3066 3088 3089 3092\n",
      " 3098 3099 3101]\n",
      "28 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [   4   13   24   25   41   44   48   54   56   61   68   70   79   84\n",
      "   98  104  109  126  138  155  164  181  193  196  203  206  214  218\n",
      "  220  230  231  236  246  250  253  254  255  257  261  276  281  282\n",
      "  288  306  308  314  328  332  342  356  364  372  401  402  413  415\n",
      "  420  422  432  433  434  435  445  452  454  476  503  524  528  529\n",
      "  544  551  560  569  572  574  579  587  595  654  657  662  667  688\n",
      "  693  702  706  722  737  740  744  753  757  759  767  771  777  779\n",
      "  791  797  803  835  848  855  867  877  880  881  897  899  915  926\n",
      "  935  942  953  959  968  982  989  990  997 1007 1008 1013 1015 1016\n",
      " 1040 1042 1053 1063 1065 1080 1131 1137 1140 1151 1166 1168 1176 1184\n",
      " 1191 1192 1193 1201 1204 1211 1216 1227 1233 1236 1244 1255 1260 1273\n",
      " 1274 1281 1282 1320 1332 1334 1345 1362 1381 1385 1388 1394 1396 1401\n",
      " 1419 1437 1443 1467 1484 1489 1491 1492 1510 1520 1533 1540 1553 1556\n",
      " 1565 1574 1609 1624 1625 1628 1656 1659 1687 1701 1729 1733 1743 1755\n",
      " 1769 1781 1796 1812 1822 1834 1844 1847 1848 1860 1868 1876 1917 1927\n",
      " 1961 1966 1992 1997 1998 2003 2006 2021 2051 2058 2063 2084 2089 2102\n",
      " 2135 2137 2142 2156 2187 2194 2198 2238 2246 2253 2257 2287 2301 2305\n",
      " 2337 2347 2355 2383 2402 2437 2441 2446 2477 2484 2486 2487 2502 2509\n",
      " 2512 2523 2533 2539 2543 2547 2551 2557 2572 2574 2597 2623 2636 2638\n",
      " 2662 2678 2686 2696 2720 2725 2726 2730 2731 2739 2745 2747 2761 2763\n",
      " 2768 2785 2792 2799 2800 2804 2822 2843 2855 2863 2867 2891 2893 2894\n",
      " 2909 2912 2917 2940 2956 2971 2999 3037 3045 3058 3067 3068 3073 3085\n",
      " 3096 3104 3108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [  18   26   40   55   67   69   77   85   89   91  100  116  122  134\n",
      "  142  143  147  151  153  154  167  176  179  184  191  198  213  225\n",
      "  237  241  277  283  300  329  343  363  365  377  390  404  407  409\n",
      "  421  426  428  442  459  468  477  479  486  495  497  515  523  530\n",
      "  537  546  547  555  556  558  566  598  608  616  619  630  633  636\n",
      "  638  641  642  665  666  669  694  703  719  723  727  728  729  734\n",
      "  739  751  755  773  786  800  805  815  824  853  859  870  873  882\n",
      "  912  916  919  924  962  985  992  995  996 1025 1031 1032 1037 1067\n",
      " 1069 1074 1094 1108 1117 1135 1141 1152 1157 1163 1172 1177 1203 1206\n",
      " 1214 1215 1242 1269 1271 1296 1299 1302 1329 1331 1341 1357 1359 1364\n",
      " 1375 1403 1405 1410 1420 1427 1433 1459 1461 1465 1480 1503 1532 1535\n",
      " 1537 1545 1549 1552 1577 1579 1584 1586 1590 1598 1601 1674 1680 1705\n",
      " 1716 1738 1744 1751 1757 1759 1763 1777 1797 1798 1829 1839 1842 1853\n",
      " 1865 1878 1898 1913 1926 1935 1936 1952 1959 1971 1983 1989 1995 1996\n",
      " 2016 2027 2043 2079 2086 2104 2120 2121 2126 2131 2134 2140 2148 2154\n",
      " 2161 2166 2177 2179 2216 2223 2234 2244 2259 2263 2276 2283 2300 2312\n",
      " 2313 2317 2321 2329 2334 2349 2351 2354 2385 2399 2404 2415 2460 2489\n",
      " 2491 2494 2497 2506 2508 2511 2524 2556 2562 2565 2570 2576 2582 2584\n",
      " 2586 2587 2599 2600 2605 2608 2626 2630 2635 2641 2645 2656 2668 2675\n",
      " 2680 2704 2717 2719 2728 2771 2772 2773 2777 2782 2791 2813 2829 2832\n",
      " 2834 2858 2859 2860 2870 2874 2884 2902 2908 2914 2923 2924 2927 2936\n",
      " 2949 2953 2961 2975 2978 2992 3000 3001 3005 3006 3022 3050 3057 3065\n",
      " 3077 3091 3094]\n",
      "30 TRAIN: [   0    2    3 ... 3108 3109 3111] TEST: [   1   51   60   64   78   82  115  121  124  128  129  145  156  170\n",
      "  171  178  188  190  192  215  227  228  240  264  272  294  326  339\n",
      "  351  371  378  382  386  391  397  414  425  437  441  446  458  463\n",
      "  469  471  491  498  512  517  534  535  545  549  561  565  573  585\n",
      "  596  607  610  615  687  689  701  707  717  750  752  756  801  819\n",
      "  825  826  839  842  847  861  865  888  894  896  898  901  913  918\n",
      "  920  938  950  966  972  973  976  981  983  984  988  998 1004 1024\n",
      " 1030 1033 1039 1041 1045 1047 1073 1077 1079 1082 1091 1098 1102 1104\n",
      " 1105 1128 1133 1146 1173 1189 1207 1212 1221 1223 1229 1230 1259 1279\n",
      " 1301 1307 1317 1319 1321 1335 1340 1350 1351 1358 1380 1384 1391 1407\n",
      " 1412 1434 1445 1449 1454 1462 1469 1487 1500 1505 1507 1511 1522 1542\n",
      " 1551 1566 1567 1583 1605 1622 1632 1640 1641 1644 1703 1706 1710 1722\n",
      " 1724 1727 1736 1754 1786 1808 1811 1820 1821 1857 1858 1861 1867 1869\n",
      " 1870 1872 1873 1894 1905 1907 1908 1910 1916 1944 1951 1956 1958 1972\n",
      " 1984 1990 2007 2024 2048 2050 2060 2061 2068 2092 2106 2118 2125 2144\n",
      " 2153 2155 2159 2160 2172 2173 2181 2208 2212 2218 2220 2226 2256 2258\n",
      " 2262 2266 2271 2284 2294 2295 2298 2318 2330 2331 2332 2333 2338 2353\n",
      " 2357 2365 2368 2372 2374 2378 2381 2410 2433 2449 2472 2481 2495 2499\n",
      " 2518 2521 2532 2541 2548 2549 2550 2568 2577 2579 2585 2593 2595 2601\n",
      " 2606 2616 2622 2629 2637 2640 2644 2657 2659 2672 2681 2699 2705 2706\n",
      " 2710 2716 2721 2733 2738 2740 2741 2756 2757 2809 2812 2828 2836 2851\n",
      " 2866 2879 2921 2925 2939 2941 2952 2966 2972 2980 2994 3015 3040 3041\n",
      " 3069 3100 3110]\n",
      "31 TRAIN: [   0    2    3 ... 3109 3110 3111] TEST: [   1   21   50   52   72   74   78   82  109  128  149  151  152  167\n",
      "  173  181  200  205  208  218  247  251  261  262  282  289  290  300\n",
      "  320  325  339  345  349  353  354  356  357  365  368  379  385  396\n",
      "  421  425  436  462  475  495  505  506  514  518  522  531  535  538\n",
      "  566  586  610  617  624  627  630  649  653  678  701  717  720  744\n",
      "  747  806  807  811  824  828  834  839  841  872  875  882  893  895\n",
      "  896  903  913  920  927  933  944  950  961  962  977  979  993 1007\n",
      " 1008 1010 1014 1024 1032 1039 1043 1067 1102 1105 1152 1168 1173 1176\n",
      " 1202 1216 1218 1236 1246 1253 1265 1266 1271 1277 1289 1295 1317 1321\n",
      " 1335 1338 1354 1356 1360 1369 1378 1392 1395 1399 1411 1434 1460 1468\n",
      " 1512 1514 1520 1547 1549 1552 1558 1560 1562 1569 1575 1586 1588 1612\n",
      " 1649 1652 1656 1661 1685 1693 1700 1720 1726 1742 1761 1766 1767 1790\n",
      " 1795 1799 1802 1809 1810 1812 1815 1828 1839 1844 1869 1870 1888 1893\n",
      " 1918 1919 1921 1939 1945 1951 1957 2003 2004 2021 2037 2050 2051 2052\n",
      " 2067 2071 2078 2112 2136 2144 2146 2164 2170 2185 2189 2190 2194 2200\n",
      " 2230 2236 2253 2254 2262 2287 2302 2305 2307 2312 2328 2329 2344 2354\n",
      " 2372 2373 2378 2397 2400 2409 2429 2434 2451 2452 2456 2463 2468 2478\n",
      " 2492 2502 2503 2511 2512 2514 2515 2526 2528 2531 2535 2544 2565 2567\n",
      " 2582 2591 2609 2646 2660 2667 2679 2697 2703 2704 2723 2730 2733 2736\n",
      " 2737 2747 2756 2758 2760 2778 2780 2785 2791 2794 2813 2820 2838 2839\n",
      " 2841 2843 2844 2846 2859 2897 2904 2913 2915 2920 2927 2933 2945 2959\n",
      " 2973 2977 2995 2998 3015 3017 3030 3044 3046 3062 3064 3067 3079 3081\n",
      " 3085 3089 3091 3106]\n",
      "32 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [   5    8   15   20   33   47   49   57   70   83   99  102  103  112\n",
      "  113  115  135  160  168  176  182  183  185  195  197  198  199  221\n",
      "  238  240  250  260  283  284  285  293  304  311  314  333  344  351\n",
      "  360  369  378  391  404  413  429  431  434  450  457  486  511  517\n",
      "  523  525  547  555  561  575  614  628  635  647  662  666  693  699\n",
      "  724  743  749  766  787  789  800  805  821  826  842  845  850  858\n",
      "  861  877  884  894  907  918  931  937  938  942  943  967  970  975\n",
      "  978 1002 1015 1022 1030 1033 1051 1059 1064 1066 1077 1081 1089 1107\n",
      " 1114 1120 1126 1141 1142 1143 1153 1155 1157 1163 1171 1197 1229 1243\n",
      " 1252 1261 1262 1267 1290 1302 1309 1313 1326 1333 1350 1367 1373 1380\n",
      " 1381 1386 1397 1402 1407 1408 1412 1413 1431 1439 1441 1452 1453 1482\n",
      " 1484 1517 1518 1521 1531 1534 1554 1571 1600 1605 1615 1621 1622 1626\n",
      " 1636 1696 1705 1713 1714 1732 1747 1769 1770 1787 1817 1824 1825 1830\n",
      " 1834 1837 1857 1890 1899 1928 1929 1930 1933 1948 1966 1973 1976 1977\n",
      " 1978 1989 1995 2010 2017 2036 2042 2043 2055 2057 2060 2062 2069 2083\n",
      " 2118 2129 2149 2163 2172 2187 2188 2193 2196 2205 2206 2213 2216 2229\n",
      " 2237 2240 2249 2256 2257 2277 2284 2298 2301 2314 2316 2317 2325 2340\n",
      " 2342 2355 2357 2358 2389 2401 2414 2425 2439 2448 2465 2470 2471 2472\n",
      " 2484 2499 2518 2534 2536 2559 2571 2572 2595 2604 2614 2641 2652 2666\n",
      " 2668 2669 2680 2683 2716 2732 2772 2788 2818 2823 2835 2852 2863 2869\n",
      " 2874 2879 2885 2888 2896 2909 2910 2921 2940 2943 2951 2954 2969 2975\n",
      " 2984 2986 2989 2990 2991 2997 3009 3010 3025 3028 3036 3038 3048 3053\n",
      " 3061 3084 3095 3108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [  19   26   27   34   44   59   62   64   68   77   95   97  101  110\n",
      "  118  119  129  155  164  184  192  219  223  235  241  249  263  305\n",
      "  313  321  327  334  362  373  393  406  424  440  447  452  468  470\n",
      "  473  487  521  533  534  550  554  593  597  602  611  612  613  644\n",
      "  654  657  659  670  677  685  692  695  728  741  748  751  753  759\n",
      "  763  772  776  788  801  813  816  860  905  926  946  951  953  955\n",
      "  972  980  999 1003 1016 1029 1053 1065 1072 1073 1078 1080 1085 1086\n",
      " 1101 1121 1127 1129 1150 1172 1174 1178 1185 1208 1213 1224 1225 1226\n",
      " 1251 1270 1282 1304 1308 1311 1314 1318 1325 1327 1328 1337 1358 1366\n",
      " 1385 1422 1429 1435 1442 1447 1449 1457 1475 1478 1483 1500 1528 1541\n",
      " 1567 1579 1581 1583 1599 1616 1623 1632 1647 1653 1655 1662 1664 1665\n",
      " 1680 1697 1701 1735 1738 1753 1759 1765 1783 1791 1797 1798 1808 1820\n",
      " 1849 1876 1894 1913 1916 1920 1923 1927 1947 1950 1954 1961 1967 1970\n",
      " 1982 1984 1990 1993 1997 1999 2000 2001 2007 2029 2032 2048 2058 2061\n",
      " 2064 2076 2084 2087 2093 2098 2119 2122 2123 2128 2137 2141 2145 2147\n",
      " 2156 2159 2166 2179 2182 2183 2184 2195 2202 2208 2210 2228 2235 2251\n",
      " 2264 2269 2273 2297 2334 2336 2337 2345 2362 2385 2391 2395 2410 2412\n",
      " 2415 2417 2435 2444 2445 2454 2462 2464 2473 2479 2483 2485 2489 2490\n",
      " 2500 2501 2517 2522 2527 2548 2549 2550 2558 2562 2574 2579 2592 2594\n",
      " 2599 2603 2610 2621 2622 2642 2659 2672 2699 2712 2734 2742 2754 2762\n",
      " 2763 2787 2790 2803 2809 2817 2826 2854 2857 2858 2867 2891 2895 2911\n",
      " 2918 2925 2932 2946 2947 2950 2955 2962 2974 2976 2978 2979 3003 3004\n",
      " 3037 3054 3105]\n",
      "34 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [   4   14   31   36   38   39   56   67   98  107  114  130  133  136\n",
      "  139  156  163  169  177  214  217  226  230  231  237  245  276  279\n",
      "  299  303  308  322  336  338  342  346  347  370  371  374  377  397\n",
      "  403  405  417  418  420  422  423  461  474  476  483  499  510  524\n",
      "  551  553  558  564  570  571  572  573  580  583  587  607  609  648\n",
      "  668  673  681  698  700  703  706  725  726  732  736  754  779  784\n",
      "  812  814  820  848  856  867  874  876  919  932  935  936  940  948\n",
      "  954  971  983 1005 1006 1018 1028 1037 1047 1068 1104 1108 1117 1131\n",
      " 1132 1134 1139 1140 1166 1175 1182 1191 1200 1201 1209 1217 1221 1235\n",
      " 1237 1238 1256 1260 1263 1293 1305 1310 1322 1332 1346 1351 1353 1355\n",
      " 1364 1365 1370 1383 1414 1416 1433 1445 1491 1492 1508 1516 1530 1546\n",
      " 1553 1557 1577 1580 1582 1602 1609 1611 1619 1630 1634 1638 1641 1650\n",
      " 1659 1667 1669 1674 1683 1684 1687 1689 1704 1706 1723 1730 1743 1744\n",
      " 1768 1793 1807 1819 1827 1841 1846 1853 1858 1864 1878 1897 1898 1908\n",
      " 1910 1931 1946 1949 1953 1968 1981 1998 2002 2026 2027 2054 2063 2066\n",
      " 2074 2077 2095 2099 2105 2109 2125 2127 2143 2154 2171 2173 2201 2218\n",
      " 2222 2226 2248 2259 2268 2270 2278 2281 2319 2327 2380 2387 2420 2427\n",
      " 2430 2441 2446 2461 2467 2469 2476 2482 2494 2496 2504 2525 2530 2533\n",
      " 2537 2539 2551 2561 2564 2602 2631 2645 2649 2650 2658 2663 2671 2674\n",
      " 2677 2681 2688 2711 2718 2719 2724 2727 2740 2751 2765 2769 2786 2805\n",
      " 2812 2827 2837 2845 2848 2855 2860 2866 2881 2887 2893 2901 2931 2939\n",
      " 2952 2966 2972 2996 3006 3008 3012 3019 3024 3039 3041 3059 3066 3071\n",
      " 3077 3090 3099]\n",
      "35 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [  25   41   53   58   61   65   73   85   92  120  144  158  170  174\n",
      "  175  180  190  210  248  255  257  264  281  291  292  312  317  318\n",
      "  330  331  340  341  343  359  389  392  398  400  402  408  445  453\n",
      "  454  459  464  479  484  507  508  519  536  545  562  569  579  581\n",
      "  582  585  592  594  596  604  606  619  631  634  637  650  651  691\n",
      "  722  723  750  752  757  764  770  785  802  817  818  819  822  823\n",
      "  830  833  846  862  863  871  880  885  888  890  900  908  914  949\n",
      "  959  968  996 1017 1021 1023 1035 1048 1052 1055 1057 1058 1084 1091\n",
      " 1092 1098 1116 1122 1135 1151 1188 1203 1205 1210 1231 1239 1250 1274\n",
      " 1275 1285 1288 1297 1300 1320 1323 1324 1342 1347 1349 1363 1368 1372\n",
      " 1377 1390 1394 1396 1401 1415 1421 1427 1430 1437 1438 1466 1470 1474\n",
      " 1476 1496 1498 1519 1522 1527 1532 1539 1555 1563 1565 1570 1574 1593\n",
      " 1595 1617 1618 1627 1629 1639 1668 1678 1679 1688 1722 1740 1757 1760\n",
      " 1764 1786 1788 1823 1838 1850 1852 1875 1877 1887 1895 1902 1903 1912\n",
      " 1917 1925 1926 1940 1944 1955 1958 1959 1974 1992 2008 2009 2018 2034\n",
      " 2038 2068 2081 2089 2092 2101 2113 2131 2132 2138 2150 2160 2175 2197\n",
      " 2198 2203 2207 2209 2212 2217 2219 2225 2232 2238 2241 2246 2266 2267\n",
      " 2272 2276 2290 2294 2303 2313 2318 2320 2323 2330 2343 2349 2352 2364\n",
      " 2366 2371 2376 2381 2388 2407 2408 2413 2449 2488 2507 2510 2519 2523\n",
      " 2545 2553 2554 2570 2617 2620 2623 2628 2657 2661 2690 2705 2717 2729\n",
      " 2745 2746 2755 2793 2795 2796 2800 2804 2816 2821 2822 2847 2853 2856\n",
      " 2862 2882 2884 2906 2917 2919 2957 2970 2971 2981 2993 3014 3018 3043\n",
      " 3055 3063 3100]\n",
      "36 TRAIN: [   0    1    2 ... 3108 3109 3110] TEST: [   7   28   35   63   94  124  126  127  134  145  150  157  161  162\n",
      "  171  189  193  194  196  201  211  220  234  242  254  268  275  278\n",
      "  296  307  348  355  363  366  367  395  399  410  412  427  428  438\n",
      "  448  449  465  477  482  490  493  504  513  530  537  542  543  589\n",
      "  608  618  622  638  640  641  642  645  658  660  664  665  669  675\n",
      "  682  696  704  708  715  727  731  733  739  755  756  758  771  778\n",
      "  790  799  835  837  854  855  868  878  889  898  902  912  915  922\n",
      "  925  930  958  965  969  974  994 1013 1027 1044 1049 1061 1090 1094\n",
      " 1111 1115 1118 1119 1128 1133 1138 1165 1196 1219 1223 1228 1255 1264\n",
      " 1272 1286 1287 1307 1316 1334 1382 1384 1393 1417 1418 1432 1456 1459\n",
      " 1479 1480 1487 1489 1493 1497 1504 1507 1513 1524 1525 1537 1545 1564\n",
      " 1608 1614 1625 1628 1643 1657 1670 1675 1692 1707 1719 1727 1729 1739\n",
      " 1752 1763 1771 1781 1784 1801 1813 1829 1833 1840 1847 1856 1861 1880\n",
      " 1900 1922 1924 1935 1964 1983 1991 2006 2012 2013 2020 2023 2039 2044\n",
      " 2049 2073 2085 2102 2115 2124 2126 2151 2152 2165 2177 2192 2211 2215\n",
      " 2220 2244 2252 2261 2280 2283 2300 2306 2309 2310 2321 2322 2331 2333\n",
      " 2339 2351 2356 2359 2363 2365 2367 2368 2374 2392 2394 2398 2405 2418\n",
      " 2432 2442 2447 2486 2487 2491 2508 2509 2529 2538 2566 2577 2588 2601\n",
      " 2607 2612 2613 2615 2616 2629 2633 2635 2636 2639 2656 2662 2686 2687\n",
      " 2694 2702 2721 2722 2726 2744 2748 2750 2767 2770 2779 2789 2811 2814\n",
      " 2831 2836 2840 2849 2851 2865 2870 2871 2907 2926 2935 2963 2988 3007\n",
      " 3022 3023 3027 3035 3040 3050 3051 3058 3060 3068 3070 3078 3080 3086\n",
      " 3088 3107 3111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 TRAIN: [   1    2    3 ... 3108 3110 3111] TEST: [   0   17   18   23   24   30   43   86   89  137  142  153  154  159\n",
      "  178  187  209  216  224  232  233  253  258  259  265  266  287  297\n",
      "  301  302  306  319  329  390  414  426  430  437  443  444  455  480\n",
      "  485  501  502  516  526  528  529  532  539  540  541  546  552  577\n",
      "  578  591  601  621  626  672  674  676  683  684  686  694  702  705\n",
      "  716  719  738  740  761  768  775  781  792  795  796  810  827  829\n",
      "  844  866  883  887  899  921  934  960  982  985  989 1004 1020 1041\n",
      " 1045 1050 1063 1079 1082 1083 1093 1100 1109 1124 1130 1144 1147 1148\n",
      " 1160 1164 1167 1170 1192 1198 1211 1234 1258 1268 1273 1279 1292 1319\n",
      " 1329 1331 1339 1340 1341 1371 1376 1387 1400 1404 1420 1424 1425 1436\n",
      " 1443 1448 1455 1462 1464 1472 1473 1477 1490 1501 1511 1526 1538 1540\n",
      " 1542 1548 1573 1590 1601 1606 1633 1640 1646 1671 1681 1686 1698 1699\n",
      " 1702 1709 1711 1728 1737 1755 1780 1804 1826 1831 1836 1859 1866 1867\n",
      " 1868 1883 1886 1892 1906 1914 1915 1934 1938 1941 1960 1963 1965 1969\n",
      " 1971 1985 1988 1994 1996 2014 2016 2019 2065 2070 2082 2088 2090 2094\n",
      " 2097 2100 2103 2106 2117 2139 2142 2148 2155 2157 2161 2167 2174 2180\n",
      " 2221 2227 2274 2275 2285 2348 2350 2361 2369 2382 2383 2390 2416 2433\n",
      " 2459 2466 2475 2498 2505 2520 2532 2547 2552 2569 2573 2581 2583 2589\n",
      " 2593 2596 2600 2608 2611 2618 2619 2655 2676 2684 2685 2691 2693 2696\n",
      " 2707 2708 2710 2735 2738 2753 2757 2771 2775 2783 2797 2799 2801 2802\n",
      " 2806 2807 2808 2829 2833 2842 2861 2864 2868 2876 2898 2900 2902 2924\n",
      " 2937 2944 2953 2956 3011 3020 3021 3031 3032 3042 3047 3069 3076 3098\n",
      " 3101 3104 3109]\n",
      "38 TRAIN: [   0    1    2 ... 3108 3109 3111] TEST: [   3    6   11   22   46   51   54   66   79   80   84   88   96  121\n",
      "  131  143  165  166  172  188  207  212  215  272  274  310  332  376\n",
      "  380  383  386  387  407  415  439  451  456  458  466  469  471  478\n",
      "  488  494  500  503  512  527  556  563  565  588  590  598  599  615\n",
      "  632  633  656  667  679  687  689  690  710  721  746  765  769  774\n",
      "  777  783  798  809  825  831  832  840  852  864  891  897  911  916\n",
      "  917  928  929  945  952  956  964  988  991  992  995  998 1001 1011\n",
      " 1031 1040 1042 1056 1060 1062 1095 1110 1113 1123 1136 1145 1146 1149\n",
      " 1161 1169 1177 1184 1187 1189 1194 1207 1220 1241 1249 1254 1281 1283\n",
      " 1298 1301 1345 1348 1361 1406 1410 1419 1444 1446 1450 1461 1463 1471\n",
      " 1485 1494 1495 1502 1523 1529 1535 1536 1544 1556 1566 1568 1576 1585\n",
      " 1589 1592 1594 1604 1620 1631 1635 1642 1644 1651 1663 1672 1676 1694\n",
      " 1708 1716 1718 1724 1756 1762 1773 1779 1782 1794 1796 1803 1805 1811\n",
      " 1848 1851 1860 1871 1872 1873 1881 1882 1904 1905 1909 1932 1937 1972\n",
      " 1980 1986 1987 2011 2022 2024 2028 2030 2033 2041 2046 2075 2080 2086\n",
      " 2091 2114 2134 2153 2168 2176 2181 2223 2231 2233 2239 2242 2247 2250\n",
      " 2263 2271 2279 2282 2288 2289 2292 2295 2299 2304 2308 2324 2332 2341\n",
      " 2347 2375 2384 2386 2419 2422 2424 2426 2436 2438 2443 2450 2453 2455\n",
      " 2474 2477 2493 2495 2521 2524 2540 2541 2543 2556 2560 2563 2575 2578\n",
      " 2634 2664 2673 2682 2713 2714 2728 2739 2741 2743 2761 2774 2777 2815\n",
      " 2824 2830 2834 2875 2880 2889 2890 2894 2899 2903 2905 2912 2914 2923\n",
      " 2936 2942 2948 2985 2999 3000 3013 3026 3029 3033 3045 3049 3052 3087\n",
      " 3093 3102 3110]\n",
      "39 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [  16   29   37   45   55   69   81   87   90  106  111  116  117  122\n",
      "  123  138  140  148  179  186  191  202  206  213  225  229  236  239\n",
      "  243  246  273  277  286  295  315  324  326  335  350  352  358  364\n",
      "  381  382  384  394  409  411  419  432  433  441  460  467  472  481\n",
      "  489  491  492  497  509  515  549  567  568  576  600  603  625  636\n",
      "  639  643  646  671  680  697  707  709  711  712  713  729  734  737\n",
      "  760  773  782  786  791  793  797  803  804  808  838  843  847  859\n",
      "  865  870  879  881  886  901  904  906  910  924  963  966  976  986\n",
      "  990  997 1000 1009 1025 1036 1046 1069 1071 1074 1087 1088 1096 1097\n",
      " 1103 1106 1137 1179 1180 1183 1186 1193 1204 1212 1222 1227 1233 1240\n",
      " 1242 1245 1248 1257 1276 1284 1296 1303 1352 1357 1359 1362 1389 1440\n",
      " 1454 1458 1467 1481 1499 1503 1505 1509 1551 1559 1561 1572 1578 1584\n",
      " 1591 1596 1597 1603 1607 1613 1624 1637 1654 1658 1673 1682 1690 1691\n",
      " 1710 1712 1715 1717 1731 1733 1734 1749 1751 1754 1758 1785 1792 1800\n",
      " 1818 1822 1832 1845 1855 1862 1879 1884 1891 1896 1901 1911 1936 1942\n",
      " 1943 1952 1975 1979 2005 2025 2035 2040 2047 2053 2059 2072 2079 2096\n",
      " 2107 2108 2116 2133 2162 2178 2186 2214 2245 2255 2258 2265 2286 2291\n",
      " 2315 2335 2346 2360 2370 2377 2403 2404 2406 2421 2423 2437 2460 2480\n",
      " 2506 2513 2546 2557 2576 2580 2585 2586 2590 2597 2606 2630 2632 2637\n",
      " 2638 2640 2643 2644 2648 2654 2665 2692 2701 2706 2720 2725 2766 2776\n",
      " 2781 2792 2798 2819 2828 2832 2850 2878 2886 2892 2908 2930 2941 2949\n",
      " 2958 2961 2965 2980 2982 2992 3016 3034 3056 3057 3065 3072 3074 3082\n",
      " 3083 3096 3097]\n",
      "40 TRAIN: [   0    1    3 ... 3109 3110 3111] TEST: [   2    9   10   12   13   32   40   42   48   60   71   75   76   91\n",
      "   93  100  104  105  108  125  132  141  146  147  203  204  222  227\n",
      "  228  244  252  256  267  269  270  271  280  288  294  298  309  316\n",
      "  323  328  337  361  372  375  388  401  416  435  442  446  463  496\n",
      "  498  520  544  548  557  559  560  574  584  595  605  616  620  623\n",
      "  629  652  655  661  663  688  714  718  730  735  742  745  762  767\n",
      "  780  794  815  836  849  851  853  857  869  873  892  909  923  939\n",
      "  941  947  957  973  981  984  987 1012 1019 1026 1034 1038 1054 1070\n",
      " 1075 1076 1099 1112 1125 1154 1156 1158 1159 1162 1181 1190 1195 1199\n",
      " 1206 1214 1215 1230 1232 1244 1247 1259 1269 1278 1280 1291 1294 1299\n",
      " 1306 1312 1315 1330 1336 1343 1344 1374 1375 1379 1388 1391 1398 1403\n",
      " 1405 1409 1423 1426 1428 1451 1465 1469 1486 1488 1506 1510 1515 1533\n",
      " 1543 1550 1587 1598 1610 1645 1648 1660 1666 1677 1695 1703 1721 1725\n",
      " 1736 1741 1745 1746 1748 1750 1772 1774 1775 1776 1777 1778 1789 1806\n",
      " 1814 1816 1821 1835 1842 1843 1854 1863 1865 1874 1885 1889 1907 1956\n",
      " 1962 2015 2031 2045 2056 2104 2110 2111 2120 2121 2130 2135 2140 2158\n",
      " 2169 2191 2199 2204 2224 2234 2243 2260 2293 2296 2311 2326 2338 2353\n",
      " 2379 2393 2396 2399 2402 2411 2428 2431 2440 2457 2458 2481 2497 2516\n",
      " 2542 2555 2568 2584 2587 2598 2605 2624 2625 2626 2627 2647 2651 2653\n",
      " 2670 2675 2678 2689 2695 2698 2700 2709 2715 2731 2749 2752 2759 2764\n",
      " 2768 2773 2782 2784 2810 2825 2872 2873 2877 2883 2916 2922 2928 2929\n",
      " 2934 2938 2960 2964 2967 2968 2983 2987 2994 3001 3002 3005 3073 3075\n",
      " 3092 3094 3103]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [   3    6   19   44   47   53   60   76   87   88   93   97  102  123\n",
      "  130  136  149  162  186  196  204  224  228  231  237  250  254  256\n",
      "  265  267  282  284  290  291  318  321  322  323  346  357  361  380\n",
      "  391  400  409  416  417  426  432  447  454  456  460  478  490  545\n",
      "  566  576  584  603  616  623  630  649  654  655  656  657  660  661\n",
      "  662  667  670  671  675  686  700  710  711  720  726  733  734  737\n",
      "  759  840  876  880  884  893  921  939  952  957  964  968  980  982\n",
      "  988  990 1008 1009 1021 1063 1087 1092 1103 1107 1112 1123 1130 1142\n",
      " 1144 1148 1167 1179 1205 1208 1209 1229 1240 1241 1244 1266 1276 1283\n",
      " 1287 1293 1297 1307 1312 1332 1340 1350 1353 1375 1383 1394 1403 1413\n",
      " 1425 1434 1444 1456 1457 1462 1473 1504 1509 1519 1551 1552 1556 1566\n",
      " 1568 1572 1574 1590 1594 1596 1601 1609 1617 1639 1650 1652 1653 1655\n",
      " 1666 1686 1689 1691 1706 1728 1733 1754 1770 1796 1800 1802 1812 1819\n",
      " 1837 1850 1855 1859 1875 1894 1899 1928 1933 1949 1955 1966 1983 1996\n",
      " 2008 2013 2034 2042 2066 2069 2070 2072 2080 2092 2105 2126 2130 2137\n",
      " 2139 2149 2169 2187 2188 2189 2198 2199 2208 2209 2219 2236 2241 2254\n",
      " 2281 2283 2287 2289 2297 2298 2323 2328 2333 2346 2359 2373 2375 2395\n",
      " 2404 2417 2435 2439 2448 2451 2477 2498 2515 2527 2530 2541 2546 2554\n",
      " 2564 2573 2592 2595 2607 2616 2618 2633 2636 2643 2653 2658 2668 2672\n",
      " 2675 2678 2679 2680 2689 2693 2714 2743 2761 2768 2771 2774 2776 2791\n",
      " 2816 2818 2832 2834 2847 2875 2880 2892 2894 2904 2917 2926 2941 2949\n",
      " 2957 2973 2981 2989 2996 2998 3001 3006 3013 3017 3025 3053 3056 3059\n",
      " 3077 3093 3102 3103]\n",
      "42 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [  18   21   59   75   85  101  109  118  129  139  144  145  150  163\n",
      "  165  169  189  205  210  225  238  241  249  251  253  258  297  298\n",
      "  304  320  340  342  351  352  355  372  381  383  386  387  403  419\n",
      "  424  450  459  476  481  484  486  489  495  502  504  512  532  533\n",
      "  537  539  550  574  581  588  599  601  602  606  621  629  635  636\n",
      "  647  664  677  690  695  729  736  741  751  762  783  826  828  841\n",
      "  853  861  878  882  887  888  918  920  950  959  967  977  978  989\n",
      "  995 1010 1020 1025 1030 1052 1058 1064 1074 1077 1090 1108 1119 1127\n",
      " 1146 1150 1153 1181 1194 1201 1211 1220 1221 1246 1247 1267 1269 1275\n",
      " 1277 1280 1288 1291 1302 1308 1315 1316 1334 1342 1374 1376 1378 1386\n",
      " 1389 1397 1416 1418 1419 1430 1431 1463 1470 1505 1511 1535 1539 1555\n",
      " 1589 1591 1624 1637 1640 1648 1651 1654 1657 1661 1680 1700 1701 1704\n",
      " 1710 1724 1737 1738 1750 1757 1760 1762 1767 1798 1806 1815 1826 1835\n",
      " 1845 1852 1864 1870 1879 1897 1898 1900 1907 1909 1920 1935 1937 1965\n",
      " 1972 1982 1991 1999 2001 2025 2026 2067 2099 2101 2152 2155 2162 2165\n",
      " 2177 2182 2185 2191 2217 2221 2222 2227 2229 2242 2246 2251 2258 2266\n",
      " 2275 2290 2294 2299 2303 2309 2313 2321 2331 2337 2349 2368 2379 2383\n",
      " 2399 2412 2413 2414 2416 2420 2432 2436 2455 2465 2470 2493 2506 2510\n",
      " 2511 2513 2516 2545 2578 2583 2586 2600 2602 2619 2644 2648 2649 2654\n",
      " 2655 2660 2670 2686 2694 2760 2772 2782 2790 2793 2812 2819 2822 2835\n",
      " 2837 2842 2843 2849 2853 2854 2855 2867 2870 2890 2907 2914 2918 2919\n",
      " 2929 2940 2950 2956 2964 2983 2994 3000 3002 3008 3029 3032 3035 3058\n",
      " 3064 3067 3075 3089]\n",
      "43 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [  10   17   30   54   57   69   72   82   96   99  116  126  127  128\n",
      "  140  152  156  171  194  202  207  209  211  213  222  227  240  242\n",
      "  246  260  274  277  280  300  305  307  308  312  314  317  330  332\n",
      "  349  397  398  401  411  412  415  418  423  425  435  451  458  466\n",
      "  469  471  479  482  485  498  505  514  518  522  523  526  527  529\n",
      "  531  562  573  604  610  640  653  659  673  678  687  703  708  713\n",
      "  728  735  757  765  777  781  782  785  788  795  802  804  816  832\n",
      "  834  847  849  862  902  906  907  917  935  956  969  972  976  991\n",
      " 1001 1016 1034 1035 1048 1067 1069 1072 1095 1099 1105 1116 1136 1137\n",
      " 1140 1156 1161 1162 1163 1166 1183 1215 1223 1230 1235 1252 1256 1258\n",
      " 1271 1272 1273 1298 1310 1311 1339 1354 1357 1364 1382 1393 1411 1435\n",
      " 1437 1453 1464 1468 1472 1476 1481 1501 1506 1512 1533 1537 1540 1545\n",
      " 1557 1570 1580 1581 1593 1613 1627 1630 1660 1683 1692 1702 1708 1709\n",
      " 1712 1716 1721 1730 1736 1761 1769 1774 1779 1783 1805 1808 1827 1834\n",
      " 1840 1863 1876 1887 1889 1890 1895 1906 1908 1926 1958 1970 1989 2002\n",
      " 2006 2009 2017 2027 2033 2036 2041 2059 2074 2077 2079 2090 2102 2103\n",
      " 2106 2141 2144 2145 2148 2166 2168 2170 2175 2184 2224 2244 2247 2261\n",
      " 2271 2274 2286 2348 2361 2362 2363 2364 2365 2367 2382 2386 2418 2437\n",
      " 2441 2449 2475 2482 2542 2555 2576 2580 2591 2603 2611 2614 2627 2635\n",
      " 2637 2659 2663 2682 2683 2708 2711 2713 2722 2726 2731 2732 2733 2734\n",
      " 2755 2765 2775 2781 2799 2801 2807 2844 2852 2858 2860 2863 2869 2891\n",
      " 2893 2912 2936 2953 2955 2965 2969 2971 2999 3011 3014 3016 3019 3030\n",
      " 3040 3052 3108]\n",
      "44 TRAIN: [   0    1    2 ... 3108 3110 3111] TEST: [   9   16   23   36   42   84   91  100  117  153  166  176  177  191\n",
      "  198  212  215  229  233  235  261  263  272  288  293  295  299  310\n",
      "  338  339  341  344  365  371  376  379  384  414  420  428  430  442\n",
      "  444  448  473  511  515  519  542  543  548  551  552  563  571  575\n",
      "  582  614  624  638  646  676  684  688  691  697  701  704  709  712\n",
      "  716  738  756  761  779  789  796  797  801  807  813  822  837  856\n",
      "  858  864  865  873  904  913  914  923  937  948  958  963  981  987\n",
      " 1006 1012 1039 1042 1044 1049 1053 1056 1071 1113 1129 1135 1158 1164\n",
      " 1165 1168 1189 1193 1199 1210 1213 1219 1226 1228 1233 1234 1239 1261\n",
      " 1281 1294 1305 1322 1338 1343 1346 1355 1358 1370 1372 1373 1388 1407\n",
      " 1415 1422 1423 1426 1429 1436 1441 1443 1460 1475 1478 1488 1490 1492\n",
      " 1493 1510 1518 1532 1534 1538 1547 1554 1575 1577 1582 1584 1600 1635\n",
      " 1636 1658 1668 1669 1714 1715 1720 1726 1734 1735 1739 1742 1771 1776\n",
      " 1781 1782 1794 1804 1807 1809 1813 1830 1843 1853 1860 1862 1903 1916\n",
      " 1918 1929 1938 1941 1950 1962 1963 1980 1984 1997 2014 2021 2040 2044\n",
      " 2045 2046 2048 2052 2054 2073 2075 2085 2086 2095 2104 2110 2114 2118\n",
      " 2131 2140 2146 2150 2154 2157 2171 2197 2200 2211 2214 2226 2231 2232\n",
      " 2248 2272 2277 2278 2279 2291 2307 2317 2318 2319 2357 2370 2394 2403\n",
      " 2410 2431 2438 2445 2446 2458 2461 2509 2518 2520 2523 2524 2525 2532\n",
      " 2534 2551 2556 2572 2574 2593 2604 2610 2617 2620 2638 2641 2642 2657\n",
      " 2687 2692 2700 2728 2729 2738 2739 2742 2756 2762 2769 2795 2828 2829\n",
      " 2840 2897 2899 2902 2909 2910 2944 2947 2961 2963 3010 3033 3038 3082\n",
      " 3099 3107 3109]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 TRAIN: [   0    1    2 ... 3108 3109 3111] TEST: [   4    5    8   14   25   32   39   50   67   68   86   90   98  108\n",
      "  112  119  168  183  185  190  192  203  219  223  243  255  266  269\n",
      "  285  286  296  316  350  353  358  366  389  421  422  429  431  434\n",
      "  445  461  477  480  487  491  499  507  509  525  536  549  553  561\n",
      "  564  565  569  587  595  597  598  609  619  645  652  669  672  680\n",
      "  681  682  694  699  719  743  744  760  778  792  803  810  821  827\n",
      "  835  836  839  842  844  874  879  897  903  916  930  931  932  936\n",
      "  938  979  998 1004 1005 1011 1015 1022 1023 1046 1061 1066 1078 1082\n",
      " 1086 1101 1115 1125 1145 1157 1159 1172 1176 1177 1185 1190 1236 1249\n",
      " 1263 1268 1270 1282 1330 1337 1362 1366 1367 1369 1371 1387 1402 1404\n",
      " 1417 1450 1477 1486 1495 1496 1502 1514 1515 1522 1530 1560 1569 1587\n",
      " 1632 1633 1638 1649 1659 1664 1665 1674 1678 1688 1693 1695 1705 1719\n",
      " 1727 1729 1731 1748 1751 1768 1784 1785 1788 1797 1799 1820 1823 1829\n",
      " 1831 1833 1836 1838 1847 1873 1874 1892 1901 1917 1921 1925 1927 1930\n",
      " 1931 1934 1967 1969 1978 1981 1988 1993 2018 2035 2068 2088 2107 2109\n",
      " 2113 2119 2120 2122 2136 2143 2147 2156 2160 2172 2176 2202 2204 2220\n",
      " 2223 2235 2259 2267 2270 2284 2292 2296 2308 2315 2334 2339 2352 2354\n",
      " 2356 2372 2408 2428 2433 2434 2440 2447 2464 2466 2471 2486 2497 2504\n",
      " 2507 2533 2539 2544 2568 2569 2571 2584 2601 2605 2608 2609 2622 2629\n",
      " 2630 2632 2656 2662 2684 2695 2696 2698 2702 2703 2704 2744 2747 2751\n",
      " 2752 2758 2773 2789 2800 2804 2813 2814 2821 2846 2866 2896 2906 2925\n",
      " 2938 2975 2977 2985 3004 3009 3028 3037 3049 3050 3054 3061 3065 3066\n",
      " 3074 3078 3110]\n",
      "46 TRAIN: [   0    2    3 ... 3109 3110 3111] TEST: [   1   22   27   38   40   46   51   52   55   64   78   94  103  104\n",
      "  105  115  122  124  134  138  147  154  179  180  197  200  221  230\n",
      "  232  259  264  292  362  363  368  373  378  406  436  439  441  446\n",
      "  449  452  463  468  474  488  513  534  540  557  559  560  583  596\n",
      "  617  631  650  689  707  714  727  740  750  753  755  758  764  767\n",
      "  775  784  818  833  838  850  854  855  860  885  890  895  924  925\n",
      "  927  940  945  947  955  984  985  992 1003 1036 1038 1041 1051 1097\n",
      " 1120 1121 1122 1128 1131 1147 1154 1171 1180 1192 1200 1207 1225 1245\n",
      " 1255 1259 1264 1274 1285 1286 1306 1320 1323 1326 1328 1335 1336 1349\n",
      " 1365 1398 1406 1424 1448 1455 1458 1459 1461 1480 1485 1489 1499 1520\n",
      " 1524 1536 1544 1548 1550 1571 1586 1597 1599 1606 1616 1618 1628 1634\n",
      " 1682 1684 1690 1694 1696 1698 1699 1713 1752 1763 1801 1818 1821 1825\n",
      " 1861 1867 1883 1919 1944 1948 1960 1971 1974 1985 1987 1995 2003 2007\n",
      " 2023 2028 2038 2039 2064 2065 2071 2083 2084 2096 2108 2115 2117 2121\n",
      " 2127 2129 2135 2142 2163 2183 2186 2192 2205 2207 2216 2234 2238 2250\n",
      " 2255 2263 2264 2268 2282 2285 2301 2305 2360 2376 2388 2390 2393 2401\n",
      " 2405 2453 2456 2459 2463 2480 2484 2488 2494 2495 2496 2501 2549 2561\n",
      " 2563 2566 2575 2590 2623 2640 2645 2646 2647 2667 2671 2676 2677 2697\n",
      " 2715 2716 2718 2719 2720 2723 2724 2730 2736 2737 2741 2745 2759 2766\n",
      " 2779 2780 2796 2797 2798 2808 2817 2831 2836 2839 2850 2857 2859 2868\n",
      " 2876 2883 2884 2886 2887 2889 2913 2921 2935 2968 2974 2991 2992 2995\n",
      " 2997 3003 3012 3015 3020 3021 3022 3043 3047 3069 3071 3080 3083 3086\n",
      " 3098 3101 3105]\n",
      "47 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [  13   28   31   33   37   41   58   71   77   79   80  107  120  121\n",
      "  146  157  160  161  178  182  188  193  199  201  218  226  239  244\n",
      "  257  262  268  270  273  289  294  301  311  327  334  337  343  345\n",
      "  347  360  375  385  393  395  405  410  438  462  464  467  470  472\n",
      "  517  554  556  568  577  580  591  608  622  634  644  674  693  715\n",
      "  718  723  725  732  742  752  754  790  794  798  805  814  817  851\n",
      "  870  883  889  892  901  911  919  929  941  986  994  997 1007 1024\n",
      " 1037 1045 1047 1054 1062 1076 1084 1100 1104 1106 1110 1118 1134 1139\n",
      " 1174 1175 1182 1184 1196 1202 1206 1212 1231 1243 1248 1254 1257 1279\n",
      " 1290 1303 1325 1329 1331 1333 1344 1352 1377 1384 1395 1401 1412 1439\n",
      " 1442 1446 1452 1479 1494 1517 1563 1576 1603 1610 1611 1619 1629 1643\n",
      " 1644 1671 1676 1679 1697 1703 1717 1722 1741 1747 1749 1755 1766 1791\n",
      " 1824 1841 1846 1865 1871 1872 1877 1880 1884 1905 1910 1913 1915 1936\n",
      " 1939 1946 1968 1975 1976 1992 1994 2000 2011 2015 2047 2055 2062 2081\n",
      " 2087 2093 2111 2124 2132 2134 2158 2173 2174 2180 2190 2194 2195 2239\n",
      " 2245 2273 2311 2324 2325 2327 2338 2340 2345 2358 2371 2378 2381 2384\n",
      " 2387 2392 2396 2400 2407 2411 2421 2427 2450 2454 2467 2472 2491 2492\n",
      " 2503 2508 2514 2535 2540 2543 2577 2579 2581 2585 2588 2594 2598 2625\n",
      " 2626 2634 2651 2652 2664 2685 2688 2690 2699 2706 2707 2709 2717 2721\n",
      " 2727 2740 2750 2753 2754 2777 2778 2785 2792 2805 2806 2810 2826 2833\n",
      " 2848 2856 2861 2865 2878 2882 2895 2903 2920 2924 2928 2932 2933 2937\n",
      " 2939 2942 2945 2967 2990 2993 3005 3023 3046 3048 3055 3063 3084 3085\n",
      " 3087 3094 3097]\n",
      "48 TRAIN: [   1    2    3 ... 3109 3110 3111] TEST: [   0   12   20   34   43   45   49   62   63   65   89  106  125  141\n",
      "  151  164  172  173  174  181  195  214  216  275  279  283  287  319\n",
      "  326  329  331  333  335  336  348  374  382  392  394  396  399  402\n",
      "  453  455  457  493  494  496  500  506  510  546  572  594  607  625\n",
      "  627  628  639  641  643  651  663  705  721  731  745  746  749  772\n",
      "  773  774  791  793  799  825  829  831  852  871  886  891  898  899\n",
      "  908  909  915  933  934  953  961  965  973  974  999 1000 1014 1019\n",
      " 1026 1029 1040 1050 1055 1059 1060 1075 1079 1080 1094 1096 1098 1102\n",
      " 1126 1170 1188 1195 1217 1218 1224 1227 1232 1250 1251 1265 1284 1292\n",
      " 1300 1301 1304 1321 1345 1356 1363 1396 1399 1408 1410 1414 1420 1421\n",
      " 1427 1433 1449 1454 1465 1471 1474 1484 1508 1521 1526 1527 1528 1531\n",
      " 1541 1561 1562 1565 1573 1578 1585 1598 1602 1614 1615 1621 1625 1641\n",
      " 1645 1662 1667 1675 1718 1732 1740 1758 1759 1778 1787 1792 1795 1803\n",
      " 1810 1814 1816 1842 1848 1856 1857 1866 1869 1896 1911 1912 1914 1942\n",
      " 1943 1954 1956 1957 1959 1977 2005 2020 2024 2030 2031 2043 2050 2056\n",
      " 2057 2061 2076 2097 2098 2100 2123 2133 2164 2196 2210 2213 2225 2230\n",
      " 2237 2249 2252 2253 2257 2262 2269 2288 2293 2300 2302 2304 2314 2322\n",
      " 2330 2332 2342 2343 2344 2347 2353 2355 2366 2374 2377 2380 2385 2462\n",
      " 2468 2476 2481 2485 2487 2499 2500 2502 2505 2528 2553 2557 2565 2582\n",
      " 2589 2621 2624 2639 2665 2681 2712 2725 2783 2784 2794 2803 2815 2820\n",
      " 2838 2841 2845 2864 2871 2872 2879 2881 2888 2923 2927 2934 2958 2959\n",
      " 2962 2966 2970 2972 2976 2978 3027 3034 3044 3057 3060 3070 3081 3088\n",
      " 3091 3100 3106]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 TRAIN: [   0    1    2 ... 3109 3110 3111] TEST: [   7   11   26   29   48   61   70   73   74   81  131  132  137  155\n",
      "  159  170  175  187  236  248  252  302  309  313  315  328  370  377\n",
      "  388  404  407  413  437  443  475  492  497  508  516  520  530  547\n",
      "  555  558  570  578  586  589  590  593  605  612  613  618  632  633\n",
      "  637  668  679  683  696  702  724  747  763  766  769  770  776  780\n",
      "  800  806  808  811  812  815  824  843  848  857  859  867  869  877\n",
      "  894  896  905  926  942  943  960  962  970  983  993  996 1013 1017\n",
      " 1018 1032 1033 1068 1070 1081 1088 1091 1111 1114 1117 1132 1143 1149\n",
      " 1155 1169 1173 1178 1186 1187 1191 1198 1203 1214 1216 1222 1253 1260\n",
      " 1262 1289 1295 1299 1309 1313 1317 1318 1319 1324 1327 1347 1359 1361\n",
      " 1368 1379 1380 1381 1385 1390 1391 1392 1405 1409 1428 1432 1451 1469\n",
      " 1491 1497 1500 1503 1513 1516 1523 1525 1542 1543 1546 1553 1558 1564\n",
      " 1567 1579 1583 1592 1595 1612 1620 1622 1623 1626 1670 1672 1673 1707\n",
      " 1743 1744 1745 1773 1777 1780 1786 1789 1790 1793 1811 1817 1822 1828\n",
      " 1839 1844 1849 1878 1885 1886 1888 1893 1904 1923 1940 1947 1953 1973\n",
      " 1979 1986 1990 2004 2016 2022 2032 2037 2049 2051 2053 2063 2078 2125\n",
      " 2128 2138 2159 2161 2193 2201 2206 2212 2228 2233 2256 2260 2312 2316\n",
      " 2326 2336 2351 2391 2397 2406 2415 2422 2423 2424 2425 2429 2457 2469\n",
      " 2473 2512 2517 2521 2522 2529 2547 2550 2552 2558 2599 2613 2628 2650\n",
      " 2661 2673 2674 2701 2710 2746 2748 2757 2763 2767 2770 2788 2802 2824\n",
      " 2830 2862 2873 2874 2877 2900 2908 2915 2916 2922 2930 2946 2948 2952\n",
      " 2960 2982 2984 2987 2988 3007 3018 3024 3026 3039 3042 3045 3051 3090\n",
      " 3092 3096 3104]\n",
      "50 TRAIN: [   0    1    3 ... 3108 3109 3110] TEST: [   2   15   24   35   56   66   83   92   95  110  111  113  114  133\n",
      "  135  142  143  148  158  167  184  206  208  217  220  234  245  247\n",
      "  271  276  278  281  303  306  324  325  354  356  359  364  367  369\n",
      "  390  408  427  433  440  465  483  501  503  521  524  528  535  538\n",
      "  541  544  567  579  585  592  600  611  615  620  626  642  648  658\n",
      "  665  666  685  692  698  706  717  722  730  739  748  768  771  786\n",
      "  787  809  819  820  823  830  845  846  863  866  868  872  875  881\n",
      "  900  910  912  922  928  944  946  949  951  954  966  971  975 1002\n",
      " 1027 1028 1031 1043 1057 1065 1073 1083 1085 1089 1093 1109 1124 1133\n",
      " 1138 1141 1151 1152 1160 1197 1204 1237 1238 1242 1278 1296 1314 1341\n",
      " 1348 1351 1360 1400 1438 1440 1445 1447 1466 1467 1482 1483 1487 1498\n",
      " 1507 1529 1549 1559 1588 1604 1605 1607 1608 1631 1642 1646 1647 1656\n",
      " 1663 1677 1681 1685 1687 1711 1723 1725 1746 1753 1756 1764 1765 1772\n",
      " 1775 1832 1851 1854 1858 1868 1881 1882 1891 1902 1922 1924 1932 1945\n",
      " 1951 1952 1961 1964 1998 2010 2012 2019 2029 2058 2060 2082 2089 2091\n",
      " 2094 2112 2116 2151 2153 2167 2178 2179 2181 2203 2215 2218 2240 2243\n",
      " 2265 2276 2280 2295 2306 2310 2320 2329 2335 2341 2350 2369 2389 2398\n",
      " 2402 2409 2419 2426 2430 2442 2443 2444 2452 2460 2474 2478 2479 2483\n",
      " 2489 2490 2519 2526 2531 2536 2537 2538 2548 2559 2560 2562 2567 2570\n",
      " 2587 2596 2597 2606 2612 2615 2631 2666 2669 2691 2705 2735 2749 2764\n",
      " 2786 2787 2809 2811 2823 2825 2827 2851 2885 2898 2901 2905 2911 2931\n",
      " 2943 2951 2954 2979 2980 2986 3031 3036 3041 3062 3068 3072 3073 3076\n",
      " 3079 3095 3111]\n",
      "In-Sample AUC: 0.5551641873897212\n",
      "MeanCV AUC: 0.551185550334636\n",
      "Standard Deviation CV AUC: 0.030348111299971444\n",
      "Non-zero coefficients: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:25: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
      "/var/folders/y0/1x_8r5js5_z6xvnv37zjwr6r0000gn/T/ipykernel_59613/1802922695.py:36: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  AUC_out.to_csv(f\"data/{name}_AUCs.txt\", sep='\\t',index=False, line_terminator='\\n')\n"
     ]
    }
   ],
   "source": [
    "name = \"all\"\n",
    "AUCs = list()\n",
    "bp = grid_lr.best_params_\n",
    "rkf = RepeatedKFold(n_splits=10, n_repeats=5, random_state=42)\n",
    "clf = LogisticRegression(C=bp['C'], max_iter=bp['max_iter'], l1_ratio=bp['l1_ratio'], random_state=42,\n",
    "      solver='saga', n_jobs=-1, penalty='elasticnet')\n",
    "\n",
    "count = 0\n",
    "for train_index, test_index in rkf.split(X):\n",
    "    count = count + 1\n",
    "    print(count, \"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    AUCs.append(auc)\n",
    "\n",
    "    X_header = np.array(X_train.columns)\n",
    "    data_array = np.vstack((X_header, clf.coef_[0,:]))\n",
    "    model_weights = pd.DataFrame(data=data_array.T,columns=['SNP', 'Coefficient'])\n",
    "    m_name = f'data/{name}_10fold_repeat{count}_coefficients.txt'\n",
    "    model_weights.to_csv(m_name, sep='\\t',index=False, line_terminator='\\n')\n",
    "\n",
    "# Fit predictor to statistically significant features (just once!!!)\n",
    "clf.fit(X, Y)\n",
    "y_pred = clf.predict_proba(X)[:,1]\n",
    "\n",
    "# This in-sample AUC should be better than the AUCs from the repeated cross-validation\n",
    "auc = roc_auc_score(Y, y_pred)\n",
    "\n",
    "#AUC results from the 50 predictors\n",
    "AUC_out = pd.DataFrame(AUCs, columns=['AUC'])\n",
    "AUC_out.to_csv(f\"data/{name}_AUCs.txt\", sep='\\t',index=False, line_terminator='\\n')\n",
    "\n",
    "AUC_std= st.stdev(AUCs)\n",
    "AUC_mean= st.mean(AUCs)\n",
    "\n",
    "num_coef = np.sum(clf.coef_[0,:] != 0)\n",
    "print(f'In-Sample AUC: {auc}')\n",
    "print(f'MeanCV AUC: {AUC_mean}')\n",
    "print(f'Standard Deviation CV AUC: {AUC_std}')\n",
    "print(f'Non-zero coefficients: {num_coef}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fb8634",
   "metadata": {},
   "source": [
    "## Males\n",
    "\n",
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "452e22c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phenotype\n",
       "0    989\n",
       "1    989\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1 = table[table.gender == \"M\"]\n",
    "X = table1[table1.columns[5:]]\n",
    "Y = table1['phenotype']\n",
    "lr = LogisticRegression(random_state=42, solver='saga', n_jobs=-1, penalty='elasticnet')\n",
    "table1.groupby('phenotype')['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b03c41d",
   "metadata": {},
   "source": [
    "### Grid search for 3 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "138ed48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.02], &#x27;l1_ratio&#x27;: [0.2, 0.1],\n",
       "                         &#x27;max_iter&#x27;: [75, 100, 150]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.02], &#x27;l1_ratio&#x27;: [0.2, 0.1],\n",
       "                         &#x27;max_iter&#x27;: [75, 100, 150]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                          random_state=42, solver='saga'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.02], 'l1_ratio': [0.2, 0.1],\n",
       "                         'max_iter': [75, 100, 150]},\n",
       "             scoring='roc_auc', verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {'C': [0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 1, 10, 20, 30],\n",
    "#               'max_iter': [10, 25, 50, 75, 100, 150, 200, 400, 800, 1600],\n",
    "#               'l1_ratio': [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]}\n",
    "\n",
    "parameters = {'C': [0.01, 0.02],\n",
    "              'max_iter': [75, 100, 150],\n",
    "              'l1_ratio': [0.2, 0.1]}\n",
    "\n",
    "grid_lr = GridSearchCV(lr, parameters, verbose=False, scoring='roc_auc', n_jobs=-1, cv=10)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "grid_lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3137e415",
   "metadata": {},
   "source": [
    "### Best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a99971ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max AUC score:0.6243225531401534\n",
      "\n",
      "Non-zero coefficients: 37\n",
      "\n",
      "Best estimator: LogisticRegression(C=0.01, l1_ratio=0.1, n_jobs=-1, penalty='elasticnet',\n",
      "                   random_state=42, solver='saga')\n",
      "Scorer: make_scorer(roc_auc_score, needs_threshold=True)\n",
      "Best params: {'C': 0.01, 'l1_ratio': 0.1, 'max_iter': 100}\n",
      "Best score: 0.5620659282996945\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs7520918</td>\n",
       "      <td>-0.10687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs112270735</td>\n",
       "      <td>-0.077184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs444618</td>\n",
       "      <td>-0.054004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs13161496</td>\n",
       "      <td>-0.044109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rs3733349</td>\n",
       "      <td>-0.035941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rs3785891</td>\n",
       "      <td>-0.022054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rs494312</td>\n",
       "      <td>-0.015573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rs62190394</td>\n",
       "      <td>-0.008948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rs12995314</td>\n",
       "      <td>-0.00536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rs72838312</td>\n",
       "      <td>-0.004366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rs142448570</td>\n",
       "      <td>-0.00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rs74609071</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rs4028634</td>\n",
       "      <td>0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rs17016235</td>\n",
       "      <td>0.00292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rs1501467</td>\n",
       "      <td>0.006768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rs7682766</td>\n",
       "      <td>0.007628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rs6532190</td>\n",
       "      <td>0.010966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rs379066</td>\n",
       "      <td>0.015095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rs2412116</td>\n",
       "      <td>0.015274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rs5848</td>\n",
       "      <td>0.015471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rs764324</td>\n",
       "      <td>0.01817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rs11601088</td>\n",
       "      <td>0.019219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rs10110312</td>\n",
       "      <td>0.028269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rs4897753</td>\n",
       "      <td>0.029363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rs6599389</td>\n",
       "      <td>0.03295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rs11097213</td>\n",
       "      <td>0.036052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rs3822023</td>\n",
       "      <td>0.041542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rs79828056</td>\n",
       "      <td>0.046307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rs1372420</td>\n",
       "      <td>0.051416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rs11264302</td>\n",
       "      <td>0.057684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rs10831599</td>\n",
       "      <td>0.065901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rs12434297</td>\n",
       "      <td>0.068324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rs9985581</td>\n",
       "      <td>0.070506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>rs6842271</td>\n",
       "      <td>0.077488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>rs12935995</td>\n",
       "      <td>0.079672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>rs11248057</td>\n",
       "      <td>0.080207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>rs3806760</td>\n",
       "      <td>0.147021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SNP Coefficient\n",
       "Index                         \n",
       "1        rs7520918    -0.10687\n",
       "2      rs112270735   -0.077184\n",
       "3         rs444618   -0.054004\n",
       "4       rs13161496   -0.044109\n",
       "5        rs3733349   -0.035941\n",
       "6        rs3785891   -0.022054\n",
       "7         rs494312   -0.015573\n",
       "8       rs62190394   -0.008948\n",
       "9       rs12995314    -0.00536\n",
       "10      rs72838312   -0.004366\n",
       "11     rs142448570    -0.00037\n",
       "12      rs74609071    0.000361\n",
       "13       rs4028634      0.0029\n",
       "14      rs17016235     0.00292\n",
       "15       rs1501467    0.006768\n",
       "16       rs7682766    0.007628\n",
       "17       rs6532190    0.010966\n",
       "18        rs379066    0.015095\n",
       "19       rs2412116    0.015274\n",
       "20          rs5848    0.015471\n",
       "21        rs764324     0.01817\n",
       "22      rs11601088    0.019219\n",
       "23      rs10110312    0.028269\n",
       "24       rs4897753    0.029363\n",
       "25       rs6599389     0.03295\n",
       "26      rs11097213    0.036052\n",
       "27       rs3822023    0.041542\n",
       "28      rs79828056    0.046307\n",
       "29       rs1372420    0.051416\n",
       "30      rs11264302    0.057684\n",
       "31      rs10831599    0.065901\n",
       "32      rs12434297    0.068324\n",
       "33       rs9985581    0.070506\n",
       "34       rs6842271    0.077488\n",
       "35      rs12935995    0.079672\n",
       "36      rs11248057    0.080207\n",
       "37       rs3806760    0.147021"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "max_auc_score = roc_auc_score(Y, best_lr.predict_proba(X)[:, 1])\n",
    "coefs = best_lr.coef_[0, :]\n",
    "num_coef = np.sum(coefs != 0)\n",
    "X_header = np.array(X.columns)\n",
    "\n",
    "data_array = np.vstack((X_header, coefs))\n",
    "model_coefs = pd.DataFrame(data=data_array.T, columns=['SNP', 'Coefficient'])\n",
    "print(f'Max AUC score:{max_auc_score}\\n')\n",
    "print(f'Non-zero coefficients: {num_coef}\\n')\n",
    "print(f'Best estimator: {grid_lr.best_estimator_}')\n",
    "print(f'Scorer: {grid_lr.scorer_}')\n",
    "print(f'Best params: {grid_lr.best_params_}')\n",
    "print(f'Best score: {grid_lr.best_score_}\\n')\n",
    "m = model_coefs[model_coefs['Coefficient'] != 0 ].sort_values(by='Coefficient')\n",
    "m = m.reset_index(drop=True).assign(Index=range(len(m)))\n",
    "m.Index= m.Index + 1\n",
    "m.set_index('Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ea506",
   "metadata": {},
   "source": [
    "## Females\n",
    "\n",
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58d178c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phenotype\n",
       "0    567\n",
       "1    567\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1 = table[table.gender == \"F\"]\n",
    "X = table1[table1.columns[5:]]\n",
    "Y = table1['phenotype']\n",
    "lr = LogisticRegression(random_state=42, solver='saga', n_jobs=-1, penalty='elasticnet')\n",
    "table1.groupby('phenotype')['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3996d08f",
   "metadata": {},
   "source": [
    "### Grid search for 3 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c26faf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.005, 0.01], &#x27;l1_ratio&#x27;: [0.1, 0.2],\n",
       "                         &#x27;max_iter&#x27;: [25, 50, 75]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.005, 0.01], &#x27;l1_ratio&#x27;: [0.1, 0.2],\n",
       "                         &#x27;max_iter&#x27;: [25, 50, 75]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                          random_state=42, solver='saga'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.005, 0.01], 'l1_ratio': [0.1, 0.2],\n",
       "                         'max_iter': [25, 50, 75]},\n",
       "             scoring='roc_auc', verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {'C': [0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 1, 10, 20, 30],\n",
    "#              'max_iter': [10, 25, 50, 75, 100, 150, 200, 400, 800, 1600],\n",
    "#              'l1_ratio': [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]}\n",
    "\n",
    "parameters = {'C': [0.005, 0.01],\n",
    "              'max_iter': [25, 50, 75],\n",
    "              'l1_ratio': [0.1, 0.2]}\n",
    "\n",
    "grid_lr = GridSearchCV(lr, parameters, verbose=False, scoring='roc_auc', n_jobs=-1, cv=10)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "grid_lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409085c4",
   "metadata": {},
   "source": [
    "### Best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af1705e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max AUC score:0.56756840825036\n",
      "\n",
      "Non-zero coefficients: 6\n",
      "\n",
      "Best estimator: LogisticRegression(C=0.005, l1_ratio=0.1, max_iter=50, n_jobs=-1,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga')\n",
      "Scorer: make_scorer(roc_auc_score, needs_threshold=True)\n",
      "Best params: {'C': 0.005, 'l1_ratio': 0.1, 'max_iter': 50}\n",
      "Best score: 0.5115738908675196\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs6871718</td>\n",
       "      <td>-0.026889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs1949362</td>\n",
       "      <td>-0.023602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs6964</td>\n",
       "      <td>0.005616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs11248057</td>\n",
       "      <td>0.005966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rs3850379</td>\n",
       "      <td>0.008878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rs3806760</td>\n",
       "      <td>0.016905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SNP Coefficient\n",
       "Index                        \n",
       "1       rs6871718   -0.026889\n",
       "2       rs1949362   -0.023602\n",
       "3          rs6964    0.005616\n",
       "4      rs11248057    0.005966\n",
       "5       rs3850379    0.008878\n",
       "6       rs3806760    0.016905"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "max_auc_score = roc_auc_score(Y, best_lr.predict_proba(X)[:, 1])\n",
    "coefs = best_lr.coef_[0, :]\n",
    "num_coef = np.sum(coefs != 0)\n",
    "X_header = np.array(X.columns)\n",
    "\n",
    "data_array = np.vstack((X_header, coefs))\n",
    "model_coefs = pd.DataFrame(data=data_array.T, columns=['SNP', 'Coefficient'])\n",
    "print(f'Max AUC score:{max_auc_score}\\n')\n",
    "print(f'Non-zero coefficients: {num_coef}\\n')\n",
    "print(f'Best estimator: {grid_lr.best_estimator_}')\n",
    "print(f'Scorer: {grid_lr.scorer_}')\n",
    "print(f'Best params: {grid_lr.best_params_}')\n",
    "print(f'Best score: {grid_lr.best_score_}\\n')\n",
    "m = model_coefs[model_coefs['Coefficient'] != 0 ].sort_values(by='Coefficient')\n",
    "m = m.reset_index(drop=True).assign(Index=range(len(m)))\n",
    "m.Index= m.Index + 1\n",
    "m.set_index('Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb368ecf",
   "metadata": {},
   "source": [
    "## NN\n",
    "\n",
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1b37b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phenotype\n",
       "0    304\n",
       "1    338\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1 = table[table.inv_genotype==\"NN\"]\n",
    "X = table1[table1.columns[5:]]\n",
    "Y = table1['phenotype']\n",
    "lr = LogisticRegression(random_state=42, solver='saga', n_jobs=-1, penalty='elasticnet')\n",
    "table1.groupby('phenotype')['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847aecf3",
   "metadata": {},
   "source": [
    "### Grid search for 3 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb22ab8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.02, 0.05], &#x27;l1_ratio&#x27;: [0.5, 0.4, 0.3],\n",
       "                         &#x27;max_iter&#x27;: [10, 25]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.02, 0.05], &#x27;l1_ratio&#x27;: [0.5, 0.4, 0.3],\n",
       "                         &#x27;max_iter&#x27;: [10, 25]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                          random_state=42, solver='saga'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.02, 0.05], 'l1_ratio': [0.5, 0.4, 0.3],\n",
       "                         'max_iter': [10, 25]},\n",
       "             scoring='roc_auc', verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {'C': [0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 1, 10, 20, 30],\n",
    "#              'max_iter': [10, 25, 50, 75, 100, 150, 200, 400, 800, 1600],\n",
    "#              'l1_ratio': [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]}\n",
    "\n",
    "parameters = {'C': [0.01, 0.02, 0.05],\n",
    "              'max_iter': [10, 25],\n",
    "              'l1_ratio': [0.5, 0.4, 0.3]}\n",
    "\n",
    "grid_lr = GridSearchCV(lr, parameters, verbose=False, scoring='roc_auc', n_jobs=-1, cv=10)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "grid_lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1cdf8e",
   "metadata": {},
   "source": [
    "### Best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbe6c057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max AUC score:0.609418794767985\n",
      "\n",
      "Non-zero coefficients: 9\n",
      "\n",
      "Best estimator: LogisticRegression(C=0.02, l1_ratio=0.3, max_iter=10, n_jobs=-1,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga')\n",
      "Scorer: make_scorer(roc_auc_score, needs_threshold=True)\n",
      "Best params: {'C': 0.02, 'l1_ratio': 0.3, 'max_iter': 10}\n",
      "Best score: 0.5288828992007361\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs7826007</td>\n",
       "      <td>-0.013424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs4897753</td>\n",
       "      <td>0.001234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs3822023</td>\n",
       "      <td>0.005838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs6842271</td>\n",
       "      <td>0.010758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rs12434297</td>\n",
       "      <td>0.012576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rs6964</td>\n",
       "      <td>0.014571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rs9985581</td>\n",
       "      <td>0.020144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rs3806760</td>\n",
       "      <td>0.031815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rs11248057</td>\n",
       "      <td>0.106701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SNP Coefficient\n",
       "Index                        \n",
       "1       rs7826007   -0.013424\n",
       "2       rs4897753    0.001234\n",
       "3       rs3822023    0.005838\n",
       "4       rs6842271    0.010758\n",
       "5      rs12434297    0.012576\n",
       "6          rs6964    0.014571\n",
       "7       rs9985581    0.020144\n",
       "8       rs3806760    0.031815\n",
       "9      rs11248057    0.106701"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "max_auc_score = roc_auc_score(Y, best_lr.predict_proba(X)[:, 1])\n",
    "coefs = best_lr.coef_[0, :]\n",
    "num_coef = np.sum(coefs != 0)\n",
    "X_header = np.array(X.columns)\n",
    "\n",
    "data_array = np.vstack((X_header, coefs))\n",
    "model_coefs = pd.DataFrame(data=data_array.T, columns=['SNP', 'Coefficient'])\n",
    "print(f'Max AUC score:{max_auc_score}\\n')\n",
    "print(f'Non-zero coefficients: {num_coef}\\n')\n",
    "print(f'Best estimator: {grid_lr.best_estimator_}')\n",
    "print(f'Scorer: {grid_lr.scorer_}')\n",
    "print(f'Best params: {grid_lr.best_params_}')\n",
    "print(f'Best score: {grid_lr.best_score_}\\n')\n",
    "m = model_coefs[model_coefs['Coefficient'] != 0 ].sort_values(by='Coefficient')\n",
    "m = m.reset_index(drop=True).assign(Index=range(len(m)))\n",
    "m.Index= m.Index + 1\n",
    "m.set_index('Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f697917",
   "metadata": {},
   "source": [
    "## NI\n",
    "\n",
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3b5e9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phenotype\n",
       "0    739\n",
       "1    747\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1 = table[table.inv_genotype==\"NI\"]\n",
    "X = table1[table1.columns[5:]]\n",
    "Y = table1['phenotype']\n",
    "lr = LogisticRegression(random_state=42, solver='saga', n_jobs=-1, penalty='elasticnet')\n",
    "table1.groupby('phenotype')['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6141ffd",
   "metadata": {},
   "source": [
    "### Grid search for 3 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "041a63ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.005, 0.01], &#x27;l1_ratio&#x27;: [0.2, 0.1],\n",
       "                         &#x27;max_iter&#x27;: [10, 25, 50]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.005, 0.01], &#x27;l1_ratio&#x27;: [0.2, 0.1],\n",
       "                         &#x27;max_iter&#x27;: [10, 25, 50]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                          random_state=42, solver='saga'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.005, 0.01], 'l1_ratio': [0.2, 0.1],\n",
       "                         'max_iter': [10, 25, 50]},\n",
       "             scoring='roc_auc', verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {'C': [0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 1, 10, 20, 30],\n",
    "#               'max_iter': [10, 25, 50, 75, 100, 150, 200, 400, 800, 1600],\n",
    "#               'l1_ratio': [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]}\n",
    "\n",
    "parameters = {'C': [0.005, 0.01],\n",
    "              'max_iter': [10, 25, 50],\n",
    "              'l1_ratio': [0.2, 0.1]}\n",
    "\n",
    "grid_lr = GridSearchCV(lr, parameters, verbose=False, scoring='roc_auc', n_jobs=-1, cv=10)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "grid_lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e71338",
   "metadata": {},
   "source": [
    "### Best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed611403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max AUC score:0.5796736789286148\n",
      "\n",
      "Non-zero coefficients: 8\n",
      "\n",
      "Best estimator: LogisticRegression(C=0.01, l1_ratio=0.2, max_iter=10, n_jobs=-1,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga')\n",
      "Scorer: make_scorer(roc_auc_score, needs_threshold=True)\n",
      "Best params: {'C': 0.01, 'l1_ratio': 0.2, 'max_iter': 10}\n",
      "Best score: 0.5327258606255274\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs7520918</td>\n",
       "      <td>-0.045971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs1949362</td>\n",
       "      <td>-0.017297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs6532190</td>\n",
       "      <td>0.008321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs17016235</td>\n",
       "      <td>0.00924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rs6842271</td>\n",
       "      <td>0.023003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rs9985581</td>\n",
       "      <td>0.03514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rs7682766</td>\n",
       "      <td>0.036363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rs3806760</td>\n",
       "      <td>0.047802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SNP Coefficient\n",
       "Index                        \n",
       "1       rs7520918   -0.045971\n",
       "2       rs1949362   -0.017297\n",
       "3       rs6532190    0.008321\n",
       "4      rs17016235     0.00924\n",
       "5       rs6842271    0.023003\n",
       "6       rs9985581     0.03514\n",
       "7       rs7682766    0.036363\n",
       "8       rs3806760    0.047802"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "max_auc_score = roc_auc_score(Y, best_lr.predict_proba(X)[:, 1])\n",
    "coefs = best_lr.coef_[0, :]\n",
    "num_coef = np.sum(coefs != 0)\n",
    "X_header = np.array(X.columns)\n",
    "\n",
    "data_array = np.vstack((X_header, coefs))\n",
    "model_coefs = pd.DataFrame(data=data_array.T, columns=['SNP', 'Coefficient'])\n",
    "print(f'Max AUC score:{max_auc_score}\\n')\n",
    "print(f'Non-zero coefficients: {num_coef}\\n')\n",
    "print(f'Best estimator: {grid_lr.best_estimator_}')\n",
    "print(f'Scorer: {grid_lr.scorer_}')\n",
    "print(f'Best params: {grid_lr.best_params_}')\n",
    "print(f'Best score: {grid_lr.best_score_}\\n')\n",
    "m = model_coefs[model_coefs['Coefficient'] != 0 ].sort_values(by='Coefficient')\n",
    "m = m.reset_index(drop=True).assign(Index=range(len(m)))\n",
    "m.Index= m.Index + 1\n",
    "m.set_index('Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b5d34",
   "metadata": {},
   "source": [
    "## II\n",
    "\n",
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "978219df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phenotype\n",
       "0    513\n",
       "1    471\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1 = table[table.inv_genotype==\"II\"]\n",
    "X = table1[table1.columns[5:]]\n",
    "Y = table1['phenotype']\n",
    "lr = LogisticRegression(random_state=42, solver='saga', n_jobs=-1, penalty='elasticnet')\n",
    "table1.groupby('phenotype')['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7e20a",
   "metadata": {},
   "source": [
    "### Grid search for 3 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "561baea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.005, 0.01, 0.02], &#x27;l1_ratio&#x27;: [0.2, 0.1],\n",
       "                         &#x27;max_iter&#x27;: [50, 100, 200]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.005, 0.01, 0.02], &#x27;l1_ratio&#x27;: [0.2, 0.1],\n",
       "                         &#x27;max_iter&#x27;: [50, 100, 200]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                          random_state=42, solver='saga'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.005, 0.01, 0.02], 'l1_ratio': [0.2, 0.1],\n",
       "                         'max_iter': [50, 100, 200]},\n",
       "             scoring='roc_auc', verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {'C': [0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 1, 10, 20, 30],\n",
    "#               'max_iter': [10, 25, 50, 75, 100, 150, 200, 400, 800, 1600],\n",
    "#               'l1_ratio': [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]}\n",
    "\n",
    "parameters = {'C': [0.005, 0.01, 0.02],\n",
    "              'max_iter': [50, 100, 200],\n",
    "              'l1_ratio': [0.2, 0.1]}\n",
    "\n",
    "grid_lr = GridSearchCV(lr, parameters, verbose=False, scoring='roc_auc', n_jobs=-1, cv=10)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "grid_lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c34429f",
   "metadata": {},
   "source": [
    "### Best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de0de7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max AUC score:0.6603758748132421\n",
      "\n",
      "Non-zero coefficients: 26\n",
      "\n",
      "Best estimator: LogisticRegression(C=0.01, l1_ratio=0.1, n_jobs=-1, penalty='elasticnet',\n",
      "                   random_state=42, solver='saga')\n",
      "Scorer: make_scorer(roc_auc_score, needs_threshold=True)\n",
      "Best params: {'C': 0.01, 'l1_ratio': 0.1, 'max_iter': 100}\n",
      "Best score: 0.5940495196987687\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs34333</td>\n",
       "      <td>-0.057329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs494312</td>\n",
       "      <td>-0.05673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs3733349</td>\n",
       "      <td>-0.055571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs6871718</td>\n",
       "      <td>-0.051304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rs444618</td>\n",
       "      <td>-0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rs1736103</td>\n",
       "      <td>-0.031732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rs7535292</td>\n",
       "      <td>-0.026481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rs13161496</td>\n",
       "      <td>-0.016119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rs4331494</td>\n",
       "      <td>-0.004139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rs34992950</td>\n",
       "      <td>-0.003211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rs12510869</td>\n",
       "      <td>-0.000945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rs2412116</td>\n",
       "      <td>0.001716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rs2410595</td>\n",
       "      <td>0.003706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rs4859611</td>\n",
       "      <td>0.014846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rs112318363</td>\n",
       "      <td>0.015892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rs379066</td>\n",
       "      <td>0.019658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rs13188899</td>\n",
       "      <td>0.030844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rs12935995</td>\n",
       "      <td>0.03166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rs231454</td>\n",
       "      <td>0.036038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rs3822023</td>\n",
       "      <td>0.043356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rs11097213</td>\n",
       "      <td>0.059403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rs11248057</td>\n",
       "      <td>0.077958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rs12434297</td>\n",
       "      <td>0.094157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rs11264302</td>\n",
       "      <td>0.095165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rs3806760</td>\n",
       "      <td>0.114488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rs5848</td>\n",
       "      <td>0.126228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SNP Coefficient\n",
       "Index                         \n",
       "1          rs34333   -0.057329\n",
       "2         rs494312    -0.05673\n",
       "3        rs3733349   -0.055571\n",
       "4        rs6871718   -0.051304\n",
       "5         rs444618   -0.032258\n",
       "6        rs1736103   -0.031732\n",
       "7        rs7535292   -0.026481\n",
       "8       rs13161496   -0.016119\n",
       "9        rs4331494   -0.004139\n",
       "10      rs34992950   -0.003211\n",
       "11      rs12510869   -0.000945\n",
       "12       rs2412116    0.001716\n",
       "13       rs2410595    0.003706\n",
       "14       rs4859611    0.014846\n",
       "15     rs112318363    0.015892\n",
       "16        rs379066    0.019658\n",
       "17      rs13188899    0.030844\n",
       "18      rs12935995     0.03166\n",
       "19        rs231454    0.036038\n",
       "20       rs3822023    0.043356\n",
       "21      rs11097213    0.059403\n",
       "22      rs11248057    0.077958\n",
       "23      rs12434297    0.094157\n",
       "24      rs11264302    0.095165\n",
       "25       rs3806760    0.114488\n",
       "26          rs5848    0.126228"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "max_auc_score = roc_auc_score(Y, best_lr.predict_proba(X)[:, 1])\n",
    "coefs = best_lr.coef_[0, :]\n",
    "num_coef = np.sum(coefs != 0)\n",
    "X_header = np.array(X.columns)\n",
    "\n",
    "data_array = np.vstack((X_header, coefs))\n",
    "model_coefs = pd.DataFrame(data=data_array.T, columns=['SNP', 'Coefficient'])\n",
    "print(f'Max AUC score:{max_auc_score}\\n')\n",
    "print(f'Non-zero coefficients: {num_coef}\\n')\n",
    "print(f'Best estimator: {grid_lr.best_estimator_}')\n",
    "print(f'Scorer: {grid_lr.scorer_}')\n",
    "print(f'Best params: {grid_lr.best_params_}')\n",
    "print(f'Best score: {grid_lr.best_score_}\\n')\n",
    "m = model_coefs[model_coefs['Coefficient'] != 0 ].sort_values(by='Coefficient')\n",
    "m = m.reset_index(drop=True).assign(Index=range(len(m)))\n",
    "m.Index= m.Index + 1\n",
    "m.set_index('Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324565d",
   "metadata": {},
   "source": [
    "## NN Males\n",
    "\n",
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f0c0b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phenotype\n",
       "0    191\n",
       "1    216\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1 = table[(table.gender == \"M\") & (table.inv_genotype==\"NN\")]\n",
    "X = table1[table1.columns[5:]]\n",
    "Y = table1['phenotype']\n",
    "lr = LogisticRegression(random_state=42, solver='saga', n_jobs=-1, penalty='elasticnet')\n",
    "table1.groupby('phenotype')['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76b7d22",
   "metadata": {},
   "source": [
    "### Grid search for 3 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87892ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.05, 0.1, 0.5], &#x27;l1_ratio&#x27;: [0.7, 0.6, 0.5],\n",
       "                         &#x27;max_iter&#x27;: [10, 25]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.05, 0.1, 0.5], &#x27;l1_ratio&#x27;: [0.7, 0.6, 0.5],\n",
       "                         &#x27;max_iter&#x27;: [10, 25]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                          random_state=42, solver='saga'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.05, 0.1, 0.5], 'l1_ratio': [0.7, 0.6, 0.5],\n",
       "                         'max_iter': [10, 25]},\n",
       "             scoring='roc_auc', verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {'C': [0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 1, 10, 20, 30],\n",
    "#               'max_iter': [10, 25, 50, 75, 100, 150, 200, 400, 800, 1600],\n",
    "#               'l1_ratio': [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]}\n",
    "\n",
    "parameters = {'C': [0.05, 0.1, 0.5],\n",
    "              'max_iter': [10, 25],\n",
    "              'l1_ratio': [0.7, 0.6, 0.5]}\n",
    "\n",
    "grid_lr = GridSearchCV(lr, parameters, verbose=False, scoring='roc_auc', n_jobs=-1, cv=10)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "grid_lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50579272",
   "metadata": {},
   "source": [
    "### Best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7c2440a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max AUC score:0.7224403723094822\n",
      "\n",
      "Non-zero coefficients: 32\n",
      "\n",
      "Best estimator: LogisticRegression(C=0.1, l1_ratio=0.6, max_iter=10, n_jobs=-1,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga')\n",
      "Scorer: make_scorer(roc_auc_score, needs_threshold=True)\n",
      "Best params: {'C': 0.1, 'l1_ratio': 0.6, 'max_iter': 10}\n",
      "Best score: 0.5580189109136477\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs35776335</td>\n",
       "      <td>-0.213769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs13161496</td>\n",
       "      <td>-0.193039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs12499663</td>\n",
       "      <td>-0.150666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs444618</td>\n",
       "      <td>-0.124434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rs112270735</td>\n",
       "      <td>-0.083023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rs1269243287</td>\n",
       "      <td>-0.055458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rs3912643</td>\n",
       "      <td>-0.048141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rs11097297</td>\n",
       "      <td>-0.047875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rs2128786</td>\n",
       "      <td>-0.03413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rs3850379</td>\n",
       "      <td>-0.030484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rs4331494</td>\n",
       "      <td>-0.014515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rs11264302</td>\n",
       "      <td>-0.001455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rs3850745</td>\n",
       "      <td>-0.001154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rs35456861</td>\n",
       "      <td>-0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rs764324</td>\n",
       "      <td>-0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rs12543164</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rs10448130</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rs35933728</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rs2412116</td>\n",
       "      <td>0.018849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rs79828056</td>\n",
       "      <td>0.022762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rs1949362</td>\n",
       "      <td>0.027434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rs1501467</td>\n",
       "      <td>0.035676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rs78197677</td>\n",
       "      <td>0.05128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rs1372420</td>\n",
       "      <td>0.073048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rs6842271</td>\n",
       "      <td>0.088079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rs12434297</td>\n",
       "      <td>0.089281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rs9985581</td>\n",
       "      <td>0.124415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rs3822023</td>\n",
       "      <td>0.128854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rs55805734</td>\n",
       "      <td>0.133538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rs4897753</td>\n",
       "      <td>0.210087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rs6964</td>\n",
       "      <td>0.215979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rs3806760</td>\n",
       "      <td>0.233441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SNP Coefficient\n",
       "Index                          \n",
       "1        rs35776335   -0.213769\n",
       "2        rs13161496   -0.193039\n",
       "3        rs12499663   -0.150666\n",
       "4          rs444618   -0.124434\n",
       "5       rs112270735   -0.083023\n",
       "6      rs1269243287   -0.055458\n",
       "7         rs3912643   -0.048141\n",
       "8        rs11097297   -0.047875\n",
       "9         rs2128786    -0.03413\n",
       "10        rs3850379   -0.030484\n",
       "11        rs4331494   -0.014515\n",
       "12       rs11264302   -0.001455\n",
       "13        rs3850745   -0.001154\n",
       "14       rs35456861   -0.000152\n",
       "15         rs764324   -0.000024\n",
       "16       rs12543164    0.000034\n",
       "17       rs10448130    0.000146\n",
       "18       rs35933728    0.000247\n",
       "19        rs2412116    0.018849\n",
       "20       rs79828056    0.022762\n",
       "21        rs1949362    0.027434\n",
       "22        rs1501467    0.035676\n",
       "23       rs78197677     0.05128\n",
       "24        rs1372420    0.073048\n",
       "25        rs6842271    0.088079\n",
       "26       rs12434297    0.089281\n",
       "27        rs9985581    0.124415\n",
       "28        rs3822023    0.128854\n",
       "29       rs55805734    0.133538\n",
       "30        rs4897753    0.210087\n",
       "31           rs6964    0.215979\n",
       "32        rs3806760    0.233441"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "max_auc_score = roc_auc_score(Y, best_lr.predict_proba(X)[:, 1])\n",
    "coefs = best_lr.coef_[0, :]\n",
    "num_coef = np.sum(coefs != 0)\n",
    "X_header = np.array(X.columns)\n",
    "\n",
    "data_array = np.vstack((X_header, coefs))\n",
    "model_coefs = pd.DataFrame(data=data_array.T, columns=['SNP', 'Coefficient'])\n",
    "print(f'Max AUC score:{max_auc_score}\\n')\n",
    "print(f'Non-zero coefficients: {num_coef}\\n')\n",
    "print(f'Best estimator: {grid_lr.best_estimator_}')\n",
    "print(f'Scorer: {grid_lr.scorer_}')\n",
    "print(f'Best params: {grid_lr.best_params_}')\n",
    "print(f'Best score: {grid_lr.best_score_}\\n')\n",
    "m = model_coefs[model_coefs['Coefficient'] != 0 ].sort_values(by='Coefficient')\n",
    "m = m.reset_index(drop=True).assign(Index=range(len(m)))\n",
    "m.Index= m.Index + 1\n",
    "m.set_index('Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28dbef0",
   "metadata": {},
   "source": [
    "## NI Males\n",
    "\n",
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f8d5d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phenotype\n",
       "0    480\n",
       "1    477\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1 = table[(table.gender == \"M\") & (table.inv_genotype==\"NI\")]\n",
    "X = table1[table1.columns[5:]]\n",
    "Y = table1['phenotype']\n",
    "lr = LogisticRegression(random_state=42, solver='saga', n_jobs=-1, penalty='elasticnet')\n",
    "table1.groupby('phenotype')['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1d5ebc",
   "metadata": {},
   "source": [
    "### Grid search for 3 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fb25296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.005, 0.01], &#x27;l1_ratio&#x27;: [0.2, 0.1],\n",
       "                         &#x27;max_iter&#x27;: [10, 25, 50]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.005, 0.01], &#x27;l1_ratio&#x27;: [0.2, 0.1],\n",
       "                         &#x27;max_iter&#x27;: [10, 25, 50]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                          random_state=42, solver='saga'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.005, 0.01], 'l1_ratio': [0.2, 0.1],\n",
       "                         'max_iter': [10, 25, 50]},\n",
       "             scoring='roc_auc', verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {'C': [0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 1, 10, 20, 30],\n",
    "#               'max_iter': [10, 25, 50, 75, 100, 150, 200, 400, 800, 1600],\n",
    "#               'l1_ratio': [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]}\n",
    "\n",
    "parameters = {'C': [0.005, 0.01],\n",
    "              'max_iter': [10, 25, 50],\n",
    "              'l1_ratio': [0.2, 0.1]}\n",
    "\n",
    "grid_lr = GridSearchCV(lr, parameters, verbose=False, scoring='roc_auc', n_jobs=-1, cv=10)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "grid_lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157610a2",
   "metadata": {},
   "source": [
    "### Best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad71c73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max AUC score:0.5835888364779874\n",
      "\n",
      "Non-zero coefficients: 4\n",
      "\n",
      "Best estimator: LogisticRegression(C=0.005, l1_ratio=0.1, max_iter=25, n_jobs=-1,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga')\n",
      "Scorer: make_scorer(roc_auc_score, needs_threshold=True)\n",
      "Best params: {'C': 0.005, 'l1_ratio': 0.1, 'max_iter': 25}\n",
      "Best score: 0.5212733636229314\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs7520918</td>\n",
       "      <td>-0.011899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs9985581</td>\n",
       "      <td>0.016555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs6842271</td>\n",
       "      <td>0.016555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs3806760</td>\n",
       "      <td>0.027075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SNP Coefficient\n",
       "Index                       \n",
       "1      rs7520918   -0.011899\n",
       "2      rs9985581    0.016555\n",
       "3      rs6842271    0.016555\n",
       "4      rs3806760    0.027075"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "max_auc_score = roc_auc_score(Y, best_lr.predict_proba(X)[:, 1])\n",
    "coefs = best_lr.coef_[0, :]\n",
    "num_coef = np.sum(coefs != 0)\n",
    "X_header = np.array(X.columns)\n",
    "\n",
    "data_array = np.vstack((X_header, coefs))\n",
    "model_coefs = pd.DataFrame(data=data_array.T, columns=['SNP', 'Coefficient'])\n",
    "print(f'Max AUC score:{max_auc_score}\\n')\n",
    "print(f'Non-zero coefficients: {num_coef}\\n')\n",
    "print(f'Best estimator: {grid_lr.best_estimator_}')\n",
    "print(f'Scorer: {grid_lr.scorer_}')\n",
    "print(f'Best params: {grid_lr.best_params_}')\n",
    "print(f'Best score: {grid_lr.best_score_}\\n')\n",
    "m = model_coefs[model_coefs['Coefficient'] != 0 ].sort_values(by='Coefficient')\n",
    "m = m.reset_index(drop=True).assign(Index=range(len(m)))\n",
    "m.Index= m.Index + 1\n",
    "m.set_index('Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2b71f2",
   "metadata": {},
   "source": [
    "## II Males\n",
    "\n",
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dc8f1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phenotype\n",
       "0    318\n",
       "1    296\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1 = table[(table.gender == \"M\") & (table.inv_genotype==\"II\")]\n",
    "X = table1[table1.columns[5:]]\n",
    "Y = table1['phenotype']\n",
    "lr = LogisticRegression(random_state=42, solver='saga', n_jobs=-1, penalty='elasticnet')\n",
    "table1.groupby('phenotype')['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be8ef32",
   "metadata": {},
   "source": [
    "### Grid search for 3 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b38a1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.02], &#x27;l1_ratio&#x27;: [0.2, 0.1],\n",
       "                         &#x27;max_iter&#x27;: [50, 75, 100]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.02], &#x27;l1_ratio&#x27;: [0.2, 0.1],\n",
       "                         &#x27;max_iter&#x27;: [50, 75, 100]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                          random_state=42, solver='saga'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.02], 'l1_ratio': [0.2, 0.1],\n",
       "                         'max_iter': [50, 75, 100]},\n",
       "             scoring='roc_auc', verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {'C': [0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 1, 10, 20, 30],\n",
    "#               'max_iter': [10, 25, 50, 75, 100, 150, 200, 400, 800, 1600],\n",
    "#               'l1_ratio': [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]}\n",
    "\n",
    "parameters = {'C': [0.01, 0.02],\n",
    "              'max_iter': [50, 75, 100],\n",
    "              'l1_ratio': [0.2, 0.1]}\n",
    "\n",
    "grid_lr = GridSearchCV(lr, parameters, verbose=False, scoring='roc_auc', n_jobs=-1, cv=10)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "grid_lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e02fe4",
   "metadata": {},
   "source": [
    "### Best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc9f8d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max AUC score:0.6759093999660037\n",
      "\n",
      "Non-zero coefficients: 18\n",
      "\n",
      "Best estimator: LogisticRegression(C=0.01, l1_ratio=0.1, max_iter=75, n_jobs=-1,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga')\n",
      "Scorer: make_scorer(roc_auc_score, needs_threshold=True)\n",
      "Best params: {'C': 0.01, 'l1_ratio': 0.1, 'max_iter': 75}\n",
      "Best score: 0.6007288190582128\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs34333</td>\n",
       "      <td>-0.092096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs3733349</td>\n",
       "      <td>-0.053093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs3785891</td>\n",
       "      <td>-0.013793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs8064765</td>\n",
       "      <td>-0.003056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rs62075803</td>\n",
       "      <td>-0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rs4796663</td>\n",
       "      <td>-0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rs4028634</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rs2410595</td>\n",
       "      <td>0.003947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rs764324</td>\n",
       "      <td>0.00623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rs4482120</td>\n",
       "      <td>0.009129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rs112318363</td>\n",
       "      <td>0.037641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rs12935995</td>\n",
       "      <td>0.040157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rs11097213</td>\n",
       "      <td>0.049525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rs3806760</td>\n",
       "      <td>0.050662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rs11248057</td>\n",
       "      <td>0.078256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rs11264302</td>\n",
       "      <td>0.08048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rs5848</td>\n",
       "      <td>0.085027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rs12434297</td>\n",
       "      <td>0.085108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SNP Coefficient\n",
       "Index                         \n",
       "1          rs34333   -0.092096\n",
       "2        rs3733349   -0.053093\n",
       "3        rs3785891   -0.013793\n",
       "4        rs8064765   -0.003056\n",
       "5       rs62075803   -0.002828\n",
       "6        rs4796663   -0.002828\n",
       "7        rs4028634    0.001729\n",
       "8        rs2410595    0.003947\n",
       "9         rs764324     0.00623\n",
       "10       rs4482120    0.009129\n",
       "11     rs112318363    0.037641\n",
       "12      rs12935995    0.040157\n",
       "13      rs11097213    0.049525\n",
       "14       rs3806760    0.050662\n",
       "15      rs11248057    0.078256\n",
       "16      rs11264302     0.08048\n",
       "17          rs5848    0.085027\n",
       "18      rs12434297    0.085108"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "max_auc_score = roc_auc_score(Y, best_lr.predict_proba(X)[:, 1])\n",
    "coefs = best_lr.coef_[0, :]\n",
    "num_coef = np.sum(coefs != 0)\n",
    "X_header = np.array(X.columns)\n",
    "\n",
    "data_array = np.vstack((X_header, coefs))\n",
    "model_coefs = pd.DataFrame(data=data_array.T, columns=['SNP', 'Coefficient'])\n",
    "print(f'Max AUC score:{max_auc_score}\\n')\n",
    "print(f'Non-zero coefficients: {num_coef}\\n')\n",
    "print(f'Best estimator: {grid_lr.best_estimator_}')\n",
    "print(f'Scorer: {grid_lr.scorer_}')\n",
    "print(f'Best params: {grid_lr.best_params_}')\n",
    "print(f'Best score: {grid_lr.best_score_}\\n')\n",
    "m = model_coefs[model_coefs['Coefficient'] != 0 ].sort_values(by='Coefficient')\n",
    "m = m.reset_index(drop=True).assign(Index=range(len(m)))\n",
    "m.Index= m.Index + 1\n",
    "m.set_index('Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f5a901",
   "metadata": {},
   "source": [
    "## NN Females\n",
    "\n",
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc1bcbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phenotype\n",
       "0    113\n",
       "1    122\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1 = table[(table.gender == \"F\") & (table.inv_genotype==\"NN\")]\n",
    "X = table1[table1.columns[5:]]\n",
    "Y = table1['phenotype']\n",
    "lr = LogisticRegression(random_state=42, solver='saga', n_jobs=-1, penalty='elasticnet')\n",
    "table1.groupby('phenotype')['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b49931",
   "metadata": {},
   "source": [
    "### Grid search for 3 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b9bf97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 0.5, 1], &#x27;l1_ratio&#x27;: [0.7, 0.6, 0.5],\n",
       "                         &#x27;max_iter&#x27;: [10, 25]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 0.5, 1], &#x27;l1_ratio&#x27;: [0.7, 0.6, 0.5],\n",
       "                         &#x27;max_iter&#x27;: [10, 25]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                          random_state=42, solver='saga'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 0.5, 1], 'l1_ratio': [0.7, 0.6, 0.5],\n",
       "                         'max_iter': [10, 25]},\n",
       "             scoring='roc_auc', verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {'C': [0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 1, 10, 20, 30],\n",
    "#               'max_iter': [10, 25, 50, 75, 100, 150, 200, 400, 800, 1600],\n",
    "#               'l1_ratio': [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]}\n",
    "\n",
    "parameters = {'C': [0.1, 0.5, 1],\n",
    "              'max_iter': [10, 25],\n",
    "              'l1_ratio': [0.7, 0.6, 0.5]}\n",
    "\n",
    "grid_lr = GridSearchCV(lr, parameters, verbose=False, scoring='roc_auc', n_jobs=-1, cv=10)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "grid_lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3948266",
   "metadata": {},
   "source": [
    "### Best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f6dea48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max AUC score:0.8581894675758015\n",
      "\n",
      "Non-zero coefficients: 112\n",
      "\n",
      "Best estimator: LogisticRegression(C=0.5, l1_ratio=0.6, max_iter=10, n_jobs=-1,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga')\n",
      "Scorer: make_scorer(roc_auc_score, needs_threshold=True)\n",
      "Best params: {'C': 0.5, 'l1_ratio': 0.6, 'max_iter': 10}\n",
      "Best score: 0.5679924242424242\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs6871718</td>\n",
       "      <td>-0.426813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs999361</td>\n",
       "      <td>-0.426221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs7826007</td>\n",
       "      <td>-0.365302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs3733349</td>\n",
       "      <td>-0.346928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rs78197677</td>\n",
       "      <td>-0.284285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rs7535292</td>\n",
       "      <td>-0.26294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rs4859611</td>\n",
       "      <td>-0.257429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rs1949362</td>\n",
       "      <td>-0.254682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rs11601088</td>\n",
       "      <td>-0.247447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rs7515378</td>\n",
       "      <td>-0.221912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rs12101192</td>\n",
       "      <td>-0.193561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rs231454</td>\n",
       "      <td>-0.182738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rs1859223</td>\n",
       "      <td>-0.170208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rs79976845</td>\n",
       "      <td>-0.159289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rs4495967</td>\n",
       "      <td>-0.150381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rs4482120</td>\n",
       "      <td>-0.150381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rs1501467</td>\n",
       "      <td>-0.140416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rs79828056</td>\n",
       "      <td>-0.136308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rs2433733</td>\n",
       "      <td>-0.12592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rs1372420</td>\n",
       "      <td>-0.125209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rs41311559</td>\n",
       "      <td>-0.114078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rs140859835</td>\n",
       "      <td>-0.084564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rs11097297</td>\n",
       "      <td>-0.083788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rs11097213</td>\n",
       "      <td>-0.076345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rs3822023</td>\n",
       "      <td>-0.074309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rs142448570</td>\n",
       "      <td>-0.073881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rs10448130</td>\n",
       "      <td>-0.073017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rs76848738</td>\n",
       "      <td>-0.061152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rs11021711</td>\n",
       "      <td>-0.060124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rs28691231</td>\n",
       "      <td>-0.049795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rs1269243287</td>\n",
       "      <td>-0.049795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rs34572188</td>\n",
       "      <td>-0.049509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rs2412116</td>\n",
       "      <td>-0.043475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>rs375017</td>\n",
       "      <td>-0.03843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>rs7666159</td>\n",
       "      <td>-0.033879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>rs4416502</td>\n",
       "      <td>-0.030128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>rs9330264</td>\n",
       "      <td>-0.027804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>rs734073</td>\n",
       "      <td>-0.023279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>rs55805734</td>\n",
       "      <td>-0.021777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>rs8064765</td>\n",
       "      <td>-0.019273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>rs4796663</td>\n",
       "      <td>-0.015331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>rs62075803</td>\n",
       "      <td>-0.015331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>rs12510869</td>\n",
       "      <td>-0.009278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>rs3850379</td>\n",
       "      <td>-0.000811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>rs10515816</td>\n",
       "      <td>-0.000433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rs3912643</td>\n",
       "      <td>-0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>rs13188899</td>\n",
       "      <td>-0.00041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>rs4921799</td>\n",
       "      <td>-0.000409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>rs4897753</td>\n",
       "      <td>-0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>rs6964</td>\n",
       "      <td>-0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>rs3806760</td>\n",
       "      <td>-0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>rs4028634</td>\n",
       "      <td>-0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>rs11579790</td>\n",
       "      <td>-0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>rs379066</td>\n",
       "      <td>-0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>rs3850745</td>\n",
       "      <td>-0.000123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>rs4841589</td>\n",
       "      <td>-0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>rs12499663</td>\n",
       "      <td>-0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>rs74609071</td>\n",
       "      <td>0.000652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>rs35456861</td>\n",
       "      <td>0.001887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>rs9985581</td>\n",
       "      <td>0.009368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>rs6842271</td>\n",
       "      <td>0.009368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>rs34288580</td>\n",
       "      <td>0.009444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>rs148514732</td>\n",
       "      <td>0.012629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>rs7515370</td>\n",
       "      <td>0.020841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>rs5848</td>\n",
       "      <td>0.023656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>rs77312060</td>\n",
       "      <td>0.026649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>rs72838312</td>\n",
       "      <td>0.02777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>rs444618</td>\n",
       "      <td>0.029691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>rs12995314</td>\n",
       "      <td>0.031652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>rs62190394</td>\n",
       "      <td>0.031652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>rs10110312</td>\n",
       "      <td>0.033873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>rs12543164</td>\n",
       "      <td>0.035274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>rs2075583</td>\n",
       "      <td>0.035907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>rs6532190</td>\n",
       "      <td>0.039457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>rs17324625</td>\n",
       "      <td>0.051377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>rs7682766</td>\n",
       "      <td>0.058691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>rs143756122</td>\n",
       "      <td>0.060175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>rs148894916</td>\n",
       "      <td>0.060175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>rs11264302</td>\n",
       "      <td>0.060206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>rs71371995</td>\n",
       "      <td>0.061233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>rs12150561</td>\n",
       "      <td>0.063362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>rs494312</td>\n",
       "      <td>0.066012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>rs536718528</td>\n",
       "      <td>0.066406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>rs12935995</td>\n",
       "      <td>0.070272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>rs2410595</td>\n",
       "      <td>0.070705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>rs7104332</td>\n",
       "      <td>0.077242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>rs4331494</td>\n",
       "      <td>0.077355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>rs7734182</td>\n",
       "      <td>0.085825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>rs35933728</td>\n",
       "      <td>0.086571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>rs17016235</td>\n",
       "      <td>0.090649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>rs34333</td>\n",
       "      <td>0.112067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>rs201304809</td>\n",
       "      <td>0.120855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>rs12434297</td>\n",
       "      <td>0.130994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>rs11589479</td>\n",
       "      <td>0.132404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>rs9799610</td>\n",
       "      <td>0.162529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>rs72803476</td>\n",
       "      <td>0.163414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>rs35776335</td>\n",
       "      <td>0.173641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>rs2128786</td>\n",
       "      <td>0.189926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>rs72846765</td>\n",
       "      <td>0.194033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>rs6599389</td>\n",
       "      <td>0.196567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>rs73211813</td>\n",
       "      <td>0.203329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>rs7387252</td>\n",
       "      <td>0.20655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>rs1800606</td>\n",
       "      <td>0.21257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>rs208024</td>\n",
       "      <td>0.219757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>rs9971953</td>\n",
       "      <td>0.254225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>rs9971789</td>\n",
       "      <td>0.254225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>rs7520918</td>\n",
       "      <td>0.289942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>rs13161496</td>\n",
       "      <td>0.291558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>rs3785891</td>\n",
       "      <td>0.302039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>rs764324</td>\n",
       "      <td>0.306943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>rs4241591</td>\n",
       "      <td>0.308725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>rs11248057</td>\n",
       "      <td>0.32366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SNP Coefficient\n",
       "Index                          \n",
       "1         rs6871718   -0.426813\n",
       "2          rs999361   -0.426221\n",
       "3         rs7826007   -0.365302\n",
       "4         rs3733349   -0.346928\n",
       "5        rs78197677   -0.284285\n",
       "6         rs7535292    -0.26294\n",
       "7         rs4859611   -0.257429\n",
       "8         rs1949362   -0.254682\n",
       "9        rs11601088   -0.247447\n",
       "10        rs7515378   -0.221912\n",
       "11       rs12101192   -0.193561\n",
       "12         rs231454   -0.182738\n",
       "13        rs1859223   -0.170208\n",
       "14       rs79976845   -0.159289\n",
       "15        rs4495967   -0.150381\n",
       "16        rs4482120   -0.150381\n",
       "17        rs1501467   -0.140416\n",
       "18       rs79828056   -0.136308\n",
       "19        rs2433733    -0.12592\n",
       "20        rs1372420   -0.125209\n",
       "21       rs41311559   -0.114078\n",
       "22      rs140859835   -0.084564\n",
       "23       rs11097297   -0.083788\n",
       "24       rs11097213   -0.076345\n",
       "25        rs3822023   -0.074309\n",
       "26      rs142448570   -0.073881\n",
       "27       rs10448130   -0.073017\n",
       "28       rs76848738   -0.061152\n",
       "29       rs11021711   -0.060124\n",
       "30       rs28691231   -0.049795\n",
       "31     rs1269243287   -0.049795\n",
       "32       rs34572188   -0.049509\n",
       "33        rs2412116   -0.043475\n",
       "34         rs375017    -0.03843\n",
       "35        rs7666159   -0.033879\n",
       "36        rs4416502   -0.030128\n",
       "37        rs9330264   -0.027804\n",
       "38         rs734073   -0.023279\n",
       "39       rs55805734   -0.021777\n",
       "40        rs8064765   -0.019273\n",
       "41        rs4796663   -0.015331\n",
       "42       rs62075803   -0.015331\n",
       "43       rs12510869   -0.009278\n",
       "44        rs3850379   -0.000811\n",
       "45       rs10515816   -0.000433\n",
       "46        rs3912643   -0.000415\n",
       "47       rs13188899    -0.00041\n",
       "48        rs4921799   -0.000409\n",
       "49        rs4897753   -0.000298\n",
       "50           rs6964   -0.000209\n",
       "51        rs3806760   -0.000191\n",
       "52        rs4028634   -0.000161\n",
       "53       rs11579790   -0.000147\n",
       "54         rs379066   -0.000132\n",
       "55        rs3850745   -0.000123\n",
       "56        rs4841589   -0.000072\n",
       "57       rs12499663   -0.000069\n",
       "58       rs74609071    0.000652\n",
       "59       rs35456861    0.001887\n",
       "60        rs9985581    0.009368\n",
       "61        rs6842271    0.009368\n",
       "62       rs34288580    0.009444\n",
       "63      rs148514732    0.012629\n",
       "64        rs7515370    0.020841\n",
       "65           rs5848    0.023656\n",
       "66       rs77312060    0.026649\n",
       "67       rs72838312     0.02777\n",
       "68         rs444618    0.029691\n",
       "69       rs12995314    0.031652\n",
       "70       rs62190394    0.031652\n",
       "71       rs10110312    0.033873\n",
       "72       rs12543164    0.035274\n",
       "73        rs2075583    0.035907\n",
       "74        rs6532190    0.039457\n",
       "75       rs17324625    0.051377\n",
       "76        rs7682766    0.058691\n",
       "77      rs143756122    0.060175\n",
       "78      rs148894916    0.060175\n",
       "79       rs11264302    0.060206\n",
       "80       rs71371995    0.061233\n",
       "81       rs12150561    0.063362\n",
       "82         rs494312    0.066012\n",
       "83      rs536718528    0.066406\n",
       "84       rs12935995    0.070272\n",
       "85        rs2410595    0.070705\n",
       "86        rs7104332    0.077242\n",
       "87        rs4331494    0.077355\n",
       "88        rs7734182    0.085825\n",
       "89       rs35933728    0.086571\n",
       "90       rs17016235    0.090649\n",
       "91          rs34333    0.112067\n",
       "92      rs201304809    0.120855\n",
       "93       rs12434297    0.130994\n",
       "94       rs11589479    0.132404\n",
       "95        rs9799610    0.162529\n",
       "96       rs72803476    0.163414\n",
       "97       rs35776335    0.173641\n",
       "98        rs2128786    0.189926\n",
       "99       rs72846765    0.194033\n",
       "100       rs6599389    0.196567\n",
       "101      rs73211813    0.203329\n",
       "102       rs7387252     0.20655\n",
       "103       rs1800606     0.21257\n",
       "104        rs208024    0.219757\n",
       "105       rs9971953    0.254225\n",
       "106       rs9971789    0.254225\n",
       "107       rs7520918    0.289942\n",
       "108      rs13161496    0.291558\n",
       "109       rs3785891    0.302039\n",
       "110        rs764324    0.306943\n",
       "111       rs4241591    0.308725\n",
       "112      rs11248057     0.32366"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "max_auc_score = roc_auc_score(Y, best_lr.predict_proba(X)[:, 1])\n",
    "coefs = best_lr.coef_[0, :]\n",
    "num_coef = np.sum(coefs != 0)\n",
    "X_header = np.array(X.columns)\n",
    "\n",
    "data_array = np.vstack((X_header, coefs))\n",
    "model_coefs = pd.DataFrame(data=data_array.T, columns=['SNP', 'Coefficient'])\n",
    "print(f'Max AUC score:{max_auc_score}\\n')\n",
    "print(f'Non-zero coefficients: {num_coef}\\n')\n",
    "print(f'Best estimator: {grid_lr.best_estimator_}')\n",
    "print(f'Scorer: {grid_lr.scorer_}')\n",
    "print(f'Best params: {grid_lr.best_params_}')\n",
    "print(f'Best score: {grid_lr.best_score_}\\n')\n",
    "m = model_coefs[model_coefs['Coefficient'] != 0 ].sort_values(by='Coefficient')\n",
    "m = m.reset_index(drop=True).assign(Index=range(len(m)))\n",
    "m.Index= m.Index + 1\n",
    "m.set_index('Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae0fca",
   "metadata": {},
   "source": [
    "## NI Females\n",
    "\n",
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ad38e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phenotype\n",
       "0    259\n",
       "1    270\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1 = table[(table.gender == \"F\") & (table.inv_genotype==\"NI\")]\n",
    "X = table1[table1.columns[5:]]\n",
    "Y = table1['phenotype']\n",
    "lr = LogisticRegression(random_state=42, solver='saga', n_jobs=-1, penalty='elasticnet')\n",
    "table1.groupby('phenotype')['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26f9e58",
   "metadata": {},
   "source": [
    "### Grid search for 3 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3addac87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.005, 0.01], &#x27;l1_ratio&#x27;: [1, 0.9],\n",
       "                         &#x27;max_iter&#x27;: [10, 25]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.005, 0.01], &#x27;l1_ratio&#x27;: [1, 0.9],\n",
       "                         &#x27;max_iter&#x27;: [10, 25]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                          random_state=42, solver='saga'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.005, 0.01], 'l1_ratio': [1, 0.9],\n",
       "                         'max_iter': [10, 25]},\n",
       "             scoring='roc_auc', verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {'C': [0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 1, 10, 20, 30],\n",
    "#              'max_iter': [10, 25, 50, 75, 100, 150, 200, 400, 800, 1600],\n",
    "#              'l1_ratio': [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]}\n",
    "\n",
    "parameters = {'C': [0.005, 0.01],\n",
    "              'max_iter': [10, 25],\n",
    "              'l1_ratio': [1, 0.9]}\n",
    "\n",
    "grid_lr = GridSearchCV(lr, parameters, verbose=False, scoring='roc_auc', n_jobs=-1, cv=10)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "grid_lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc2f9c4",
   "metadata": {},
   "source": [
    "### Best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33c6f6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max AUC score:0.5\n",
      "\n",
      "Non-zero coefficients: 0\n",
      "\n",
      "Best estimator: LogisticRegression(C=0.005, l1_ratio=1, max_iter=10, n_jobs=-1,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga')\n",
      "Scorer: make_scorer(roc_auc_score, needs_threshold=True)\n",
      "Best params: {'C': 0.005, 'l1_ratio': 1, 'max_iter': 10}\n",
      "Best score: 0.5\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SNP, Coefficient]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "max_auc_score = roc_auc_score(Y, best_lr.predict_proba(X)[:, 1])\n",
    "coefs = best_lr.coef_[0, :]\n",
    "num_coef = np.sum(coefs != 0)\n",
    "X_header = np.array(X.columns)\n",
    "\n",
    "data_array = np.vstack((X_header, coefs))\n",
    "model_coefs = pd.DataFrame(data=data_array.T, columns=['SNP', 'Coefficient'])\n",
    "print(f'Max AUC score:{max_auc_score}\\n')\n",
    "print(f'Non-zero coefficients: {num_coef}\\n')\n",
    "print(f'Best estimator: {grid_lr.best_estimator_}')\n",
    "print(f'Scorer: {grid_lr.scorer_}')\n",
    "print(f'Best params: {grid_lr.best_params_}')\n",
    "print(f'Best score: {grid_lr.best_score_}\\n')\n",
    "m = model_coefs[model_coefs['Coefficient'] != 0 ].sort_values(by='Coefficient')\n",
    "m = m.reset_index(drop=True).assign(Index=range(len(m)))\n",
    "m.Index= m.Index + 1\n",
    "m.set_index('Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709baf8f",
   "metadata": {},
   "source": [
    "## II Females\n",
    "\n",
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea91ac61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phenotype\n",
       "0    195\n",
       "1    175\n",
       "Name: participant_id, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1 = table[(table.gender == \"F\") & (table.inv_genotype==\"II\")]\n",
    "X = table1[table1.columns[5:]]\n",
    "Y = table1['phenotype']\n",
    "lr = LogisticRegression(random_state=42, solver='saga', n_jobs=-1, penalty='elasticnet')\n",
    "table1.groupby('phenotype')['participant_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd409f",
   "metadata": {},
   "source": [
    "### Grid search for 3 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca76ac0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [1, 10, 20], &#x27;l1_ratio&#x27;: [1, 0.9],\n",
       "                         &#x27;max_iter&#x27;: [1600, 3200]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          random_state=42, solver=&#x27;saga&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [1, 10, 20], &#x27;l1_ratio&#x27;: [1, 0.9],\n",
       "                         &#x27;max_iter&#x27;: [1600, 3200]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                          random_state=42, solver='saga'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [1, 10, 20], 'l1_ratio': [1, 0.9],\n",
       "                         'max_iter': [1600, 3200]},\n",
       "             scoring='roc_auc', verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {'C': [0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 1, 10, 20, 30],\n",
    "#               'max_iter': [10, 25, 50, 75, 100, 150, 200, 400, 800, 1600],\n",
    "#               'l1_ratio': [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]}\n",
    "\n",
    "parameters = {'C': [1, 10, 20],\n",
    "              'max_iter': [1600, 3200],\n",
    "              'l1_ratio': [1, 0.9]}\n",
    "\n",
    "grid_lr = GridSearchCV(lr, parameters, verbose=False, scoring='roc_auc', n_jobs=-1, cv=10)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "grid_lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e569e629",
   "metadata": {},
   "source": [
    "### Best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62a34901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max AUC score:0.8847765567765569\n",
      "\n",
      "Non-zero coefficients: 131\n",
      "\n",
      "Best estimator: LogisticRegression(C=10, l1_ratio=1, max_iter=3200, n_jobs=-1,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga')\n",
      "Scorer: make_scorer(roc_auc_score, needs_threshold=True)\n",
      "Best params: {'C': 10, 'l1_ratio': 1, 'max_iter': 3200}\n",
      "Best score: 0.5429274165806673\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs138844738</td>\n",
       "      <td>-4.155261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs115879964</td>\n",
       "      <td>-4.155261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs536718528</td>\n",
       "      <td>-3.617586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs115448944</td>\n",
       "      <td>-3.150895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rs71607338</td>\n",
       "      <td>-2.57904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rs17324625</td>\n",
       "      <td>-2.427067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rs2433733</td>\n",
       "      <td>-1.988805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rs6842271</td>\n",
       "      <td>-1.715214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rs62075803</td>\n",
       "      <td>-1.652955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rs4796663</td>\n",
       "      <td>-1.652955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rs112957100</td>\n",
       "      <td>-1.549041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rs79976845</td>\n",
       "      <td>-1.439649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rs74950708</td>\n",
       "      <td>-1.321806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rs11021711</td>\n",
       "      <td>-1.198849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rs1065712</td>\n",
       "      <td>-1.095391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rs444618</td>\n",
       "      <td>-1.090401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rs13131187</td>\n",
       "      <td>-1.017069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rs375017</td>\n",
       "      <td>-1.003348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rs11248057</td>\n",
       "      <td>-0.968769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rs494312</td>\n",
       "      <td>-0.932152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rs3733349</td>\n",
       "      <td>-0.883251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rs140859835</td>\n",
       "      <td>-0.836965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rs7535292</td>\n",
       "      <td>-0.718728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rs7515378</td>\n",
       "      <td>-0.699743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rs734073</td>\n",
       "      <td>-0.657171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rs76848738</td>\n",
       "      <td>-0.613196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rs4482120</td>\n",
       "      <td>-0.610804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rs6871718</td>\n",
       "      <td>-0.604013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rs112318363</td>\n",
       "      <td>-0.522652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rs74609071</td>\n",
       "      <td>-0.505636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rs12499663</td>\n",
       "      <td>-0.467277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rs77312060</td>\n",
       "      <td>-0.455806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rs3744427</td>\n",
       "      <td>-0.437119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>rs12434297</td>\n",
       "      <td>-0.431097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>rs11589479</td>\n",
       "      <td>-0.430368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>rs7666159</td>\n",
       "      <td>-0.427637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>rs34333</td>\n",
       "      <td>-0.413831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>rs10110312</td>\n",
       "      <td>-0.399533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>rs4921799</td>\n",
       "      <td>-0.395144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>rs1372420</td>\n",
       "      <td>-0.388175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>rs10515816</td>\n",
       "      <td>-0.384538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>rs1736103</td>\n",
       "      <td>-0.381249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>rs73211813</td>\n",
       "      <td>-0.354654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>rs10448130</td>\n",
       "      <td>-0.33797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>rs764324</td>\n",
       "      <td>-0.313281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rs4841589</td>\n",
       "      <td>-0.298304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>rs999361</td>\n",
       "      <td>-0.278567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>rs7387252</td>\n",
       "      <td>-0.254134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>rs72846765</td>\n",
       "      <td>-0.253638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>rs71371995</td>\n",
       "      <td>-0.187556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>rs34992950</td>\n",
       "      <td>-0.183292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>rs11579790</td>\n",
       "      <td>-0.141663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>rs9971953</td>\n",
       "      <td>-0.140982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>rs9971789</td>\n",
       "      <td>-0.140982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>rs7520918</td>\n",
       "      <td>-0.132976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>rs35933728</td>\n",
       "      <td>-0.128462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>rs13161496</td>\n",
       "      <td>-0.126504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>rs28691231</td>\n",
       "      <td>-0.113809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>rs4859611</td>\n",
       "      <td>-0.081506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>rs379066</td>\n",
       "      <td>-0.054031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>rs72803476</td>\n",
       "      <td>-0.048141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>rs7826007</td>\n",
       "      <td>-0.021814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>rs35456861</td>\n",
       "      <td>-0.01947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>rs148514732</td>\n",
       "      <td>-0.010154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>rs9330264</td>\n",
       "      <td>-0.008158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>rs72838312</td>\n",
       "      <td>-0.000916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>rs12543164</td>\n",
       "      <td>0.007514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>rs1501467</td>\n",
       "      <td>0.008177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>rs150107452</td>\n",
       "      <td>0.029482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>rs4241591</td>\n",
       "      <td>0.036761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>rs1269243287</td>\n",
       "      <td>0.044491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>rs2128786</td>\n",
       "      <td>0.051102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>rs2075583</td>\n",
       "      <td>0.066752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>rs3785891</td>\n",
       "      <td>0.091773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>rs12995314</td>\n",
       "      <td>0.108912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>rs62190394</td>\n",
       "      <td>0.108912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>rs1949362</td>\n",
       "      <td>0.110172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>rs7682766</td>\n",
       "      <td>0.120521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>rs6532182</td>\n",
       "      <td>0.12645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>rs4331494</td>\n",
       "      <td>0.140858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>rs12935995</td>\n",
       "      <td>0.148705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>rs1859223</td>\n",
       "      <td>0.150722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>rs7104332</td>\n",
       "      <td>0.155063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>rs3850745</td>\n",
       "      <td>0.219926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>rs11097213</td>\n",
       "      <td>0.221927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>rs117979807</td>\n",
       "      <td>0.232891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>rs2410595</td>\n",
       "      <td>0.2445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>rs35776335</td>\n",
       "      <td>0.287265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>rs12101192</td>\n",
       "      <td>0.326314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>rs4495967</td>\n",
       "      <td>0.341328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>rs79828056</td>\n",
       "      <td>0.353429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>rs11264302</td>\n",
       "      <td>0.368833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>rs17016235</td>\n",
       "      <td>0.383153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>rs6532190</td>\n",
       "      <td>0.383153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>rs34572188</td>\n",
       "      <td>0.393827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>rs208024</td>\n",
       "      <td>0.402916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>rs13188899</td>\n",
       "      <td>0.430538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>rs6964</td>\n",
       "      <td>0.445559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>rs75214905</td>\n",
       "      <td>0.458369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>rs3822023</td>\n",
       "      <td>0.458818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>rs231454</td>\n",
       "      <td>0.496512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>rs4897753</td>\n",
       "      <td>0.501664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>rs11097297</td>\n",
       "      <td>0.514293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>rs148894916</td>\n",
       "      <td>0.565314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>rs143756122</td>\n",
       "      <td>0.565314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>rs201304809</td>\n",
       "      <td>0.586162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>rs10831599</td>\n",
       "      <td>0.612322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>rs7515370</td>\n",
       "      <td>0.632874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>rs9799610</td>\n",
       "      <td>0.642287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>rs2412116</td>\n",
       "      <td>0.660505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>rs112270735</td>\n",
       "      <td>0.673886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>rs12150561</td>\n",
       "      <td>0.82272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>rs7734182</td>\n",
       "      <td>0.898797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>rs6836715</td>\n",
       "      <td>0.936025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>rs78197677</td>\n",
       "      <td>0.968978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>rs6599389</td>\n",
       "      <td>1.057432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>rs34288580</td>\n",
       "      <td>1.086857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>rs5848</td>\n",
       "      <td>1.09313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>rs3806760</td>\n",
       "      <td>1.103029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>rs142448570</td>\n",
       "      <td>1.167941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>rs41311559</td>\n",
       "      <td>1.289618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>rs9985581</td>\n",
       "      <td>1.394087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>rs3850379</td>\n",
       "      <td>1.404536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>rs55805734</td>\n",
       "      <td>1.418262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>rs117230705</td>\n",
       "      <td>1.559671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>rs74677851</td>\n",
       "      <td>1.919257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>rs4028634</td>\n",
       "      <td>2.386557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>rs11601088</td>\n",
       "      <td>2.926625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>rs1800606</td>\n",
       "      <td>3.409027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>rs8064765</td>\n",
       "      <td>5.881005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>rs79531911</td>\n",
       "      <td>7.603942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SNP Coefficient\n",
       "Index                          \n",
       "1       rs138844738   -4.155261\n",
       "2       rs115879964   -4.155261\n",
       "3       rs536718528   -3.617586\n",
       "4       rs115448944   -3.150895\n",
       "5        rs71607338    -2.57904\n",
       "6        rs17324625   -2.427067\n",
       "7         rs2433733   -1.988805\n",
       "8         rs6842271   -1.715214\n",
       "9        rs62075803   -1.652955\n",
       "10        rs4796663   -1.652955\n",
       "11      rs112957100   -1.549041\n",
       "12       rs79976845   -1.439649\n",
       "13       rs74950708   -1.321806\n",
       "14       rs11021711   -1.198849\n",
       "15        rs1065712   -1.095391\n",
       "16         rs444618   -1.090401\n",
       "17       rs13131187   -1.017069\n",
       "18         rs375017   -1.003348\n",
       "19       rs11248057   -0.968769\n",
       "20         rs494312   -0.932152\n",
       "21        rs3733349   -0.883251\n",
       "22      rs140859835   -0.836965\n",
       "23        rs7535292   -0.718728\n",
       "24        rs7515378   -0.699743\n",
       "25         rs734073   -0.657171\n",
       "26       rs76848738   -0.613196\n",
       "27        rs4482120   -0.610804\n",
       "28        rs6871718   -0.604013\n",
       "29      rs112318363   -0.522652\n",
       "30       rs74609071   -0.505636\n",
       "31       rs12499663   -0.467277\n",
       "32       rs77312060   -0.455806\n",
       "33        rs3744427   -0.437119\n",
       "34       rs12434297   -0.431097\n",
       "35       rs11589479   -0.430368\n",
       "36        rs7666159   -0.427637\n",
       "37          rs34333   -0.413831\n",
       "38       rs10110312   -0.399533\n",
       "39        rs4921799   -0.395144\n",
       "40        rs1372420   -0.388175\n",
       "41       rs10515816   -0.384538\n",
       "42        rs1736103   -0.381249\n",
       "43       rs73211813   -0.354654\n",
       "44       rs10448130    -0.33797\n",
       "45         rs764324   -0.313281\n",
       "46        rs4841589   -0.298304\n",
       "47         rs999361   -0.278567\n",
       "48        rs7387252   -0.254134\n",
       "49       rs72846765   -0.253638\n",
       "50       rs71371995   -0.187556\n",
       "51       rs34992950   -0.183292\n",
       "52       rs11579790   -0.141663\n",
       "53        rs9971953   -0.140982\n",
       "54        rs9971789   -0.140982\n",
       "55        rs7520918   -0.132976\n",
       "56       rs35933728   -0.128462\n",
       "57       rs13161496   -0.126504\n",
       "58       rs28691231   -0.113809\n",
       "59        rs4859611   -0.081506\n",
       "60         rs379066   -0.054031\n",
       "61       rs72803476   -0.048141\n",
       "62        rs7826007   -0.021814\n",
       "63       rs35456861    -0.01947\n",
       "64      rs148514732   -0.010154\n",
       "65        rs9330264   -0.008158\n",
       "66       rs72838312   -0.000916\n",
       "67       rs12543164    0.007514\n",
       "68        rs1501467    0.008177\n",
       "69      rs150107452    0.029482\n",
       "70        rs4241591    0.036761\n",
       "71     rs1269243287    0.044491\n",
       "72        rs2128786    0.051102\n",
       "73        rs2075583    0.066752\n",
       "74        rs3785891    0.091773\n",
       "75       rs12995314    0.108912\n",
       "76       rs62190394    0.108912\n",
       "77        rs1949362    0.110172\n",
       "78        rs7682766    0.120521\n",
       "79        rs6532182     0.12645\n",
       "80        rs4331494    0.140858\n",
       "81       rs12935995    0.148705\n",
       "82        rs1859223    0.150722\n",
       "83        rs7104332    0.155063\n",
       "84        rs3850745    0.219926\n",
       "85       rs11097213    0.221927\n",
       "86      rs117979807    0.232891\n",
       "87        rs2410595      0.2445\n",
       "88       rs35776335    0.287265\n",
       "89       rs12101192    0.326314\n",
       "90        rs4495967    0.341328\n",
       "91       rs79828056    0.353429\n",
       "92       rs11264302    0.368833\n",
       "93       rs17016235    0.383153\n",
       "94        rs6532190    0.383153\n",
       "95       rs34572188    0.393827\n",
       "96         rs208024    0.402916\n",
       "97       rs13188899    0.430538\n",
       "98           rs6964    0.445559\n",
       "99       rs75214905    0.458369\n",
       "100       rs3822023    0.458818\n",
       "101        rs231454    0.496512\n",
       "102       rs4897753    0.501664\n",
       "103      rs11097297    0.514293\n",
       "104     rs148894916    0.565314\n",
       "105     rs143756122    0.565314\n",
       "106     rs201304809    0.586162\n",
       "107      rs10831599    0.612322\n",
       "108       rs7515370    0.632874\n",
       "109       rs9799610    0.642287\n",
       "110       rs2412116    0.660505\n",
       "111     rs112270735    0.673886\n",
       "112      rs12150561     0.82272\n",
       "113       rs7734182    0.898797\n",
       "114       rs6836715    0.936025\n",
       "115      rs78197677    0.968978\n",
       "116       rs6599389    1.057432\n",
       "117      rs34288580    1.086857\n",
       "118          rs5848     1.09313\n",
       "119       rs3806760    1.103029\n",
       "120     rs142448570    1.167941\n",
       "121      rs41311559    1.289618\n",
       "122       rs9985581    1.394087\n",
       "123       rs3850379    1.404536\n",
       "124      rs55805734    1.418262\n",
       "125     rs117230705    1.559671\n",
       "126      rs74677851    1.919257\n",
       "127       rs4028634    2.386557\n",
       "128      rs11601088    2.926625\n",
       "129       rs1800606    3.409027\n",
       "130       rs8064765    5.881005\n",
       "131      rs79531911    7.603942"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "max_auc_score = roc_auc_score(Y, best_lr.predict_proba(X)[:, 1])\n",
    "coefs = best_lr.coef_[0, :]\n",
    "num_coef = np.sum(coefs != 0)\n",
    "X_header = np.array(X.columns)\n",
    "\n",
    "data_array = np.vstack((X_header, coefs))\n",
    "model_coefs = pd.DataFrame(data=data_array.T, columns=['SNP', 'Coefficient'])\n",
    "print(f'Max AUC score:{max_auc_score}\\n')\n",
    "print(f'Non-zero coefficients: {num_coef}\\n')\n",
    "print(f'Best estimator: {grid_lr.best_estimator_}')\n",
    "print(f'Scorer: {grid_lr.scorer_}')\n",
    "print(f'Best params: {grid_lr.best_params_}')\n",
    "print(f'Best score: {grid_lr.best_score_}\\n')\n",
    "m = model_coefs[model_coefs['Coefficient'] != 0 ].sort_values(by='Coefficient')\n",
    "m = m.reset_index(drop=True).assign(Index=range(len(m)))\n",
    "m.Index= m.Index + 1\n",
    "m.set_index('Index')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "source_map": [
   14,
   24,
   33,
   39,
   42,
   50,
   52,
   56,
   58,
   62,
   64,
   71,
   77,
   81,
   95,
   99,
   119,
   123,
   169,
   175,
   181,
   185,
   199,
   203,
   223,
   230,
   236,
   240,
   254,
   258,
   278,
   285,
   291,
   295,
   309,
   313,
   333,
   340,
   346,
   350,
   364,
   368,
   388,
   395,
   401,
   405,
   419,
   423,
   443,
   450,
   456,
   460,
   474,
   478,
   498,
   505,
   511,
   515,
   529,
   533,
   553,
   560,
   566,
   570,
   584,
   588,
   608,
   615,
   621,
   625,
   639,
   643,
   663,
   670,
   676,
   680,
   694,
   698,
   718,
   725,
   731,
   735,
   749,
   753
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}